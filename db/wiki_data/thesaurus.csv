Header,Content,acronym,Related_To,Synonym,Is_Synonym,regex_keys
k-means,"A clustering algorithm that groups examples in unsupervised learning. The k-means algorithm basically does the following: The k-means algorithm picks centroid locations to minimize the cumulativesquareof the distances from each example to its closest centroid. For example, consider the following plot of dog height to dog width:  If k=3, the k-means algorithm will determine three centroids. Each example
is assigned to its closest centroid, yielding three groups:  Imagine that a manufacturer wants to determine the ideal sizes for small,
medium, and large sweaters for dogs. The three centroids identify the mean
height and mean width of each dog in that cluster. So, the manufacturer
should probably base sweater sizes on those three centroids. Note that
the centroid of a cluster is typicallynotan example in the cluster. The preceding illustrations shows k-means for examples with only
two features (height and width). Note that k-means can group examples
across many features.",,"['centroid', 'clustering', 'feature', 'width']",,false,"(k(\s|-)?means|\s(\s|\.|\,))"
Low-Rank Adaptability (LoRA),"An algorithm for performing parameter efficient tuning (PEFT) that fine-tunes only a subset of an LLMs parameters.

An LLM tuned with LoRA maintains or improves the quality of its predictions. LoRA enables multiple specialized versions of a model.",LoRA,"['language model', 'large language model', 'model', 'parameter', 'prediction']",,false,"(Low(\s|-)?Rank(\s|-)?Adaptability(\s|-)?()|\sLoRA(\s|\.|\,)|\s(\s|\.|\,))"
gradient boosting,"A training algorithm where weak models are trained to iteratively
improve the quality (reduce the loss) of a strong model. For example, a weak model could be a linear or small decision tree model.
The strong model becomes the sum of all the previously trained weak models. In the simplest form of gradient boosting, at each iteration, a weak model
is trained to predict the loss gradient of the strong model. Then, the
strong model's output is updated by subtracting the predicted gradient, similar to gradient descent. where: Modern variations of gradient boosting also include the second derivative
(Hessian) of the loss in their computation. Decision trees are commonly used as weak models in gradient boosting. See gradient boosted (decision) trees.",,"['boosting', 'decision tree', 'gradient', 'gradient descent', 'iteration', 'linear', 'loss', 'model', 'training', 'intersection over union', 'Tensor Processing Unit']",,false,"(gradient(\s|-)?boost|\s(\s|\.|\,))"
A/B testing,"A statistical way of comparing two (or more) techniques‚ÄîtheAand theB. Typically, theAis an existing technique, and theBis a new technique.
A/B testing not only determines which technique performs better
but also whether the difference is statistically significant. A/B testing usually compares a singlemetricon two techniques;
for example, how does modelaccuracycompare for two
techniques? However, A/B testing can also compare any finite number of
metrics.",,"['accuracy', 'metric', 'model', 'test']",,false,"(A/B(\s|-)?test|\s(\s|\.|\,))"
AutoML,"Any automated process for buildingmachine learningmodels. AutoML can automatically do tasks such as the following: AutoML is useful for data scientists because it can save them time and
effort in developing machine learning pipelines and improve prediction
accuracy. It is also useful to non-experts, by making complicated
machine learning tasks more accessible to them.",,"['accuracy', 'machine learning', 'model', 'pipeline', 'prediction', 'task']",,false,"(AutoML|\s(\s|\.|\,))"
BLEU (Bilingual Evaluation Understudy),"A score between 0.0 and 1.0, inclusive, indicating the quality of a translation
between two human languages (for example, between English and Russian). A BLEU
score of 1.0 indicates a perfect translation; a BLEU score of 0.0 indicates a
terrible translation. ",BLEU,[],,false,"((\s|-)?|\sBLEU(\s|\.|\,)|\s(\s|\.|\,))"
Cloud TPU,"A specialized hardware accelerator designed to speed up machine
learning workloads on Google Cloud.",,[],,false,"(Cloud(\s|-)?TPU|\s(\s|\.|\,))"
negative class,"In binary classification, one class is
termed positive and the other is termednegative. The positive class is
the thing or event that the model is testing for and the negative class is the
other possibility. For example: Contrast withpositive class. ",,"['binary classification', 'class', 'model', 'positive class', 'test']",,false,"(negative(\s|-)?clas|\s(\s|\.|\,))"
discrete feature,"Afeaturewith a finite set of possible values. For example,
a feature whose values may only beanimal,vegetable, ormineralis a
discrete (or categorical) feature. Contrast withcontinuous feature. ",,"['continuous feature', 'feature']",,false,"(discrete(\s|-)?feature|\s(\s|\.|\,))"
golden dataset,"A set of manually curated data that captures ground truth.
Teams can use one or more golden datasets to evaluate a model's quality. Some golden datasets capture different subdomains of ground truth. For example,
a golden dataset for image classification might capture lighting conditions
and image resolution.",,"['class', 'condition', 'ground truth', 'model']",,false,"(golden(\s|-)?dataset|\s(\s|\.|\,))"
hidden layer,"A layer in aneural networkbetween theinput layer(the features) and theoutput layer(the prediction).
Each hidden layer consists of one or moreneurons.
For example, the following neural network contains two hidden layers,
the first with three neurons and the second with two neurons:  Adeep neural networkcontains more than one
hidden layer. For example, the preceding illustration is a deep neural
network because the model contains two hidden layers.",,"['deep neural network', 'feature', 'input layer', 'layer', 'model', 'neural network', 'neuron', 'output layer', 'prediction', 'Tensor Processing Unit']",,false,"(hidden(\s|-)?layer|\s(\s|\.|\,))"
multinomial classification,Synonym for multi-class classification. ,,"['class', 'multi-class classification']",multi-class classification,true,"(multinomial(\s|-)?classificat|\smulti-class classification(\s|\.|\,))"
TensorFlow,"A large-scale, distributed, machine learning platform. The term also refers to
the base API layer in the TensorFlow stack, which supports general computation
on dataflow graphs. ",,"['graph', 'layer', 'machine learning', 'task', 'Tensor']",,false,"(TensorFlow|\s(\s|\.|\,))"
L1regularization,"A type ofregularizationthat penalizesweightsin proportion to the sum of the absolute value of
the weights. L1regularization helps drive the weights of irrelevant
or barely relevant features toexactly 0. Afeaturewith
a weight of 0 is effectively removed from the model. Contrast withL2regularization.",,"['feature', 'L2regularization', 'model', 'regularization', 'weight']",,false,"(L1regularizat|\s(\s|\.|\,))"
L2regularization,"A type ofregularizationthat penalizesweightsin proportion to the sum of thesquaresof the weights.
L2regularization helps driveoutlierweights (those
with high positive or low negative values) closer to 0 butnot quite to 0.
Features with values very close to 0 remain in the model
but don't influence the model's prediction very much. L2regularization always improves generalization inlinear models. Contrast withL1regularization.",,"['feature', 'generalization', 'L1regularization', 'linear', 'linear model', 'model', 'prediction', 'regularization', 'weight']",,false,"(L2regularizat|\sridge regularization(\s|\.|\,))"
LaMDA (Language Model for Dialogue Applications),"ATransformer-basedlarge language modeldeveloped by Google trained on
a large dialogue dataset that can generate realistic conversational responses. LaMDA: our breakthrough conversation
technologyprovides an overview.",,"['language model', 'large language model', 'model', 'Transformer']",,false,"(LaMDA(\s|-)?|\s(\s|\.|\,))"
Layers API (tf.layers),"A TensorFlow API for constructing adeepneural network
as a composition of layers. The Layers API lets you build different
types oflayers, such as: The Layers API follows theKeraslayers API conventions.
That is, aside from a different prefix, all functions in the Layers API
have the same names and signatures as their counterparts in the Keras
layers API.",,"['Keras', 'layer', 'neural network', 'Tensor', 'TensorFlow']",,false,"(Layers(\s|-)?API(\s|-)?|\s(\s|\.|\,))"
XLA (Accelerated Linear Algebra),"An open-source machine learning compiler for GPUs, CPUs, and ML accelerators. The XLA compiler takes models from popular ML frameworks such asPyTorch,TensorFlow, andJAX, and optimizes them
for high-performance execution across different hardware platforms including
GPUs, CPUs, and MLaccelerators. ",,"['JAX', 'machine learning', 'model', 'performance', 'Tensor', 'TensorFlow']",,false,"(XLA(\s|-)?|\s(\s|\.|\,))"
historical bias,"A type ofbiasthat already exists in the world and has
made its way into a dataset. These biases have a tendency to reflect existing
cultural stereotypes, demographic inequalities, and prejudices against certain
social groups. For example, consider aclassification modelthat
predicts whether or not a loan applicant will default on their loan, which was
trained on historical loan-default data from the 1980s from local banks in two
different communities. If past applicants from Community A were six times more
likely to default on their loans than applicants from Community B, the model
might learn a historical bias resulting in the model being less likely to
approve loans in Community A, even if the historical conditions that resulted
in that community's higher default rates were no longer relevant. ",,"['class', 'classification model', 'condition', 'graph', 'model']",,false,"(historical(\s|-)?bia|\s(\s|\.|\,))"
in-set condition,"In adecision tree, aconditionthat tests for the presence of one item in a set of items.
For example, the following is an in-set condition: During inference, if the value of the house-stylefeatureistudororcolonialorcape, then this condition evaluates to Yes. If
the value of the house-style feature is something else (for example,ranch),
then this condition evaluates to No. In-set conditions usually lead to more efficient decision trees than
conditions that testone-hot encodedfeatures. ",,"['condition', 'decision tree', 'feature', 'inference', 'items', 'test']",,false,"(in(\s|-)?set(\s|-)?condit|\s(\s|\.|\,))"
Deep Q-Network,"In Q-learning, a deep neural network that predicts Q-functions. Critic is a synonym for Deep Q-Network.",DQN,"['critic', 'neural network', 'Q-function', 'Q-learning']",,false,"(Deep(\s|-)?Q(\s|-)?Network|\sDQN(\s|\.|\,)|\s(\s|\.|\,))"
epoch,"A full training pass over the entire training set such that each examplehas been processed once. An epoch represents N batch size training iterations, where N is the
total number of examples. ",,"['batch', 'batch size', 'instance', 'iteration', 'training', 'training set']",,false,"(epoch|\s(\s|\.|\,))"
MNIST,"A public-domain dataset compiled by LeCun, Cortes, and Burges containing
60,000 images, each image showing how a human manually wrote a particular
digit from 0‚Äì9. Each image is stored as a 28x28 array of integers, where
each integer is a grayscale value between 0 and 255, inclusive. MNIST is a canonical dataset for machine learning, often used to test new
machine learning approaches. For details, seeThe MNIST Database of Handwritten Digits.",,"['machine learning', 'test']",,false,"(MNIST|\s(\s|\.|\,))"
Markov decision process (MDP),"A graph representing the decision-making model where decisions
(oractions) are taken to navigate a sequence ofstatesunder the assumption that theMarkov propertyholds. Inreinforcement learning, these transitions
between states return a numericalreward.",,"['action', 'graph', 'Markov property', 'model', 'return', 'reward', 'state']",,false,"(Markov(\s|-)?decision(\s|-)?process(\s|-)?|\s(\s|\.|\,))"
Log Loss,The loss function used in binary logistic regression.,,"['logistic regression', 'loss', 'loss function']",,false,"(Log(\s|-)?Loss|\s(\s|\.|\,))"
axis-aligned condition,"In adecision tree, aconditionthat involves only a singlefeature. For example, if area
is a feature, then the following is an axis-aligned condition: Contrast withoblique condition. ",,"['condition', 'decision tree', 'feature', 'oblique condition']",,false,"(axis(\s|-)?aligned(\s|-)?condit|\s(\s|\.|\,))"
incompatibility of fairness metrics,"The idea that some notions of fairness are mutually incompatible and
cannot be satisfied simultaneously. As a result, there is no single
universalmetricfor quantifying fairness
that can be applied to all ML problems. While this may seem discouraging, incompatibility of fairness metrics
doesn't imply that fairness efforts are fruitless. Instead, it suggests
that fairness must be defined contextually for a given ML problem, with
the goal of preventing harms specific to its use cases. See""On the
(im)possibility of fairness""for a more detailed discussion of this topic.",,"['fairness metric', 'metric', 'retrieval-augmented generation']",,false,"(incompatibility(\s|-)?of(\s|-)?fairness(\s|-)?metric|\s(\s|\.|\,))"
holdout data,"Examplesintentionally not used (""held out"") during training.
Thevalidation datasetandtest datasetare examples of holdout data. Holdout data
helps evaluate your model's ability to generalize to data other than the
data it was trained on. The loss on the holdout set provides a better
estimate of the loss on an unseen dataset than does the loss on the
training set.",,"['loss', 'model', 'test', 'training', 'training set', 'validation']",,false,"(holdout(\s|-)?data|\s(\s|\.|\,))"
hinge loss,A family of loss functions for classification designed to find the decision boundary as distant as possible from each training example - thus maximizing the margin between examples and the boundary.,,"['binary classification', 'class', 'decision boundary', 'label', 'loss', 'loss function', 'model', 'squared hinge loss', 'training', 'Tensor Processing Unit']",,false,"(hinge(\s|-)?los|\s(\s|\.|\,))"
individual fairness,"A fairness metric that checks whether similar individuals are classified
similarly. For example, Brobdingnagian Academy might want to satisfy
individual fairness by ensuring that two students with identical grades
and standardized test scores are equally likely to gain admission. Note that individual fairness relies entirely on how you define ""similarity""
(in this case, grades and test scores), and you can run the risk of
introducing new fairness problems if your similarity metric misses important
information (such as the rigor of a student's curriculum). See""Fairness Through
Awareness""for a more detailed discussion of individual fairness.",,"['class', 'fairness metric', 'metric', 'test']",,false,"(individual(\s|-)?fairnes|\s(\s|\.|\,))"
inference,"In machine learning, the process of making predictions by
applying a trained model tounlabeled examples. Inference has a somewhat different meaning in statistics.
See theWikipedia article on statistical inferencefor details.",,"['label', 'labeled example', 'machine learning', 'model', 'prediction', 'unlabeled example']",,false,"(inference|\s(\s|\.|\,))"
encoder,"In general, any ML system that converts from a raw, sparse, or external
representation into a more processed, denser, or more internal representation. Encoders are often a component of a larger model, where they are frequently
paired with adecoder. SomeTransformerspair encoders with decoders, though other Transformers use only the encoder
or only the decoder. Some systems use the encoder's output as the input to a classification or
regression network. Insequence-to-sequence tasks, an encoder
takes an input sequence and returns an internal state (a vector). Then, thedecoderuses that internal state to predict the next sequence. Refer toTransformerfor the definition of an encoder in
the Transformer architecture. ",,"['class', 'decoder', 'model', 'representation', 'return', 'sequence-to-sequence task', 'state', 'task', 'Transformer', 'vector', 'Tensor Processing Unit']",,false,"(encoder|\s(\s|\.|\,))"
k-fold cross validation,"An algorithm used in model validation and testing for predicting a model's ability to generalize to new data. 
The k in k-fold refers to the number of equal groups you divide a dataset's examples into; that is, you train
and test your model k times. For each round of training and testing, a
different group is the test set, and all remaining groups become the training
set. After k rounds of training and testing, you calculate the mean and
standard deviation of the chosen test metric(s). For example,Mean Squared Error (MSE)might
be the most meaningful metric for a linear regression model. Therefore, you
would find the mean and standard deviation of the MSE across all four rounds.",,"['linear', 'linear regression', 'Mean Squared Error (MSE)', 'metric', 'model', 'regression model', 'test', 'test set', 'training']",,false,"(k(\s|-)?fold(\s|-)?cross(\s|-)?validat|\s(\s|\.|\,))"
loss aggregator,"A type of machine learning algorithm that
improves the performance of a modelby combining the predictions of multiple models and
using those predictions to make a single prediction. As a result,
a loss aggregator can reduce the variance of the predictions and
improve the accuracy of the predictions.",,"['accuracy', 'loss', 'machine learning', 'model', 'performance', 'prediction']",,false,"(loss(\s|-)?aggregator|\s(\s|\.|\,))"
auto-regressive model,"Amodelthat infers a prediction based on its own previous
predictions. For example, auto-regressive language models predict the nexttokenbased on the previously predicted tokens.
AllTransformer-basedlarge language modelsare auto-regressive. In contrast,GAN-based image models are usually not auto-regressive
since they generate an image in a single forward-pass and not iteratively in
steps. However, certain image generation modelsareauto-regressive because
they generate an image in steps. ",,"['language model', 'large language model', 'model', 'prediction', 'step', 'token', 'Transformer', 'intersection over union']",,false,"(auto(\s|-)?regressive(\s|-)?model|\s(\s|\.|\,))"
Parameter Server (PS),"A job that keeps track of a model'sparametersin a
distributed setting. ",,"['model', 'parameter']",,false,"(Parameter(\s|-)?Server(\s|-)?|\s(\s|\.|\,))"
Flaxformer,"An open-source Transformer library,
built on Flax, designed primarily for natural language processing
and multimodal research.",,"['Flax', 'Transformer']",,false,"(Flaxformer|\s(\s|\.|\,))"
TPU resource,"A TPU entity on Google Cloud that you create, manage, or consume. For
example,TPU nodesandTPU typesare
TPU resources.",,"['TPU node', 'TPU type', 'Tensor Processing Unit']",,false,"(TPU(\s|-)?resource|\s(\s|\.|\,))"
labeled example,"An example that contains one or morefeaturesand alabel. For example, the following table shows three
labeled examples from a house valuation model, each with three features
and one label: Insupervised machine learning,
models train on labeled examples and make predictions onunlabeled examples. Contrast labeled example with unlabeled examples. ",,"['feature', 'label', 'machine learning', 'model', 'prediction', 'supervised machine learning', 'unlabeled example']",,false,"(labeled(\s|-)?example|\s(\s|\.|\,))"
training,"The process of determining the ideal parameters(weights and
biases) comprising amodel. During training, a system reads in examplesand gradually adjusts parameters. Training uses each
example anywhere from a few times to billions of times.",,"['model', 'parameter', 'weight']",,false,"(training|\s(\s|\.|\,))"
logistic regression,"A type of regression model that predicts a probability.
Logistic regression models have the following characteristics: For example, consider a logistic regression model that calculates the
probability of an input email being either spam or not spam.
During inference, suppose the model predicts 0.72. Like any regression model, a logistic regression model predicts a number.",,"['binary classification', 'class', 'inference', 'model', 'regression model', 'step']",,false,"(logistic(\s|-)?regress|\s(\s|\.|\,))"
ensemble,"A collection of models trained independently whose predictions
are averaged or aggregated. In many cases, an ensemble produces better
predictions than a single model. For example, arandom forestis an ensemble built from multipledecision trees. Note that not alldecision forestsare ensembles.",,"['decision forest', 'decision tree', 'model', 'prediction', 'random forest', 'retrieval-augmented generation']",,false,"(ensemble|\s(\s|\.|\,))"
loss curve,A plot of loss as a function of the number of training iterations. Loss curves can help you determine when your model is converging or overfitting.,,"['generalization', 'generalization curve', 'iteration', 'loss', 'model', 'overfitting', 'training']",,false,"(loss(\s|-)?curve|\s(\s|\.|\,))"
loss,"During the trainingof a supervised model, a measure of how far a
model's prediction is from itslabel. A loss function calculates the loss. ",,"['label', 'loss function', 'model', 'prediction', 'training']",,false,"(loss|\scost(\s|\.|\,))"
large language model (LLM),"An informal term with no strict definition that usually means alanguage modelthat has a high number ofparameters.
Some large language models contain over 100 billion parameters. You might be wondering when alanguage modelbecomes large enough to
be termed alarge language model. Currently,
there is no agreed-upon defining line for the number of parameters. Most current large language models (for example,GPT) are based onTransformerarchitecture.",LLM,"['language model', 'model', 'parameter', 'Transformer']",,false,"(large(\s|-)?language(\s|-)?model|\sLLM(\s|\.|\,)|\s(\s|\.|\,))"
layer,A set of neurons in a neural network. ,,"['configuration', 'hidden layer', 'input layer', 'neural network', 'neuron', 'output layer', 'Tensor', 'TensorFlow', 'Tensor Processing Unit']",,false,"(layer|\s(\s|\.|\,))"
average precision,"A metric for summarizing the performance of a ranked sequence of results.
Average precision is calculated by taking the average of theprecisionvalues for each relevant result (each result in
the ranked list where the recall increases relative to the previous result). See alsoArea under the PR Curve.",,"['area under the PR curve', 'metric', 'performance', 'precision', 'recall', 'intersection over union', 'retrieval-augmented generation']",,false,"(average(\s|-)?precis|\s(\s|\.|\,))"
attribute,"Synonym forfeature. In machine learning fairness, attributes often refer to
characteristics pertaining to individuals.",,"['feature', 'machine learning']",feature,true,"(attribute|\sfeature(\s|\.|\,))"
group attribution bias,"Assuming that what is true for an individual is also true for everyone in that group. The effects of group attribution bias can be exacerbated
if aconvenience samplingis used for data collection. In a non-representative sample, attributions may be made that don't reflect reality. See also out-group homogeneity bias and in-group bias. ",,"['convenience sampling', 'in-group bias', 'out-group homogeneity bias']",,false,"(group(\s|-)?attribution(\s|-)?bia|\s(\s|\.|\,))"
bag of words,"A representation of the words in a phrase or passage,
irrespective of order. For example, bag of words represents the
following three phrases identically: Each word is mapped to an index in asparse vector, where
the vector has an index for every word in the vocabulary. For example,
the phrasethe dog jumpsis mapped into a feature vector with non-zero
values at the three indexes corresponding to the wordsthe,dog, andjumps. The non-zero value can be any of the following: ",,"['feature', 'feature vector', 'representation', 'sparse vector', 'vector']",,false,"(bag(\s|-)?of(\s|-)?word|\s(\s|\.|\,))"
bagging,"A method totrainanensemblewhere each
constituentmodeltrains on a random subset of training
examplessampled with replacement.
For example, arandom forestis a collection ofdecision treestrained with bagging. The termbaggingis short forbootstrapaggregating.",,"['decision tree', 'ensemble', 'model', 'random forest', 'training']",,false,"(bagging|\s(\s|\.|\,))"
Tensor rank,Seerank (Tensor).,,"['rank (Tensor)', 'Tensor']",,false,"(Tensor(\s|-)?rank|\s(\s|\.|\,))"
linear model,"A model that assigns one weight per feature to make predictions.
(Linear models also incorporate a bias.) In contrast,
the relationship of features to predictions indeep modelsis generallynonlinear. Linear models are usually easier to train and moreinterpretablethan deep models. However,
deep models can learn complex relationships between features. Linear regression and logistic regression are two types of linear models. A linear model follows this formula: Suppose a particular example contains the following values: Linear models include not only models that use only a linear equation to
make predictions but also a broader set of models that use a linear equation
as just one component of the formula that makes predictions.
For example, logistic regression post-processes the raw
prediction (y') to produce a final prediction value between 0 and 1,
exclusively.",,"['deep model', 'feature', 'linear', 'linear regression', 'logistic regression', 'model', 'nonlinear', 'online', 'prediction', 'weight']",,false,"(linear(\s|-)?model|\s(\s|\.|\,))"
matrix factorization,"In math, a mechanism for finding the matrixes whose dot product approximates a
target matrix. Inrecommendation systems, the target matrix
often holds users' ratings onitems. For example, the target
matrix for a movie recommendation system might look something like the
following, where the positive integers are user ratings and 0
means that the user didn't rate the movie: The movie recommendation system aims to predict user ratings for
unrated movies. For example, will User 1 likeBlack Panther? One approach for recommendation systems is to use matrix
factorization to generate the following two matrixes: For example, using matrix factorization on our three users and five items
could yield the following user matrix and item matrix: The dot product of the user matrix and item matrix yields a recommendation
matrix that contains not only the original user ratings but also predictions
for the movies that each user hasn't seen.
For example, consider User 1's rating ofCasablanca, which was 5.0. The dot
product corresponding to that cell in the recommendation matrix should
hopefully be around 5.0, and it is: More importantly, will User 1 likeBlack Panther? Taking the dot product
corresponding to the first row and the third column yields a predicted
rating of 4.3: Matrix factorization typically yields a user matrix and item matrix that,
together, are significantly more compact than the target matrix. ",,"['item matrix', 'items', 'prediction', 'recommendation system', 'target', 'user matrix']",,false,"(matrix(\s|-)?factorizat|\s(\s|\.|\,))"
feedback loop,"In machine learning, a situation in which a model's predictions influence the
training data for the same model or another model. For example, a model that
recommends movies will influence the movies that people see, which will then
influence subsequent movie recommendation models. ",,"['machine learning', 'model', 'prediction', 'training']",,false,"(feedback(\s|-)?loop|\s(\s|\.|\,))"
forget gate,"The portion of aLong Short-Term Memorycell that regulates the flow of information through the cell.
Forget gates maintain context by deciding which information to discard
from the cell state. ",,"['Long Short-Term Memory', 'state']",,false,"(forget(\s|-)?gate|\s(\s|\.|\,))"
batch inference,"The process of inferring predictions on multiple unlabeled examples divided into smaller
subsets (""batches""). Batch inference can leverage the parallelization features ofaccelerator chips. That is, multiple accelerators
can simultaneously infer predictions on different batches of unlabeled
examples, dramatically increasing the number of inferences per second. ",,"['accelerator chip', 'batch', 'feature', 'inference', 'label', 'labeled example', 'prediction', 'unlabeled example', 'retrieval-augmented generation']",,false,"(batch(\s|-)?inference|\s(\s|\.|\,))"
batch size,"The number of examples in a batch e.g. if the batch size is 100, then the model processes
100 examples per iteration. ",,"['batch', 'instance', 'iteration', 'model']",,false,"(batch(\s|-)?size|\s(\s|\.|\,))"
batch normalization,Normalizing the input or output of the activation functions in a hidden layer.,,"['activation function', 'batch', 'hidden layer', 'layer', 'normalization', 'Tensor Processing Unit']",,false,"(batch(\s|-)?normalizat|\s(\s|\.|\,))"
auxiliary loss,"A loss function‚Äîused in conjunction with a neural network model's main
loss function ‚Äî that helps accelerate training during the
early iterations when weights are randomly initialized. Auxiliary loss functions push effective gradients to the earlier layers. This facilitates convergence during training by combating the vanishing gradient problem. ",,"['convergence', 'gradient', 'iteration', 'layer', 'loss', 'loss function', 'model', 'neural network', 'training', 'vanishing gradient problem', 'weight']",,false,"(auxiliary(\s|-)?los|\s(\s|\.|\,))"
baseline,"A model used as a reference point for comparing how well another
model is performing. For example, a logistic regression modelmight serve as a
good baseline for a deep model. For a particular problem, the baseline helps model developers quantify
the minimal expected performance that a new model must achieve for the new
model to be useful.",,"['deep model', 'logistic regression', 'model', 'performance', 'regression model']",,false,"(baseline|\s(\s|\.|\,))"
bias (ethics/fairness),"1. Stereotyping, prejudice or favoritism towards some things, people,
or groups over others. These biases can affect collection and
interpretation of data, the design of a system, and how users interact
with a system. Forms of this type of bias include: 2. Systematic error introduced by a sampling or reporting procedure.
Forms of this type of bias include: Not to be confused with thebias termin machine learning models
orprediction bias.",,"['machine learning', 'model', 'prediction', 'prediction bias']",,false,"(bias(\s|-)?|\s(\s|\.|\,))"
agglomerative clustering,Seehierarchical clustering. ,,"['clustering', 'hierarchical clustering']",,false,"(agglomerative(\s|-)?cluster|\s(\s|\.|\,))"
model,"In general, any mathematical construct that processes input data and returns
output. Phrased differently, a model is the set of parameters and structure
needed for a system to make predictions.
Insupervised machine learning,
a model takes anexampleas input and infers apredictionas output. Within supervised machine learning,
models differ somewhat. For example: You can save, restore, or make copies of a model. Unsupervised machine learningalso
generates models, typically a function that can map an input example to
the most appropriatecluster. An algebraic function such as the following is a model: The preceding function maps input values (xandy) to
output. Similarly, a programming function like the following is also a model: A caller passes arguments to the preceding Python function, and the
Python function generates output (via thereturnstatement). Although adeep neural networkhas a very different mathematical structure than an algebraic or programming
function, a deep neural network still takes input (an example) and returns
output (a prediction). A human programmer codes a programming function manually. In contrast,
a machine learning model gradually learns the optimal parameters
during automated training. ",,"['deep neural network', 'machine learning', 'neural network', 'parameter', 'prediction', 'return', 'state', 'supervised machine learning', 'training', 'unsupervised machine learning', 'Tensor Processing Unit']",,false,"(model|\s(\s|\.|\,))"
model capacity,"The complexity of problems that a model can learn. The more complex the
problems that a model can learn, the higher the model's capacity. A model's
capacity typically increases with the number of model parameters. For a
formal definition of classifier capacity, seeVC dimension.",,"['class', 'model', 'parameter']",,false,"(model(\s|-)?capacity|\s(\s|\.|\,))"
Reinforcement Learning from Human Feedback (RLHF),"Using feedback from human raters to improve the quality of a model's responses.
For example, an RLHF mechanism can ask users to rate the quality of a model's
response with a üëç or üëé emoji. The system can then adjust its future responses
based on that feedback.",,"['model', 'rater']",,false,"(Reinforcement(\s|-)?Learning(\s|-)?from(\s|-)?Human(\s|-)?Feedback(\s|-)?|\s(\s|\.|\,))"
counterfactual fairness,"Afairness metricthat checks whether a classifier
produces the same result for one individual as it does for another individual
who is identical to the first, except with respect to one or moresensitive attributes. Evaluating a classifier for
counterfactual fairness is one method for surfacing potential sources of
bias in a model. ",,"['attribute', 'class', 'fairness metric', 'metric', 'model', 'sensitive attribute']",,false,"(counterfactual(\s|-)?fairnes|\s(\s|\.|\,))"
meta-learning,"A subset of machine learning that discovers or improves a learning algorithm.
A meta-learning system can also aim to train a model to quickly learn a new
task from a small amount of data or from experience gained in previous tasks.
Meta-learning algorithms generally try to achieve the following: Meta-learning is related to few-shot learning.",,"['few-shot learning', 'machine learning', 'model', 'task', 'intersection over union']",,false,"(meta(\s|-)?learn|\s(\s|\.|\,))"
accelerator chip,"A category of specialized hardware components designed to perform key
computations needed for deep learning algorithms. Accelerator chips (or justaccelerators, for short) can significantly
increase the speed and efficiency of training and inference tasks
compared to a general-purpose CPU. They are ideal for training
neural networks and similar computationally intensive tasks. Examples of accelerator chips include:",,"['inference', 'neural network', 'task', 'training']",,false,"(accelerator(\s|-)?chip|\s(\s|\.|\,))"
Saver,ATensorFlow objectresponsible for saving model checkpoints. ,,"['checkpoint', 'model', 'Tensor', 'TensorFlow']",,false,"(Saver|\s(\s|\.|\,))"
bidirectional,"A term used to describe a system that evaluates the text that bothprecedesandfollowsa target section of text. In contrast, aunidirectionalsystem only
evaluates the text thatprecedesa target section of text. For example, consider amasked language modelthat
must determine probabilities for the word or words representing the underline in
the following question: What is the _____ with you? A unidirectional language model would have to base its probabilities only
on the context provided by the words ""What"", ""is"", and ""the"". In contrast,
a bidirectional language model could also gain context from ""with"" and ""you"",
which might help the model generate better predictions.",,"['bidirectional language model', 'language model', 'masked language model', 'model', 'prediction', 'target', 'unidirectional', 'unidirectional language model']",,false,"(bidirectional|\s(\s|\.|\,))"
multi-class classification,"In supervised learning, aclassificationproblem
in which the dataset containsmore than twoclassesof labels.
For example, the labels in the Iris dataset must be one of the following
three classes: A model trained on the Iris dataset that predicts Iris type on new examples
is performing multi-class classification. In contrast, classification problems that distinguish between exactly two
classes arebinary classification models.
For example, an email model that predicts eitherspamornot spamis a binary classification model. In clustering problems, multi-class classification refers to more than
two clusters. ",,"['binary classification', 'class', 'classification model', 'clustering', 'label', 'model']",,false,"(multi(\s|-)?class(\s|-)?classificat|\smultinomial classification(\s|\.|\,))"
multimodal model,"A model whose inputs and/or outputs include more than onemodality. For example, consider a model that takes both an
image and a text caption (two modalities) asfeatures, and
outputs a score indicating how appropriate the text caption is for the image.
So, this model's inputs are multimodal and the output is unimodal. ",,"['feature', 'modality', 'model', 'Tensor Processing Unit']",,false,"(multimodal(\s|-)?model|\s(\s|\.|\,))"
multitask,"A machine learning technique in which a singlemodelis
trained to perform multipletasks. Multitask models are created by training on data that is appropriate for
each of the different tasks. This allows the model to learn to share
information across the tasks, which helps the model learn more effectively. A model trained for multiple tasks often has improved generalization abilities
and can be more robust at handling different types of data. ",,"['generalization', 'machine learning', 'model', 'task', 'training']",,false,"(multitask|\s(\s|\.|\,))"
hallucination,"The production of plausible-seeming but factually incorrect output by agenerative AImodel that purports to be making an
assertion about the real world.
For example, a generative AI model that claims that Barack Obama died in 1865
ishallucinating. ",,"['generative AI', 'model', 'Tensor Processing Unit']",,false,"(hallucinat|\sconfabulation(\s|\.|\,))"
boosting,"A machine learning technique that iteratively combines a set of simple and
not very accurate classifiers (referred to as ""weak"" classifiers) into a
classifier with high accuracy (a ""strong"" classifier) byupweightingthe examples that the model is currently
misclassifying.",,"['accuracy', 'class', 'machine learning', 'model', 'upweighting', 'weight']",,false,"(boosting|\s(\s|\.|\,))"
bidirectional language model,"Alanguage modelthat determines the probability that a
given token is present at a given location in an excerpt of text based on
theprecedingandfollowingtext.",,"['language model', 'model', 'token']",,false,"(bidirectional(\s|-)?language(\s|-)?model|\s(\s|\.|\,))"
bigram,AnN-gramin which N=2.,,"['N-gram']",,false,"(bigram|\s(\s|\.|\,))"
bounding box,"In an image, the (x,y) coordinates of a rectangle around an area of
interest, such as the dog in the image below.  ",,[],,false,"(bounding(\s|-)?box|\s(\s|\.|\,))"
calibration layer,"A post-prediction adjustment, typically to account forprediction bias. The adjusted predictions and
probabilities should match the distribution of an observed set of labels.",,"['distribution', 'label', 'prediction', 'prediction bias']",,false,"(calibration(\s|-)?layer|\s(\s|\.|\,))"
numerical data,"Featuresrepresented as integers or real-valued numbers.
For example, a house valuation model would probably represent the size
of a house (in square feet or square meters) as numerical data. Representing
a feature as numerical data indicates that the feature's values have
amathematicalrelationship to the label.
That is, the number of square meters in a house probably has some
mathematical relationship to the value of the house. Not all integer data should be represented as numerical data. For example,
postal codes in some parts of the world are integers; however, integer postal
codes shouldn't be represented as numerical data in models. That's because a
postal code of20000is not twice (or half) as potent as a postal code of
10000. Furthermore, although different postal codesdocorrelate to different
real estate values, we can't assume that real estate values at postal code
20000 are twice as valuable as real estate values at postal code 10000.
Postal codes should be represented ascategorical datainstead. Numerical features are sometimes calledcontinuous features. ",,"['categorical data', 'continuous feature', 'feature', 'label', 'model', 'state']",,false,"(numerical(\s|-)?data|\s(\s|\.|\,))"
outliers,"Values distant from most other values. In machine learning, any of the
following are outliers: For example, suppose thatwidget-priceis a feature of a certain model.
Assume that the meanwidget-priceis 7 Euros with a standard deviation
of 1 Euro. Examples containing awidget-priceof 12 Euros or 2 Euros
would therefore be considered outliers because each of those prices is
five standard deviations from the mean. Outliers are often caused by typos or other input mistakes. In other cases,
outliers aren't mistakes; after all, values five standard deviations away
from the mean are rare but hardly impossible. Outliers often cause problems in model training.Clippingis one way of managing outliers.",,"['clipping', 'feature', 'machine learning', 'model', 'model training', 'training']",,false,"(outliers|\s(\s|\.|\,))"
offline inference,"The process of a model generating a batch ofpredictionsand then caching (saving) those predictions. Apps can then access the inferred
prediction from the cache rather than rerunning the model. For example, consider a model that generates local weather forecasts
(predictions) once every four hours. After each model run, the system
caches all the local weather forecasts. Weather apps retrieve the forecasts
from the cache. Offline inference is also calledstatic inference. Contrast withonline inference.",,"['batch', 'inference', 'model', 'offline', 'online', 'online inference', 'prediction', 'static', 'static inference']",,false,"(offline(\s|-)?inference|\sstatic inference(\s|\.|\,))"
one-hot encoding,"Representing categorical data as a vector in which: One-hot encoding is commonly used to represent strings or identifiers that
have a finite set of possible values.
For example, suppose a certain categorical feature namedScandinaviahas five possible values: One-hot encoding could represent each of the five values as follows: Thanks to one-hot encoding, a model can learn different connections
based on each of the five countries. Representing a feature asnumerical datais an
alternative to one-hot encoding. Unfortunately, representing the
Scandinavian countries numerically is not a good choice. For example,
consider the following numeric representation: With numeric encoding, a model would interpret the raw numbers
mathematically and would try to train on those numbers.
However, Iceland isn't actually twice as much (or half as much) of
something as Norway, so the model would come to some strange conclusions. ",,"['categorical data', 'feature', 'model', 'numerical data', 'representation', 'vector']",,false,"(one(\s|-)?hot(\s|-)?encod|\s(\s|\.|\,))"
one-vs.-all,"Given a classification problem with N classes, a
solution consisting of N separatebinary classifiers‚Äîone binary classifier for
each possible outcome. For example, given a model that classifies examples
as animal, vegetable, or mineral, a one-vs.-all solution would provide the
following three separate binary classifiers:",,"['class', 'model']",,false,"(one(\s|-)?vs.(\s|-)?all|\s(\s|\.|\,))"
objective function,"The mathematical formula or metric that a model aims to optimize.
For example, the objective function for linear regression is usually Mean Squared Loss. Therefore, when training a
linear regression model, training aims to minimize Mean Squared Loss. In some cases, the goal is to maximize the objective function.
For example, if the objective function is accuracy, the goal is
to maximize accuracy. See also loss.",,"['accuracy', 'linear', 'linear regression', 'loss', 'metric', 'model', 'objective', 'regression model', 'squared loss', 'training']",,false,"(objective(\s|-)?funct|\s(\s|\.|\,))"
broadcasting,"Expanding the shape of an operand in a matrix math operation todimensionscompatible for that operation. For example,
linear algebra requires that the two operands in a matrix addition operation
must have the same dimensions. Consequently, you can't add a matrix of shape
(m, n) to a vector of length n. Broadcasting enables this operation by
virtually expanding the vector of length n to a matrix of shape (m, n) by
replicating the same values down each column. For example, given the following definitions, linear algebra prohibits
A+B because A and B have different dimensions: However, broadcasting enables the operation A+B by virtually expanding B to: Thus, A+B is now a valid operation: See the following description ofbroadcasting in NumPyfor more details.",,"['dimensions', 'linear', 'NumPy', 'replica', 'vector']",,false,"(broadcast|\s(\s|\.|\,))"
centroid,"The center of a cluster as determined by a k-means or k-median algorithm. ‚Ä®For instance, if k is 3, then the k-means or k-median algorithm finds 3 centroids.",,"['instance', 'k-means', 'k-median']",,false,"(centroid|\s(\s|\.|\,))"
pipelining,"A form of model parallelism in which a model's processing is divided into consecutive stages and each stage is executed
on a different device. While a stage is processing one batch, the preceding stage can work on the next batch. See also staged training. ",,"['batch', 'device', 'model', 'model parallelism', 'staged training', 'training']",,false,"(pipelin|\s(\s|\.|\,))"
sequence-to-sequence task,"A task that converts an input sequence oftokensto an output
sequence of tokens. For example, two popular kinds of sequence-to-sequence
tasks are: ",,"['task', 'token', 'Tensor Processing Unit']",,false,"(sequence(\s|-)?to(\s|-)?sequence(\s|-)?task|\s(\s|\.|\,))"
out-group homogeneity bias,"The tendency to see out-group members as more alike than in-group members
when comparing attitudes, values, personality traits, and other
characteristics.In-grouprefers to people you interact with regularly;out-grouprefers to people you don't interact with regularly. If you
create a dataset by asking people to provide attributes about
out-groups, those attributes may be less nuanced and more stereotyped
than attributes that participants list for people in their in-group. For example, Lilliputians might describe the houses of other Lilliputians
in great detail, citing small differences in architectural styles, windows,
doors, and sizes. However, the same Lilliputians might simply declare that
Brobdingnagians all live in identical houses. Out-group homogeneity bias is a form ofgroup attribution bias. See alsoin-group bias. ",,"['attribute', 'group attribution bias', 'in-group bias']",,false,"(out(\s|-)?group(\s|-)?homogeneity(\s|-)?bia|\s(\s|\.|\,))"
heuristic,"A simple and quickly implemented solution to a problem. For example,
""With a heuristic, we achieved 86% accuracy. When we switched to a
deep neural network, accuracy went up to 98%.""",,"['accuracy', 'deep neural network', 'neural network']",,false,"(heuristic|\s(\s|\.|\,))"
oversampling,"Reusing the examples of a minority classin aclass-imbalanced dataset in order to
create a more balanced training set. For example, consider abinary classificationproblem in which the ratio of themajority classto the
minority class is 5,000:1. If the dataset contains a million examples, then
the dataset contains only about 200 examples of the minority class, which might
be too few examples for effective training. To overcome this deficiency, you
might oversample (reuse) those 200 examples multiple times, possibly yielding
sufficient examples for useful training. You need to be careful about overoverfittingwhen
oversampling. Contrast withundersampling. ",,"['binary classification', 'class', 'class-imbalanced dataset', 'imbalanced dataset', 'majority class', 'minority class', 'overfitting', 'training', 'training set', 'undersampling']",,false,"(oversampl|\s(\s|\.|\,))"
pjit,"AJAXfunction that splits code to run across multipleaccelerator chips. The user passes a function to pjit,
which returns a function that has the equivalent semantics but is compiled
into anXLAcomputation that runs across multiple devices
(such as GPUs orTPUcores). pjit enables users to shard computations without rewriting them by using
theSPMDpartitioner. As of March 2023,pjithas been merged withjit. Refer toDistributed arrays and automatic
parallelizationfor more details.",,"['accelerator chip', 'device', 'JAX', 'return', 'shard', 'split', 'single program / multiple data', 'Tensor Processing Unit']",,false,"(pjit|\s(\s|\.|\,))"
pmap,"AJAXfunction that executes copies of an input function
on multiple underlying hardware devices
(CPUs, GPUs, orTPUs), with different input values.
pmap relies onSPMD.",,"['device', 'JAX', 'single program / multiple data', 'Tensor Processing Unit']",,false,"(pmap|\s(\s|\.|\,))"
positional encoding,"A technique to add information about thepositionof a token in a sequence to
the token's embedding.Transformer modelsuse positional
encoding to better understand the relationship between different parts of the
sequence. A common implementation of positional encoding uses a sinusoidal function.
(Specifically, the frequency and amplitude of the sinusoidal function are
determined by the position of the token in the sequence.) This technique
enables a Transformer model to learn to attend to different parts of the
sequence based on their position.",,"['model', 'token', 'Transformer']",,false,"(positional(\s|-)?encod|\s(\s|\.|\,))"
positive class,"The class you are testing for. For example, the positive class in a cancer model might be ""tumor.""
The positive class in an email classifier might be ""spam."" Contrast withnegative class. The termpositive classcan be confusing because the ""positive"" outcome
of many tests is often an undesirable result. For example, the positive class in
many medical tests corresponds to tumors or diseases. In general, you want a
doctor to tell you, ""Congratulations! Your test results were negative.""
Regardless, the positive class is the event that the test is seeking to find. Admittedly, you're simultaneously testing for both the positive and negative
classes.",,"['class', 'model', 'negative class', 'test']",,false,"(positive(\s|-)?clas|\s(\s|\.|\,))"
precision,"A metric for classification models that answers
the following question: When the model predicted thepositive class,
what percentage of the predictions were correct? Here is the formula: where: For example, suppose a model made 200 positive predictions.
Of these 200 positive predictions: In this case: Contrast withaccuracyandrecall. ",,"['accuracy', 'class', 'classification model', 'metric', 'model', 'positive class', 'prediction', 'recall']",,false,"(precis|\s(\s|\.|\,))"
co-training,"A semi-supervised learning approach. Co-training essentially amplifies independent signals into a stronger signal.
For instance, consider aclassification modelthat
categorizes individual used cars as eitherGoodorBad. One set of
predictive features might focus on aggregate characteristics such as the year,
make, and model of the car; another set of predictive features might focus on
the previous owner's driving record and the car's maintenance history. The seminal paper on co-training isCombining Labeled and Unlabeled Data with
Co-Trainingby
Blum and Mitchell.",,"['class', 'classification model', 'condition', 'feature', 'instance', 'label', 'model', 'semi-supervised learning', 'training', 'intersection over union']",,false,"(co(\s|-)?train|\s(\s|\.|\,))"
collaborative filtering,"Makingpredictionsabout the interests of one user
based on the interests of many other users. Collaborative filtering
is often used inrecommendation systems. ",,"['prediction', 'recommendation system']",,false,"(collaborative(\s|-)?filter|\s(\s|\.|\,))"
condition,"In adecision tree, anynodethat
evaluates an expression. For example, the following portion of a
decision tree contains two conditions:  A condition is also called a split or a test. Contrast condition withleaf. See also:",,"['decision tree', 'leaf', 'split', 'test']",,false,"(condit|\s(\s|\.|\,))"
independently and identically distributed (i.i.d),"Data drawn from a distribution that doesn't change, and where each value
drawn doesn't depend on values that have been drawn previously. An i.i.d.
is theideal gasof machine
learning‚Äîa useful mathematical construct but almost never exactly found
in the real world. For example, the distribution of visitors to a web page
may be i.i.d. over a brief window of time; that is, the distribution doesn't
change during that brief window and one person's visit is generally
independent of another's visit. However, if you expand that window of time,
seasonal differences in the web page's visitors may appear. See alsononstationarity.",i.i.d.,"['distribution', 'nonstationarity', 'stationarity', 'intersection over union']",,false,"(independently(\s|-)?and(\s|-)?identically(\s|-)?distributed(\s|-)?(|\si.i.d.(\s|\.|\,)|\s(\s|\.|\,))"
predictive rate parity,"Another name forpredictive parity. #fairnessProcessing data before it's used to train a model. Preprocessing could
be as simple as removing words from an English text corpus that don't
occur in the English dictionary, or could be as complex as re-expressing
data points in a way that eliminates as many attributes that are correlated
withsensitive attributesas possible.
Preprocessing can help satisfyfairness constraints.",,"['attribute', 'fairness constraint', 'model', 'predictive parity', 'preprocessing', 'sensitive attribute']",,false,"(predictive(\s|-)?rate(\s|-)?parity|\s(\s|\.|\,))"
probability density function,"A function that identifies the frequency of data samples havingexactlya
particular value. When a dataset's values are continuous floating-point
numbers, exact matches rarely occur. However,integratinga probability
density function from valuexto valueyyields the expected frequency of
data samples betweenxandy. For example, consider a normal distribution having a mean of 200 and a
standard deviation of 30. To determine the expected frequency of data samples
falling within the range 211.4 to 218.7, you can integrate the probability
density function for a normal distribution from 211.4 to 218.7.",,"['distribution']",,false,"(probability(\s|-)?density(\s|-)?funct|\s(\s|\.|\,))"
decision tree,"A supervised learning model composed of a set ofconditionsandleavesorganized hierarchically.
For example, the following is a decision tree:",,"['condition', 'model']",,false,"(decision(\s|-)?tree|\s(\s|\.|\,))"
pre-trained model,"Models or model components (such as an embedding vector) that have been already been trained.
Sometimes, you'll feed pre-trained embedding vectors into aneural network. Other times, your model will train the
embedding vectors themselves rather than rely on the pre-trained embeddings. The termpre-trained language modelrefers to alarge language modelthat has gone throughpre-training.",,"['embedding vector', 'language model', 'large language model', 'model', 'neural network', 'pre-training', 'training', 'vector']",,false,"(pre(\s|-)?trained(\s|-)?model|\s(\s|\.|\,))"
probabilistic regression model,"A regression modelthat uses not only theweightsfor eachfeature, but also the
uncertainty of those weights. A probabilistic regression model generates
a prediction and the uncertainty of that prediction. For example, a
probabilistic regression model might yield a prediction of 325 with a
standard deviation of 12. For more information about probabilistic regression
models, see thisColab on
tensorflow.org. ",,"['feature', 'model', 'prediction', 'regression model', 'Tensor', 'TensorFlow', 'weight']",,false,"(probabilistic(\s|-)?regression(\s|-)?model|\s(\s|\.|\,))"
precision-recall curve,A curve of precision versus recall at different classification thresholds.,,"['class', 'classification threshold', 'precision', 'recall']",,false,"(precision(\s|-)?recall(\s|-)?curve|\s(\s|\.|\,))"
bucketing,"Converting a singlefeatureinto multiple binary features
calledbucketsorbins,
typically based on a value range. The chopped feature is typically acontinuous feature. For example, instead of representing temperature as a single
continuous floating-point feature, you could chop ranges of temperatures
into discrete buckets, such as: The model will treat every value in the same bucket identically. For
example, the values13and22are both in the temperate bucket, so the
model treats the two values identically. If you represent temperature as a continuous feature, then the model
treats temperature as a single feature. If you represent temperature
as three buckets, then the model treats each bucket as a separate feature.
That is, a model can learn separate relationships of each bucket to thelabel. For example, alinear regressionmodel can learn
separateweightsfor each bucket. Increasing the number of buckets makes your model more complicated by
increasing the number of relationships that your model must learn.
For example, the cold, temperate, and warm buckets are essentially
three separate features for your model to train on. If you decide to add
two more buckets--for example, freezing and hot--your model would
now have to train on five separate features. How do you know how many buckets to create, or what the ranges for each
bucket should be? The answers typically require a fair amount of
experimentation. ",,"['continuous feature', 'feature', 'label', 'linear', 'linear regression', 'model', 'temperature', 'weight']",,false,"(bucket|\sbinning(\s|\.|\,))"
candidate generation,"The initial set of recommendations chosen by arecommendation system. For example, consider a
bookstore that offers 100,000 titles. The candidate generation phase creates
a much smaller list of suitable books for a particular user, say 500. But even
500 books is way too many to recommend to a user. Subsequent, more expensive,
phases of a recommendation system (such asscoringandre-ranking) reduce those 500 to a much smaller,
more useful set of recommendations. ",,"['ranking', 'recommendation system', 're-ranking', 'scoring']",,false,"(candidate(\s|-)?generat|\s(\s|\.|\,))"
TPU slice,"A TPU slice is a fractional portion of theTPU devicesin
aTPU Pod. All of the devices in a TPU slice are connected
to one another over a dedicated high-speed network.",,"['action', 'device', 'TPU device', 'TPU Pod', 'Tensor Processing Unit']",,false,"(TPU(\s|-)?slice|\s(\s|\.|\,))"
TPU worker,"A process that runs on a host machine and executes machine learning programs
onTPU devices.",,"['device', 'host', 'machine learning', 'TPU device', 'Tensor Processing Unit']",,false,"(TPU(\s|-)?worker|\s(\s|\.|\,))"
proxy labels,"Data used to approximate labels not directly available in a dataset. For example, suppose you must train a model to predict employee stress level. Your dataset contains a lot of predictive features but
doesn't contain a label namedstress level.Undaunted, you pick ""workplace accidents"" as a proxy label for
stress level. After all, employees under high stress get into more
accidents than calm employees. Or do they? Maybe workplace accidents
actually rise and fall for multiple reasons. As a second example, suppose you wantis it raining?to be a Boolean label
for your dataset, but your dataset doesn't contain rain data. If
photographs are available, you might establish pictures of people
carrying umbrellas as a proxy label foris it raining?Is that
a good proxy label? Possibly, but people in some cultures may be
more likely to carry umbrellas to protect against sun than the rain. Proxy labels are often imperfect. When possible, choose actual labels over
proxy labels. That said, when an actual label is absent, pick the proxy
label very carefully, choosing the least horrible proxy label candidate. #fairnessAn attribute used as a stand-in for asensitive attribute. For example, an
individual's postal code might be used as a proxy for their income,
race, or ethnicity.",,"['attribute', 'feature', 'graph', 'label', 'model', 'sensitive attribute']",,false,"(proxy(\s|-)?label|\s(\s|\.|\,))"
TensorFlow Serving,A platform to deploy trained models in production.,,"['model']",,false,"(TensorFlow(\s|-)?Serv|\s(\s|\.|\,))"
Tensor Processing Unit,"An application-specific integrated circuit (ASIC) that optimizes the
performance of machine learning workloads. These ASICs are deployed as
multipleTPU chipson aTPU device.",TPU,"['device', 'machine learning', 'performance', 'TPU chip', 'TPU device']",,false,"(Tensor(\s|-)?Processing(\s|-)?Unit|\sTPU(\s|\.|\,)|\s(\s|\.|\,))"
lambda,"Synonym forregularization rate. Lambda is an overloaded term. Here we're focusing on the term's
definition withinregularization.",,"['regularization', 'regularization rate']",regularization rate,true,"(lambda|\sregularization rate(\s|\.|\,))"
re-ranking,The final stage of a recommendation system (or RAG pipeline) during which scored items (or retrieved documents) may be re-graded according to some other rule or algorithm. ,,"['action', 'items', 'ranking', 'recommendation system', 'scoring']",,false,"(re(\s|-)?rank|\s(\s|\.|\,))"
convolutional filter,"One of the two actors in aconvolutional operation. (The other actor
is a slice of an input matrix.) A convolutional filter is a matrix having
the samerankas the input matrix, but a smaller shape.
For example, given a 28x28 input matrix, the filter could be any 2D matrix
smaller than 28x28. In photographic manipulation, all the cells in a convolutional filter are
typically set to a constant pattern of ones and zeroes. In machine learning,
convolutional filters are typically seeded with random numbers and then the
networktrainsthe ideal values.",,"['convolution', 'convolutional operation', 'graph', 'machine learning']",,false,"(convolutional(\s|-)?filter|\s(\s|\.|\,))"
iteration,"A single update of a model's parameters‚Äîthe model's weights and biases‚Äîduringtraining. The batch size determines
how many examples the model processes in a single iteration. For instance,
if the batch size is 20, then the model processes 20 examples before adjusting the parameters.",,"['batch', 'batch size', 'instance', 'model', 'neural network', 'parameter', 'training', 'weight']",,false,"(iterat|\s(\s|\.|\,))"
prompt-based learning,"A capability of certain models that enables them to adapt
their behavior in response to arbitrary text input (prompts).
In a typical prompt-based learning paradigm, a large language model responds to a prompt by
generating text. For example, suppose a user enters the following prompt: Summarize Newton's Third Law of Motion. A model capable of prompt-based learning isn't specifically trained to answer
the previous prompt. Rather, the model ""knows"" a lot of facts about physics,
a lot about general language rules, and a lot about what constitutes generally
useful answers. That knowledge is sufficient to provide a (hopefully) useful
answer. Additional human feedback (""That answer was too complicated."" or
""What's a reaction?"") enables some prompt-based learning systems to gradually
improve the usefulness of their answers.",,"['action', 'language model', 'large language model', 'model', 'prompt', 'intersection over union']",,false,"(prompt(\s|-)?based(\s|-)?learn|\s(\s|\.|\,))"
data set or dataset,"A collection of raw data, commonly (but not exclusively) organized in one
of the following formats:",,[],,false,"(data(\s|-)?set(\s|-)?or(\s|-)?dataset|\s(\s|\.|\,))"
keypoints,"The coordinates of particular features in an image. For example, for animage recognitionmodel that distinguishes
flower species, keypoints might be the center of each petal, the stem,
the stamen, and so on. ",,"['feature', 'image recognition', 'model']",,false,"(keypoint|\slandmarks(\s|\.|\,))"
random forest,"Anensembleofdecision treesin
which each decision tree is trained with a specific random noise,
such asbagging. Random forests are a type ofdecision forest.",,"['bagging', 'decision forest', 'decision tree', 'ensemble', 'noise']",,false,"(random(\s|-)?forest|\s(\s|\.|\,))"
rank (Tensor),"The number of dimensions in aTensor. For instance,
a scalar has rank 0, a vector has rank 1, and a matrix has rank 2. Not to be confused withrank (ordinality).",,"['dimensions', 'instance', 'rank (ordinality)', 'scalar', 'Tensor', 'vector']",,false,"(rank(\s|-)?|\s(\s|\.|\,))"
Tensor shape,"The number of elements aTensorcontains in various dimensions.
For example, a[5, 10]Tensor has a shape of 5 in one dimension and 10
in another.",,"['dimensions', 'Tensor', 'intersection over union']",,false,"(Tensor(\s|-)?shape|\s(\s|\.|\,))"
coverage bias,See selection bias.,,"['selection bias']",,false,"(coverage(\s|-)?bia|\s(\s|\.|\,))"
chain-of-thought prompting,"A prompt engineering technique that encourages a large language model (LLM) to explain its reasoning, step by step. For example, consider the following prompt, paying
particular attention to the second sentence: How many g forces would a driver experience in a car that goes from 0 to 60
miles per hour in 7 seconds? In the answer, show all relevant calculations. The LLM's response would likely: Chain-of-thought prompting forces the LLM to perform all the calculations,
which might lead to a more correct answer. In addition, chain-of-thought
prompting enables the user to examine the LLM's steps to determine whether
or not the answer makes sense.",,"['attention', 'language model', 'large language model', 'model', 'prompt', 'prompt engineering', 'step', 'large language model', 'retrieval-augmented generation']",,false,"(chain(\s|-)?of(\s|-)?thought(\s|-)?prompt|\s(\s|\.|\,))"
centroid-based clustering,"A category ofclusteringalgorithms that organizes data
into nonhierarchical clusters.k-meansis the most widely
used centroid-based clustering algorithm. Contrast withhierarchical clusteringalgorithms.",,"['centroid', 'clustering', 'hierarchical clustering', 'k-means']",,false,"(centroid(\s|-)?based(\s|-)?cluster|\s(\s|\.|\,))"
retrieval augmented generation (RAG),"A technique for improving the quality oflarge language model (LLM)output
by grounding it with sources of knowledge retrieved after the model was trained.
RAG improves the accuracy of LLM responses by providing the trained LLM with
access to information retrieved from trusted knowledge bases or documents. Common motivations to use retrieval-augmented generation include: For example, suppose that a chemistry app uses thePaLM
APIto generate summaries
related to user queries. When the app's backend receives a query, the backend:",RAG,"['accuracy', 'language model', 'large language model', 'model', 'large language model', 'Tensor Processing Unit']",,false,"(retrieval(\s|-)?augmented(\s|-)?generat|\sRAG(\s|\.|\,)|\s(\s|\.|\,))"
chat,"The contents of a back-and-forth dialogue with an ML system, typically alarge language model.
The previous interaction in a chat
(what you typed and how the large language model responded) becomes the
context for subsequent parts of the chat. Achatbotis an application of a large language model. ",,"['action', 'language model', 'large language model', 'model', 'intersection over union']",,false,"(chat|\s(\s|\.|\,))"
optimizer,"A specific implementation of a gradient descent algorithm e.g. AdaGrad, Stochastic GD",,"['gradient', 'gradient descent']",,false,"(optimizer|\s(\s|\.|\,))"
prompt tuning,"A parameter efficient tuning mechanism that learns a ""prefix"" that the system prepends to the
actual prompt. One variation of prompt tuning‚Äîsometimes called prefix tuning‚Äîis to
prepend the prefix at every layer. In contrast, most prompt tuning only adds a prefix to the input layer. For prompt tuning, the ""prefix"" (also known as a ""soft prompt"") is a handful of learned, task-specific vectors prepended to the text token
embeddings from the actual prompt. The system learns the soft prompt by
freezing all other model parameters and fine-tuning on a specific task.",,"['input layer', 'layer', 'model', 'parameter', 'prompt', 'task', 'token', 'vector']",,false,"(prompt(\s|-)?tun|\s(\s|\.|\,))"
checkpoint,"Data that captures the state of a model'sparametersat a
particular training iteration. Checkpoints enable exporting modelweights, or performingtrainingacross
multiple sessions. Checkpoints
also enable training to continue past errors (for example, job preemption). Whenfine tuning, the starting point fortrainingthe newmodelwill be a specific
checkpoint of thepre-trained model.",,"['fine tuning', 'iteration', 'model', 'parameter', 'pre-trained model', 'state', 'training', 'weight']",,false,"(checkpoint|\s(\s|\.|\,))"
class,"A category that a label can belong to.
For example: A classification model predicts a class.
In contrast, aregression modelpredicts a number
rather than a class.",,"['classification model', 'label', 'model', 'regression model']",,false,"(class|\s(\s|\.|\,))"
device,An overloaded term with the following two possible definitions: ,,[],,false,"(device|\s(\s|\.|\,))"
regression model,"Informally, a model that generates a numerical prediction. (In contrast,
aclassification modelgenerates a class
prediction.) For example, the following are all regression models: Two common types of regression models are: Not every model that outputs numerical predictions is a regression model.
In some cases, a numeric prediction is really just a classification model
that happens to have numeric class names. For example, a model that predicts
a numeric postal code is a classification model, not a regression model.",,"['class', 'classification model', 'model', 'prediction', 'Tensor Processing Unit']",,false,"(regression(\s|-)?model|\s(\s|\.|\,))"
logits,"The vector of raw (non-normalized) predictions that a classification
model generates, which is ordinarily then passed to a normalization function.
If the model is solving amulti-class classificationproblem, logits typically become an input to thesoftmaxfunction.
The softmax function then generates a vector of (normalized)
probabilities with one value for each possible class.",,"['class', 'model', 'multi-class classification', 'normalization', 'prediction', 'softmax', 'vector']",,false,"(logits|\s(\s|\.|\,))"
majority class,"The more common label in aclass-imbalanced dataset. For example,
given a dataset containing 99% negative labels and 1% positive labels, the
negative labels are the majority class. Contrast withminority class.",,"['class', 'class-imbalanced dataset', 'imbalanced dataset', 'label', 'minority class']",,false,"(majority(\s|-)?clas|\s(\s|\.|\,))"
regularization,"Any mechanism that reduces overfitting.
Regularization can also be defined as the penalty on a model's complexity.",,"['model', 'overfitting']",,false,"(regularizat|\s(\s|\.|\,))"
regularization rate,"A number that specifies the relative importance of regularization during training. Raising the
regularization rate reduces overfitting but may
reduce the model's predictive power. Conversely, reducing or omitting
the regularization rate increases overfitting. The regularization rate is usually represented as the Greek letter lambda.",,"['lambda', 'loss', 'model', 'overfitting', 'regularization', 'training']",,false,"(regularization(\s|-)?rate|\slambda(\s|\.|\,))"
mesh,"In ML parallel programming, a term associated with assigning the data and
model to TPU chips, and defining how these values will be sharded or replicated. Mesh is an overloaded term that can mean either of the following: In either case, a mesh is specified as ashape.",,"['model', 'replica', 'shard', 'TPU chip', 'Tensor Processing Unit']",,false,"(mesh|\s(\s|\.|\,))"
causal language model,"Synonym forunidirectional language model. Seebidirectional language modelto
contrast different directional approaches in language modeling.",,"['bidirectional', 'bidirectional language model', 'language model', 'model', 'unidirectional', 'unidirectional language model']",unidirectional language model,true,"(causal(\s|-)?language(\s|-)?model|\sunidirectional language model(\s|\.|\,))"
imbalanced dataset,Synonym forclass-imbalanced dataset.,,"['class', 'class-imbalanced dataset']",class-imbalanced dataset,true,"(imbalanced(\s|-)?dataset|\sclass-imbalanced dataset(\s|\.|\,))"
dynamic model,"A model that is frequently or continuously
retrained. A dynamic model is a ""lifelong learner"" that
constantly adapts to evolving data. A dynamic model is also known as an online model. Contrast with static model. ",,"['dynamic', 'model', 'online', 'static']",,false,"(dynamic(\s|-)?model|\s(\s|\.|\,))"
online,Synonym for dynamic.,,"['dynamic']",dynamic,true,"(online|\sdynamic(\s|\.|\,))"
downsampling,Overloaded term that can mean either of the following:,,[],,false,"(downsampl|\s(\s|\.|\,))"
dynamic,"Something done frequently or continuously.
The termsdynamicandonlineare synonyms in machine learning.
The following are common uses ofdynamicandonlinein machine
learning:",,"['linear', 'machine learning', 'online']",,false,"(dynamic|\sonline(\s|\.|\,))"
modality,"A high-level data category. For example, numbers, text, images, video, and
audio are five different modalities.",,[],,false,"(modality|\s(\s|\.|\,))"
matplotlib,"An open-source Python 2D plotting library - matplotlibhelps you visualize
different aspects of machine learning.",,"['machine learning']",,false,"(matplotlib|\s(\s|\.|\,))"
return,"In reinforcement learning, given a certain policy and a certain state, the
return is the sum of all rewards that the agentexpects to receive when following thepolicyfrom thestateto the end of theepisode. The agent
accounts for the delayed nature of expected rewards by discounting rewards
according to the state transitions required to obtain the reward. Therefore, if the discount factor is \(\gamma\), and \(r_0, \ldots, r_{N}\)
denote the rewards until the end of the episode, then the return calculation
is as follows:",,"['agent', 'episode', 'policy', 'reward', 'state']",,false,"(return|\s(\s|\.|\,))"
sampling with replacement,"A method of picking items from a set of candidate items in which the same
item can be picked multiple times. The phrase ""with replacement"" means
that after each selection, the selected item is returned to the pool
of candidate items. The inverse method,sampling without replacement,
means that a candidate item can only be picked once. For example, consider the following fruit set: Suppose that the system randomly picksfigas the first item.
If using sampling with replacement, then the system picks the
second item from the following set: Yes, that's the same set as before, so the system could potentially
pickfigagain. If using sampling without replacement, once picked, a sample can't be
picked again. For example, if the system randomly picksfigas the
first sample, thenfigcan't be picked again. Therefore, the system
picks the second sample from the following (reduced) set: The wordreplacementinsampling with replacementconfuses
many people.  In English,replacementmeans ""substitution.""
However,sampling with replacementactually uses the French definition
forreplacement, which means ""putting something back."" The English wordreplacementis translated as the French
wordremplacement.",,"['items', 'return']",,false,"(sampling(\s|-)?with(\s|-)?replacement|\s(\s|\.|\,))"
selection bias,"Errors in conclusions drawn from sampled data due to a selection process
that generates systematic differences between samples observed in the data
and those not observed. The following forms of selection bias exist: For example, suppose you are creating a machine learning model that predicts
people's enjoyment of a movie. To collect training data,
you hand out a survey to everyone in the front row of a theater
showing the movie. Offhand, this may sound like a reasonable way
to gather a dataset; however, this form of data collection may
introduce the following forms of selection bias:",,"['machine learning', 'model', 'training']",,false,"(selection(\s|-)?bia|\s(\s|\.|\,))"
self-training,"A variant of self-supervised learning that is
particularly useful when all of the following conditions are true: Self-training works by iterating over the following two steps until the model
stops improving: Notice that each iteration of Step 2 adds more labeled examples for Step 1 to train on. ",,"['condition', 'iteration', 'label', 'labeled example', 'model', 'self-supervised learning', 'step', 'training']",,false,"(self(\s|-)?train|\s(\s|\.|\,))"
shape (Tensor),"The number of elements in eachdimensionof a
tensor. The shape is represented as a list of integers. For example,
the following two-dimensional tensor has a shape of [3,4]: TensorFlow uses row-major (C-style) format to represent the order of
dimensions, which is why the shape in TensorFlow is[3,4]rather than[4,3]. In other words, in a two-dimensional TensorFlow Tensor, the shape
is[number of rows,number of columns]. Astatic shapeis a tensor shape that isknownat compile time. Adynamic shapeisunknownat compile time and is
therefore dependent on runtime data. This tensor might be represented with a
placeholder dimension in TensorFlow, as in[3, ?].",,"['dimensions', 'dynamic', 'static', 'Tensor', 'TensorFlow', 'Tensor shape']",,false,"(shape(\s|-)?|\s(\s|\.|\,))"
size invariance,"In an image classification problem, an algorithm's ability to successfully
classify images even when the size of the image changes. For example,
the algorithm can still identify a
cat whether it consumes 2M pixels or 200K pixels. Note that even the best
image classification algorithms still have practical limits on size invariance.
For example, an algorithm (or human) is unlikely to correctly classify a
cat image consuming only 20 pixels. See alsotranslational invarianceandrotational invariance.",,"['class', 'rotational invariance', 'translational invariance']",,false,"(size(\s|-)?invariance|\s(\s|\.|\,))"
concept drift,"A shift in the relationship between features and the label.
Over time, concept drift reduces a model's quality. During training, the model learns the relationship between the features and
their labels in the training set. If the labels in the training set are
good proxies for the real-world, then the modelshouldmake good
real world predictions. However, due to concept drift, the model's
predictions tend to degrade over time. For example, consider abinary classificationmodel that predicts whether or not a certain car model is ""fuel efficient.""
That is, the features could be: while the label is either: However, the concept of ""fuel efficient car"" keeps
changing. A car model labeledfuel efficientin 1994 would almost certainly
be labelednot fuel efficientin 2024. A model suffering from concept drift
tends to make less and less useful predictions over time. Compare and contrast withnonstationarity. To compensate for concept drift, retrain models faster than therateof
concept drift. For example, if concept drift reduces model precision by a
meaningful margin every two months, then retrain your model more frequently
than every two months.",,"['binary classification', 'class', 'feature', 'label', 'model', 'nonstationarity', 'precision', 'prediction', 'stationarity', 'training', 'training set']",,false,"(concept(\s|-)?drift|\s(\s|\.|\,))"
confirmation bias,"The tendency to search for, interpret, favor, and recall information in a
way that confirms one's pre-existing beliefs or hypotheses.
Machine learning developers may inadvertently collect or label
data in ways that influence an outcome supporting their existing
beliefs. Confirmation bias is a form ofimplicit bias. Experimenter's biasis a form of confirmation bias in which
an experimenter continues training models until a pre-existing
hypothesis is confirmed.",,"[""experimenter's bias"", 'implicit bias', 'label', 'machine learning', 'model', 'recall', 'training']",,false,"(confirmation(\s|-)?bia|\s(\s|\.|\,))"
full softmax,Synonym forsoftmax. Contrast withcandidate sampling. ,,"['candidate sampling', 'softmax']",softmax,true,"(full(\s|-)?softmax|\ssoftmax(\s|\.|\,))"
model router,"The algorithm that determines the ideal model for inference in model cascading.
A model router is itself typically a machine learning model that gradually learns how to pick the best model for a given input.
However, a model router could sometimes be a simpler, non-machine learning algorithm. ",,"['inference', 'machine learning', 'model', 'model cascading']",,false,"(model(\s|-)?router|\s(\s|\.|\,))"
area under the PR curve,SeePR AUC (Area under the PR Curve). ,,"['PR AUC (area under the PR curve)']",,false,"(area(\s|-)?under(\s|-)?the(\s|-)?PR(\s|-)?curve|\s(\s|\.|\,))"
sketching,"A category of unsupervised learning algorithms that perform a preliminary similarity analysis on examples. ‚Ä®Sketching algorithms use a locality-sensitive hash function to identify points that are likely to be similar, and then group them into buckets. ‚Ä®‚Ä®Sketching decreases the computation required for similarity calculations
on large datasets. Instead of calculating similarity for every single pair of examples in the dataset, we calculate similarity only for each pair of points within each bucket.",,"['machine learning', 'supervised machine learning', 'unsupervised machine learning']",,false,"(sketch|\s(\s|\.|\,))"
node (TensorFlow graph),An operation in a TensorFlowgraph. ,,"['graph', 'Tensor', 'TensorFlow']",,false,"(node(\s|-)?|\s(\s|\.|\,))"
skip-gram,"Ann-gramwhich may omit (or ""skip"") words from the original
context, meaning the N words might not have been originally adjacent. More
precisely, a ""k-skip-n-gram"" is an n-gram for which up to k words may have
been skipped. For example, ""the quick brown fox"" has the following possible 2-grams: A ""1-skip-2-gram"" is a pair of words that have at most 1 word between them.
Therefore, ""the quick brown fox"" has the following 1-skip 2-grams: In addition, all the 2-grams arealso1-skip-2-grams, since fewer
than one word may be skipped. Skip-grams are useful for understanding more of a word's surrounding context.
In the example, ""fox"" was directly associated with ""quick"" in the set of
1-skip-2-grams, but not in the set of 2-grams. Skip-grams help trainword embeddingmodels.",,"['model', 'N-gram', 'word embedding']",,false,"(skip(\s|-)?gram|\s(\s|\.|\,))"
sigmoid function,"A mathematical function that ""squishes"" an input value into a constrained range,
typically 0 to 1 or -1 to +1. That is, you can pass any number (two, a million,
negative billion, whatever) to a sigmoid and the output will still be in the
constrained range.
A plot of the sigmoid activation function looks as follows:  The sigmoid function has several uses in machine learning, including: The sigmoid function over an input numberxhas the following formula: In machine learning,xis generally aweighted sum.",,"['activation function', 'machine learning', 'weight', 'weighted sum', 'Tensor Processing Unit']",,false,"(sigmoid(\s|-)?funct|\s(\s|\.|\,))"
soft prompt tuning,"A technique for tuning a large language model for a particular task, without resource intensive fine-tuning. Instead of retraining all theweights in the model, soft prompt tuning
automatically adjusts a prompt to achieve the same goal. Given a textual prompt, soft prompt tuning typically appends additional token embeddings to the prompt and uses backpropagation to optimize the input.",,"['backpropagation', 'language model', 'large language model', 'model', 'prompt', 'prompt tuning', 'task', 'token', 'training', 'weight']",,false,"(soft(\s|-)?prompt(\s|-)?tun|\s(\s|\.|\,))"
artificial general intelligence,"A non-human mechanism that demonstrates abroad rangeof problem solving,
creativity, and adaptability. For example, a program demonstrating artificial
general intelligence could translate text, compose symphonies,andexcel at
games that have not yet been invented.",,[],,false,"(artificial(\s|-)?general(\s|-)?intelligence|\s(\s|\.|\,))"
artificial intelligence,"A non-human program ormodelthat can solve sophisticated tasks.
For example, a program or model that translates text or a program or model that
identifies diseases from radiologic images both exhibit artificial intelligence. Formally,machine learningis a sub-field of artificial
intelligence. However, in recent years, some organizations have begun using the
termsartificial intelligenceandmachine learninginterchangeably.",,"['machine learning', 'model', 'task']",,false,"(artificial(\s|-)?intelligence|\s(\s|\.|\,))"
fairness constraint,,,[],,false,"(fairness(\s|-)?constraint|\s(\s|\.|\,))"
fairness metric,"A mathematical definition of ""fairness"" that is measurable.
Some commonly used fairness metrics include: Many fairness metrics are mutually exclusive; seeincompatibility of fairness metrics.",,"['incompatibility of fairness metrics', 'metric']",,false,"(fairness(\s|-)?metric|\s(\s|\.|\,))"
shrinkage,"A hyperparameter in gradient boosting that controls overfitting. Shrinkage in gradient boosting
is analogous tolearning rateingradient descent. Shrinkage is a decimal
value between 0.0 and 1.0. A lower shrinkage value reduces overfitting
more than a larger shrinkage value.",,"['boosting', 'gradient', 'gradient boosting', 'gradient descent', 'hyperparameter', 'learning rate', 'overfitting', 'parameter']",,false,"(shrinkage|\s(\s|\.|\,))"
shard,"A logical division of the training set or the model. Typically, some process creates shards by dividing
the examples or parameters into (usually) equal-sized chunks. Each shard is then assigned to a different machine. Sharding a model is called model parallelism;
sharding data is called data parallelism.",,"['data parallelism', 'model', 'model parallelism', 'parameter', 'training', 'training set']",,false,"(shard|\s(\s|\.|\,))"
feature spec,"Describes the information required to extractfeaturesdata
from thetf.Exampleprotocol buffer. Because the
tf.Example protocol buffer is just a container for data, you must specify
the following:",,"['feature']",,false,"(feature(\s|-)?spec|\s(\s|\.|\,))"
sparse representation,"Storing only theposition(s)of nonzero elements in a sparse feature. For example, suppose a categorical feature namedspeciesidentifies the 36
tree species in a particular forest. Further assume that eachexampleidentifies only a single species. You could use a one-hot vector to represent the tree species in each example.
A one-hot vector would contain a single1(to represent
the particular tree species in that example) and 350s (to represent the
35 tree speciesnotin that example). So, the one-hot representation
ofmaplemight look something like the following:  Alternatively, sparse representation would simply identify the position of the
particular species. Ifmapleis at position 24, then the sparse representation
ofmaplewould simply be: Notice that the sparse representation is much more compact than the one-hot
representation. Suppose each example in your model must represent the words‚Äîbut not
the order of those words‚Äîin an English sentence.
English consists of about 170,000 words, so English is a categorical
feature with about 170,000 elements. Most English sentences use an
extremely tiny fraction of those 170,000 words, so the set of words in a
single example is almost certainly going to be sparse data. Consider the following sentence: You could use a variant of one-hot vector to represent the words in this
sentence. In this variant, multiple cells in the vector can contain
a nonzero value. Furthermore, in this variant, a cell can contain an integer
other than one. Although the words ""my"", ""is"", ""a"", and ""great"" appear only
once in the sentence, the word ""dog"" appears twice. Using this variant of
one-hot vectors to represent the words in this sentence yields the following
170,000-element vector:  A sparse representation of the same sentence would simply be: The term ""sparse representation"" confuses a lot of people because sparse
representation is itselfnot a sparse vector. Rather, sparse
representation is actually adense representation of a sparse vector.
The synonymindex representationis a little clearer than
""sparse representation.""",,"['action', 'feature', 'model', 'representation', 'sparse feature', 'sparse vector', 'vector']",,false,"(sparse(\s|-)?representat|\s(\s|\.|\,))"
sparsity,"The number of elements set to zero (or null) in a vector or matrix divided
by the total number of entries in that vector or matrix. For example,
consider a 100-element matrix in which 98 cells contain zero. The calculation of
sparsity is as follows: Feature sparsityrefers to the sparsity of a feature vector;model sparsityrefers to the sparsity of the model weights.",,"['feature', 'feature vector', 'model', 'vector', 'weight']",,false,"(sparsity|\s(\s|\.|\,))"
nonlinear,"A relationship between two or more variables that can't be represented solely
through addition and multiplication. Alinearrelationship
can be represented as a line; anonlinearrelationship can't be
represented as a line. For example, consider two models that each relate
a single feature to a single label. The model on the left is linear
and the model on the right is nonlinear:",,"['feature', 'label', 'linear', 'model', 'online']",,false,"(nonlinear|\s(\s|\.|\,))"
prediction bias,"A value indicating how far apart the average ofpredictionsis from the average oflabelsin the dataset. Not to be confused with thebias termin machine learning models
or withbias in ethics and fairness. ",,"['label', 'machine learning', 'model', 'prediction', 'retrieval-augmented generation']",,false,"(prediction(\s|-)?bia|\s(\s|\.|\,))"
rank (ordinality),"The ordinal position of a class in a machine learning problem that categorizes
classes from highest to lowest. For example, a behavior ranking
system could rank a dog's rewards from highest (a steak) to
lowest (wilted kale).",,"['class', 'machine learning', 'ranking', 'reward']",,false,"(rank(\s|-)?|\s(\s|\.|\,))"
ranking,"A type ofsupervised learningwhose
objective is to order a list of items. ",,"['items', 'objective']",,false,"(ranking|\s(\s|\.|\,))"
attention,"A mechanism used in aneural networkthat indicates
the importance of a particular word or part of a word. Attention compresses
the amount of information a model needs to predict the next token/word.
A typical attention mechanism might consist of aweighted sumover a set of inputs, where theweightfor each input is computed by another part of the
neural network. Refer also toself-attentionandmulti-head self-attention, which are the
building blocks ofTransformers.",,"['model', 'multi-head self-attention', 'neural network', 'token', 'Transformer', 'weight', 'weighted sum']",,false,"(attent|\s(\s|\.|\,))"
ablation,"A technique for evaluating the importance of a featureor component by temporarily removingit from a model. You then retrain the model without that feature or component, and if the retrained model
performs significantly worse, then the removed feature or component was
likely important. ",,"['class', 'classification model', 'feature', 'instance', 'model', 'performance', 'precision', 'test', 'test set']",,false,"(ablation|\s(\s|\.|\,))"
squared loss,Synonym forL2loss.,,"['L2loss', 'loss']",l2loss,true,"(squared(\s|-)?los|\sL2loss(\s|\.|\,))"
termination condition,"In reinforcement learning, the conditions that determine when an episode ends, such as when the agent reaches a certain state or exceeds a threshold number of state transitions.
For example, intic-tac-toe(also
known as noughts and crosses), an episode terminates either when a player marks
three consecutive spaces or when all spaces are marked.",,"['agent', 'condition', 'episode', 'layer', 'state']",,false,"(termination(\s|-)?condit|\s(\s|\.|\,))"
binary condition,"In adecision tree, aconditionthat has only two possible outcomes, typicallyyesorno.
For example, the following is a binary condition: Contrast withnon-binary condition. ",,"['condition', 'decision tree', 'non-binary condition']",,false,"(binary(\s|-)?condit|\s(\s|\.|\,))"
static inference,Synonym for offline inference.,,"['inference', 'offline', 'offline inference']",offline inference,true,"(static(\s|-)?inference|\soffline inference(\s|\.|\,))"
feedforward neural network (FFN),"A neural network without cyclic or recursive connections. For example,
traditionaldeep neural networksare
feedforward neural networks. Contrast withrecurrent neural
networks, which are cyclic. ",FFN,"['deep neural network', 'neural network']",,false,"(feedforward(\s|-)?neural(\s|-)?network(\s|-)?()|\sFFN(\s|\.|\,)|\s(\s|\.|\,))"
stationarity,"A feature whose values don't change across one or more dimensions, usually time.
For example, a feature whose values look about the same in 2021 and
2023 exhibits stationarity. In the real world, very few features exhibit stationarity. Even features
synonymous with stability (like sea level) change over time. Contrast withnonstationarity. ",,"['dimensions', 'feature', 'nonstationarity']",,false,"(stationarity|\s(\s|\.|\,))"
stride,"In a convolutional operation or pooling, the delta in each dimension of the
next series of input slices. For example, the following animation
demonstrates a (1,1) stride during a convolutional operation. Therefore,
the next input slice starts one position to the right of the previous input
slice. When the operation reaches the right edge, the next slice is all
the way over to the left but one position down.  The preceding example demonstrates a two-dimensional stride. If the input
matrix is three-dimensional, the stride would also be three-dimensional. ",,"['convolution', 'convolutional operation', 'pooling', 'intersection over union']",,false,"(stride|\s(\s|\.|\,))"
step,A forward pass and backward pass of one batch. See backpropagation.,,"['backpropagation', 'batch']",,false,"(step|\s(\s|\.|\,))"
pure function,"A function whose outputs are based only on its inputs, and that has no side
effects. Specifically, a pure function doesn't use or change any global state,
such as the contents of a file or the value of a variable outside the function. Pure functions can be used to create thread-safe code, which is beneficial
when shardingmodelcode across multipleaccelerator chips. JAX'sfunction transformation methods require
that the input functions are pure functions. ",,"['accelerator chip', 'function transformation', 'JAX', 'model', 'shard', 'state', 'Tensor Processing Unit']",,false,"(pure(\s|-)?funct|\s(\s|\.|\,))"
"experimenter's bias",Seeconfirmation bias.,,"['confirmation bias']",,false,"(experimenter's(\s|-)?bia|\s(\s|\.|\,))"
state-action value function,Synonym for Q-function.,,"['Q-function']",q-function,true,"(state(\s|-)?action(\s|-)?value(\s|-)?funct|\sQ-function(\s|\.|\,))"
structural risk minimization (SRM),"An algorithm that balances two goals: e.g.  a function that minimizes both loss and regularization on the training set.
Contrast with empirical risk minimization.",,"['loss', 'regularization', 'training', 'training set']",,false,"(structural(\s|-)?risk(\s|-)?minimization(\s|-)?|\s(\s|\.|\,))"
stochastic gradient descent (SGD),A gradient descent algorithm in which a single example is randomly chosen from the training set i.e. the batch size is one.,,"['batch', 'batch size', 'gradient', 'gradient descent', 'training', 'training set']",,false,"(stochastic(\s|-)?gradient(\s|-)?descent(\s|-)?|\s(\s|\.|\,))"
step size,Synonym for learning rate.,,"['learning rate']",learning rate,true,"(step(\s|-)?size|\slearning rate(\s|\.|\,))"
target network,"In Deep Q-learning, a neural network that is a stable approximation of the main neural network, where the main neural network
implements either a Q-function or a policy.
Then, you can train the main network on the Q-values predicted by the target
network. Therefore, you prevent the feedback loop that occurs when the main
network trains on Q-values predicted by itself. By avoiding this feedback,
training stability increases. ",,"['feedback loop', 'neural network', 'policy', 'Q-function', 'Q-learning', 'target', 'training']",,false,"(target(\s|-)?network|\s(\s|\.|\,))"
threshold (for decision trees),"In an axis-aligned condition, the value that afeatureis being compared against. For example, 75 is the
threshold value in the following condition:",,"['axis-aligned condition', 'condition', 'feature']",,false,"(threshold(\s|-)?|\s(\s|\.|\,))"
constituency parsing,"Dividing a sentence into smaller grammatical structures (""constituents"").
A later part of the ML system, such as anatural language understandingmodel,
can parse the constituents more easily than the original sentence. For example,
consider the following sentence: My friend adopted two cats. A constituency parser can divide this sentence into the following
two constituents: These constituents can be further subdivided into smaller constituents.
For example, the verb phrase adopted two cats could be further subdivided into:",,"['model', 'natural language understanding']",,false,"(constituency(\s|-)?pars|\s(\s|\.|\,))"
input layer,"Thelayerof aneural networkthat
holds thefeature vector. That is, the input layer
providesexamplesfortrainingorinference. For example, the input layer in the following
neural network consists of two features:",,"['feature', 'feature vector', 'inference', 'layer', 'neural network', 'training', 'vector']",,false,"(input(\s|-)?layer|\s(\s|\.|\,))"
gradient,"The vector ofpartial derivativeswith respect to
all of the independent variables. In machine learning, the gradient is
the vector of partial derivatives of the model function. The gradient points
in the direction of steepest ascent. ",,"['machine learning', 'model', 'partial derivative', 'vector']",,false,"(gradient|\s(\s|\.|\,))"
graph,"In TensorFlow, a computation specification. Nodes in the graph
represent operations. Edges are directed and represent passing the result
of an operation (aTensor) as an
operand to another operation. UseTensorBoardto visualize a graph.",,"['Tensor', 'TensorBoard', 'TensorFlow']",,false,"(graph|\s(\s|\.|\,))"
graph execution,,,[],,false,"(graph(\s|-)?execut|\s(\s|\.|\,))"
test loss,"Ametricrepresenting a model'slossagainst
thetest set. When building amodel, you
typically try to minimize test loss. That's because a low test loss is a
stronger quality signal than a lowtraining lossor
lowvalidation loss. A large gap between test loss and training loss or validation loss sometimes
suggests that you need to increase theregularization rate. ",,"['loss', 'metric', 'model', 'regularization', 'regularization rate', 'test', 'test set', 'training', 'training loss', 'validation', 'validation loss']",,false,"(test(\s|-)?los|\s(\s|\.|\,))"
operation (op),"In TensorFlow, any procedure that creates,
manipulates, or destroys aTensor. For
example, a matrix multiply is an operation that takes two Tensors as
input and generates one Tensor as output. ",,"['Tensor', 'TensorFlow', 'Tensor Processing Unit']",,false,"(operation(\s|-)?|\s(\s|\.|\,))"
pandas,"A column-oriented data analysis API built on top ofnumpy.
Many machine learning frameworks,
including TensorFlow, support pandas data structures as inputs. See thepandas documentationfor details.",,"['data analysis', 'machine learning', 'NumPy', 'Tensor', 'TensorFlow']",,false,"(pandas|\s(\s|\.|\,))"
test set,"A subset of thedatasetreserved for testing
a trainedmodel. Traditionally, you divide examples in the dataset into the following three
distinct subsets: Each example in a dataset should belong to only one of the preceding subsets.
For instance, a single example shouldn't belong to both the training set and
the test set. The training set and validation set are both closely tied to training a model.
Because the test set is only indirectly associated with training,test lossis a less biased, higher quality metric thantraining lossorvalidation loss.",,"['instance', 'loss', 'metric', 'model', 'test', 'test loss', 'training', 'training loss', 'training set', 'validation', 'validation loss', 'validation set']",,false,"(test(\s|-)?set|\s(\s|\.|\,))"
tf.keras,An implementation ofKerasintegrated intoTensorFlow.,,"['Keras', 'Tensor', 'TensorFlow']",,false,"(tf.keras|\s(\s|\.|\,))"
time series analysis,"A subfield of machine learning and statistics that analyzestemporal data. Many types of machine learning
problems require time series analysis, including classification, clustering,
forecasting, and anomaly detection. For example, you could use
time series analysis to forecast the future sales of winter coats by month
based on historical sales data.",,"['anomaly detection', 'class', 'clustering', 'machine learning', 'temporal data']",,false,"(time(\s|-)?series(\s|-)?analysi|\s(\s|\.|\,))"
timestep,"One ""unrolled"" cell within arecurrent neural network.
For example, the following figure shows three timesteps (labeled with
the subscripts t-1, t, and t+1):",,"['label', 'neural network', 'recurrent neural network', 'step']",,false,"(timestep|\s(\s|\.|\,))"
training-serving skew,"The difference between a model's performance duringtrainingand that same model's performance duringserving.",,"['model', 'performance', 'serving', 'training']",,false,"(training(\s|-)?serving(\s|-)?skew|\s(\s|\.|\,))"
pipeline,"The infrastructure surrounding a machine learning algorithm. A pipeline
includes gathering the data, putting the data into training data files, training one or more models, and exporting the models to production.",,"['machine learning', 'model', 'training']",,false,"(pipeline|\s(\s|\.|\,))"
convolution,"In machine learning, a convolution mixes the convolutional filter and the input matrix
in order to train weights. 
The term ""convolution"" in machine learning is often a synonym for either a convolutional operation or convolutional layer. 
Without convolutions, a machine learning algorithm would have to learn a separate weight for every cell in a large tensor. For example, a machine learning algorithm training on 2K x 2K images would be forced to
find 4M separate weights. Thanks to convolutions, a machine learning
algorithm only has to find weights for every cell in theconvolutional filter, dramatically reducing
the memory needed to train the model. When the convolutional filter is
applied, it is simply replicated across cells such that each is multiplied
by the filter.",,"['convolutional filter', 'convolutional layer', 'convolutional operation', 'layer', 'machine learning', 'model', 'replica', 'Tensor', 'training', 'weight']",,false,"(convolut|\s(\s|\.|\,))"
partitioning strategy,The algorithm by which variables are divided across parameter servers. ,,"['parameter']",,false,"(partitioning(\s|-)?strategy|\s(\s|\.|\,))"
trajectory,"In reinforcement learning, a sequence of tuples that represent a sequence of state transitions of the agent,
where each tuple corresponds to the state,action,reward, and next state for a given state transition. ",,"['action', 'agent', 'reward', 'state']",,false,"(trajectory|\s(\s|\.|\,))"
translational invariance,"In an image classification problem, an algorithm's ability to successfully
classify images even when the position of objects within the image changes.
For example, the algorithm can still identify a dog, whether it is in the
center of the frame or at the left end of the frame. See alsosize invarianceandrotational invariance.",,"['class', 'rotational invariance', 'size invariance']",,false,"(translational(\s|-)?invariance|\s(\s|\.|\,))"
true negative (TN),"An example in which the modelcorrectlypredicts thenegative class. For example, the model infers that
a particular email message isnot spam, and that email message really isnot spam.",,"['class', 'model', 'negative class']",,false,"(true(\s|-)?negative(\s|-)?|\s(\s|\.|\,))"
true positive (TP),"An example in which the modelcorrectlypredicts thepositive class. For example, the model infers that
a particular email message is spam, and that email message really is spam.",,"['class', 'model', 'positive class']",,false,"(true(\s|-)?positive(\s|-)?|\s(\s|\.|\,))"
unawareness (to a sensitive attribute),"A situation in whichsensitive attributesare
present, but not included in the training data. Because sensitive attributes
are often correlated with other attributes of one's data, a model trained
with unawareness about a sensitive attribute could still havedisparate impactwith respect to that attribute,
or violate otherfairness constraints.",,"['attribute', 'disparate impact', 'fairness constraint', 'model', 'sensitive attribute', 'training']",,false,"(unawareness(\s|-)?|\s(\s|\.|\,))"
items,"In arecommendation system, the entities that
a system recommends. For example, videos are the items that a video store
recommends, while books are the items that a bookstore recommends.",,"['recommendation system']",,false,"(items|\s(\s|\.|\,))"
partial derivative,"A derivative in which all but one of the variables is considered a constant.
For example, the partial derivative off(x, y)with respect toxis the
derivative offconsidered as a function ofxalone (that is, keepingyconstant). The partial derivative offwith respect toxfocuses only on
howxis changing and ignores all other variables in the equation.",,[],,false,"(partial(\s|-)?derivative|\s(\s|\.|\,))"
perceptron,"A system (either hardware or software) that takes in one or more input values,
runs a function on the weighted sum of the inputs, and computes a single
output value. In machine learning, the function is typically nonlinear, such asReLU,sigmoid, ortanh.
For example, the following perceptron relies on the sigmoid function to process
three input values: In the following illustration, the perceptron takes three inputs, each of which
is itself modified by a weight before entering the perceptron:  Perceptrons are theneuronsinneural networks. ",,"['linear', 'machine learning', 'neural network', 'neuron', 'nonlinear', 'online', 'sigmoid function', 'weight', 'weighted sum', 'Rectified Linear Unit', 'Tensor Processing Unit']",,false,"(perceptron|\s(\s|\.|\,))"
performance,Overloaded term with the following meanings:,,[],,false,"(performance|\s(\s|\.|\,))"
policy,"In reinforcement learning, anagent'sprobabilistic mapping
fromstatestoactions.",,"['action', 'agent', 'state', 'test']",,false,"(policy|\s(\s|\.|\,))"
squared hinge loss,"The square of thehinge loss. Squared hinge loss penalizes
outliers more harshly than regular hinge loss.",,"['hinge loss', 'loss', 'outliers']",,false,"(squared(\s|-)?hinge(\s|-)?los|\s(\s|\.|\,))"
undersampling,"Removingexamplesfrom themajority classin aclass-imbalanced datasetin order to
create a more balancedtraining set. For example, consider a dataset in which the ratio of the majority class to
theminority classis 20:1. To overcome this class
imbalance, you could create a training set consisting ofallof the minority
class examples but only atenthof the majority class examples, which would
create a training-set class ratio of 2:1. Thanks to undersampling, this more
balanced training set might produce a better model. Alternatively, this
more balanced training set might contain insufficient examples to train an
effective model. Contrast withoversampling.",,"['class', 'class-imbalanced dataset', 'imbalanced dataset', 'majority class', 'minority class', 'model', 'oversampling', 'training', 'training set']",,false,"(undersampl|\s(\s|\.|\,))"
imputation,Short form of value imputation.,,"['value imputation']",,false,"(imputat|\s(\s|\.|\,))"
derived label,Synonym for proxy label.,,"['label']",proxy label,true,"(derived(\s|-)?label|\sproxy label(\s|\.|\,))"
convolutional layer,"A layer of adeep neural networkin which aconvolutional filterpasses along an input
matrix. For example, consider the following 3x3convolutional filter:  The following animation shows a convolutional layer consisting of 9
convolutional operations involving the 5x5 input matrix. Notice that each
convolutional operation works on a different 3x3 slice of the input matrix.
The resulting 3x3 matrix (on the right) consists of the results of the 9
convolutional operations:",,"['convolution', 'convolutional filter', 'convolutional operation', 'deep neural network', 'layer', 'neural network']",,false,"(convolutional(\s|-)?layer|\s(\s|\.|\,))"
true positive rate,Synonym for recall. That is: True positive rate is the y-axis in anROC curve. ,TPR,"['recall']",recall,true,"(true(\s|-)?positive(\s|-)?rate|\sTPR(\s|\.|\,)|\srecall(\s|\.|\,))"
unsupervised learning,"Training a model to find patterns in a (typically) unlabeled dataset.‚Ä®‚Ä®The most common use of unsupervised machine learning is toclusterdata
into groups of similar examples. For example, an unsupervised machine
learning algorithm can cluster songs based on various properties
of the music. The resulting clusters can become an input to other machine
learning algorithms (for example, to a music recommendation service).
Clustering can help when useful labels are scarce or absent.
For example, in domains such as anti-abuse and fraud, clusters can help
humans better understand the data. Contrast withsupervised machine learning. Another example of unsupervised machine learning isprincipal component analysis (PCA).
For example, applying PCA on a
dataset containing the contents of millions of shopping carts might reveal
that shopping carts containing lemons frequently also contain antacids. ",,"['clustering', 'label', 'machine learning', 'model', 'supervised machine learning', 'training', 'intersection over union']",,false,"(unsupervised(\s|-)?machine(\s|-)?learn|\s(\s|\.|\,))"
attribute sampling,"A tactic for training adecision forestin which eachdecision treeconsiders only a random subset of possiblefeatureswhen learning thecondition.
Generally, a different subset of features is sampled for eachnode. In contrast, when training a decision tree
without attribute sampling, all possible features are considered for each node.",,"['attribute', 'condition', 'decision forest', 'decision tree', 'feature', 'training']",,false,"(attribute(\s|-)?sampl|\s(\s|\.|\,))"
unidirectional language model,"Alanguage modelthat bases its probabilities only on thetokensappearingbefore, notafter, the target token(s).
Contrast withbidirectional language model.",,"['bidirectional', 'bidirectional language model', 'language model', 'model', 'target', 'token']",,false,"(unidirectional(\s|-)?language(\s|-)?model|\scausal language model(\s|\.|\,))"
unlabeled example,"An example that containsfeaturesbut nolabel.
For example, the following table shows three unlabeled examples from a house
valuation model, each with three features but no house value: Insupervised machine learning,
models train on labeled examples and make predictions onunlabeled examples. Insemi-supervisedandunsupervisedlearning,
unlabeled examples are used during training. Contrast unlabeled example withlabeled example.",,"['feature', 'label', 'labeled example', 'machine learning', 'model', 'prediction', 'supervised machine learning', 'training']",,false,"(unlabeled(\s|-)?example|\s(\s|\.|\,))"
underfitting,"Producing amodelwith poor predictive ability because the model
hasn't fully captured the complexity of the training data. Many problems
can cause underfitting, including: ",,"['model', 'training']",,false,"(underfitt|\s(\s|\.|\,))"
training loss,"A metric representing a model's loss during a
particular training iteration. For example, suppose the loss function
is Mean Squared Error. Perhaps the training loss (the Mean
Squared Error) for the 10th iteration is 2.2, and the training loss for
the 100th iteration is 1.9. A loss curve plots training loss versus the number of
iterations. A loss curve provides the following hints about training: For example, the following somewhat idealizedloss curveshows:  Although training loss is important, see also generalization.",,"['generalization', 'iteration', 'loss', 'loss curve', 'loss function', 'metric', 'model', 'training']",,false,"(training(\s|-)?los|\s(\s|\.|\,))"
user matrix,"Inrecommendation systems, anembedding vectorgenerated bymatrix factorizationthat holds latent signals about user preferences.
Each row of the user matrix holds information about the relative
strength of various latent signals for a single user.
For example, consider a movie recommendation system. In this system,
the latent signals in the user matrix might represent each user's interest
in particular genres, or might be harder-to-interpret signals that involve
complex interactions across multiple factors. The user matrix has a column for each latent feature and a row for each user.
That is, the user matrix has the same number of rows as the target
matrix that is being factorized. For example, given a movie
recommendation system for 1,000,000 users, the
user matrix will have 1,000,000 rows. ",,"['action', 'embedding vector', 'feature', 'matrix factorization', 'recommendation system', 'target', 'vector', 'intersection over union']",,false,"(user(\s|-)?matrix|\s(\s|\.|\,))"
validation set,"The subset of thedatasetthat performs initial
evaluation against a trainedmodel. Typically, you evaluate
the trained model against thevalidation setseveral
times before evaluating the model against thetest set. Traditionally, you divide the examples in the dataset into the following three
distinct subsets: Ideally, each example in the dataset should belong to only one of the
preceding subsets. For example, a single example shouldn't belong to
both the training set and the validation set. ",,"['evaluation', 'model', 'test', 'test set', 'training', 'training set', 'validation']",,false,"(validation(\s|-)?set|\s(\s|\.|\,))"
zero-shot prompting,A prompt that does not provide an example of how you want the large language model to respond.,,"['language model', 'large language model', 'model', 'prompt']",,false,"(zero(\s|-)?shot(\s|-)?prompt|\sdirect prompting(\s|\.|\,))"
augmented reality,"A technology that superimposes a computer-generated image on a user's view of
the real world, thus providing a composite view.",AR,[],,false,"(augmented(\s|-)?reality|\sAR(\s|\.|\,)|\s(\s|\.|\,))"
batch,"The set of examples used in one training iteration.
The batch size determines the number of examples in a
batch. See epochfor an explanation of how a batch relates to an epoch.",,"['batch size', 'epoch', 'iteration', 'training']",,false,"(batch|\s(\s|\.|\,))"
variational autoencoder (VAE),"A type of autoencoder that leverages the discrepancy
between inputs and outputs to generate modified versions of the inputs.
Variational autoencoders are useful forgenerative AI. VAEs are based on variational inference: a technique for estimating the
parameters of a probability model. ",,"['autoencoder', 'encoder', 'generative AI', 'inference', 'model', 'parameter', 'retrieval-augmented generation', 'Tensor Processing Unit']",,false,"(variational(\s|-)?autoencoder(\s|-)?|\s(\s|\.|\,))"
automation bias,"When a human decision maker favors recommendations made by an automated
decision-making system over information made without automation, even
when the automated decision-making system makes errors. ",,[],,false,"(automation(\s|-)?bia|\s(\s|\.|\,))"
binary classification,"A type ofclassificationtask that
predicts one of two mutually exclusive classes: For example, the following two machine learning models each perform
binary classification: Contrast withmulti-class classification. See alsologistic regressionandclassification threshold.",,"['class', 'classification threshold', 'logistic regression', 'machine learning', 'model', 'multi-class classification', 'task']",,false,"(binary(\s|-)?classificat|\s(\s|\.|\,))"
convolutional operation,"The following two-step mathematical operation: For example, consider the following 5x5 input matrix:  Now imagine the following 2x2 convolutional filter:  Each convolutional operation involves a single 2x2 slice of the
input matrix. For example, suppose we use the 2x2 slice at the
top-left of the input matrix. So, the convolution operation on
this slice looks as follows:  Aconvolutional layerconsists of a
series of convolutional operations, each acting on a different slice
of the input matrix. ",,"['convolution', 'convolutional filter', 'convolutional layer', 'layer', 'step']",,false,"(convolutional(\s|-)?operat|\s(\s|\.|\,))"
convergence,"A state reached when loss values change very little or
not at all with each iteration.A model converges when additional training won't
improve the model.",,"['early stopping', 'iteration', 'loss', 'loss curve', 'model', 'state', 'training']",,false,"(convergence|\s(\s|\.|\,))"
validation,"The initial evaluation of a model's quality.
Validation checks the quality of a model's predictions against thevalidation set. Because the validation set differs from the training set,
validation helps guard againstoverfitting. You might think of evaluating the model against the validation set as the
first round of testing and evaluating the model against thetest setas the second round of testing.",,"['evaluation', 'model', 'overfitting', 'prediction', 'test', 'test set', 'training', 'training set', 'validation set']",,false,"(validat|\s(\s|\.|\,))"
vanishing gradient problem,"The tendency for the gradients of earlyhidden layersof somedeep neural networksto become
surprisingly flat (low). Increasingly lower gradients result in increasingly
smaller changes to the weights on nodes in a deep neural network, leading to
little or no learning. Models suffering from the vanishing gradient problem
become difficult or impossible to train.Long Short-Term Memorycells address this issue. Compare toexploding gradient problem.",,"['deep neural network', 'exploding gradient problem', 'gradient', 'hidden layer', 'layer', 'Long Short-Term Memory', 'model', 'neural network', 'weight']",,false,"(vanishing(\s|-)?gradient(\s|-)?problem|\s(\s|\.|\,))"
wisdom of the crowd,"The idea that averaging the opinions or estimates of a large group
of people (""the crowd"") often produces surprisingly good results.
For example, consider a game in which people guess the number of
jelly beans packed into a large jar. Although most individual
guesses will be inaccurate, the average of all the guesses has been
empirically shown to be surprisingly close to the actual number of
jelly beans in the jar. Ensemblesare a software analog of wisdom of the crowd.
Even if individual models make wildly inaccurate predictions,
averaging the predictions of many models often generates surprisingly
good predictions. For example, although an individualdecision treemight make poor predictions, adecision forestoften makes very good predictions.",,"['decision forest', 'decision tree', 'ensemble', 'model', 'prediction', 'retrieval-augmented generation']",,false,"(wisdom(\s|-)?of(\s|-)?the(\s|-)?crowd|\s(\s|\.|\,))"
cross-validation,"A mechanism for estimating how well amodelwould generalize to
new data by testing the model against one or more non-overlapping data subsets
withheld from thetraining set. ",,"['model', 'test', 'training', 'training set']",,false,"(cross(\s|-)?validat|\s(\s|\.|\,))"
cumulative distribution function (CDF),"A function that defines the frequency of samples less than or equal to a
target value. For example, consider a normal distribution of continuous values.
A CDF tells you that approximately 50% of samples should be less than or equal
to the mean and that approximately 84% of samples should be less than or equal
to one standard deviation above the mean. ",CDF,"['distribution', 'target']",,false,"(cumulative(\s|-)?distribution(\s|-)?function(\s|-)?()|\sCDF(\s|\.|\,)|\s(\s|\.|\,))"
data analysis,"Obtaining an understanding of data by considering samples, measurement,
and visualization. Data analysis can be particularly useful when a
dataset is first received, before one builds the firstmodel.
It is also crucial in understanding experiments and debugging problems with
the system.",,"['model']",,false,"(data(\s|-)?analysi|\s(\s|\.|\,))"
data augmentation,"Artificially boosting the range and number oftrainingexamples
by transforming existingexamplesto create additional examples. For example,
suppose images are one of yourfeatures, but your dataset doesn't
contain enough image examples for the model to learn useful associations.
Ideally, you'd add enoughlabeledimages to your dataset to
enable your model to train properly. If that's not possible, data augmentation
can rotate, stretch, and reflect each image to produce many variants of the
original picture, possibly yielding enough labeled data to enable excellent
training.",,"['boosting', 'feature', 'label', 'model', 'training']",,false,"(data(\s|-)?augmentat|\s(\s|\.|\,))"
decision boundary,"The separator betweenclasseslearned by amodelin abinary classormulti-class classification problems. For example,
in the following image representing a binary classification problem,
the decision boundary is the frontier between the orange class and
the blue class:",,"['binary classification', 'class', 'model', 'multi-class classification']",,false,"(decision(\s|-)?boundary|\s(\s|\.|\,))"
decoder,"In general, any ML system that converts from a processed, dense, or
internal representation to a more raw, sparse, or external representation. Decoders are often a component of a larger model, where they are frequently
paired with anencoder. Insequence-to-sequence tasks, a decoder
starts with the internal state generated by the encoder to predict the next
sequence. Refer toTransformerfor the definition of a decoder within
the Transformer architecture.",,"['encoder', 'model', 'representation', 'sequence-to-sequence task', 'state', 'task', 'Transformer']",,false,"(decoder|\s(\s|\.|\,))"
deep model,Aneural networkcontaining more than onehidden layer. A deep model is also called adeep neural network. Contrast withwide model. ,,"['deep neural network', 'hidden layer', 'layer', 'model', 'neural network', 'wide model']",,false,"(deep(\s|-)?model|\sdeep neural network(\s|\.|\,))"
linear,"A relationship between two or more variables that can be represented solely
through addition and multiplication. The plot of a linear relationship is a line. Contrast withnonlinear.",,"['nonlinear', 'online']",,false,"(linear|\s(\s|\.|\,))"
learning rate,"A hyperparameter in model training that tells the Optimizer (the gradient descent algorithm) how strongly to adjust weights and biases on each iteration e.g. a learning rate of 0.3 would
adjust weights and biases three times more powerfully/quickly than a learning rate
of 0.1. 
If you set the learning rate too low, training will take too long. If you set the learning rate too high, gradient descent often has trouble
reaching convergence. ‚Ä®During each iteration, the Optimizer multiplies the learning rate by the gradient. The resulting product is called the 'Gradient Step'. ",,"['convergence', 'gradient', 'gradient descent', 'hyperparameter', 'iteration', 'parameter', 'step', 'training', 'weight']",,false,"(learning(\s|-)?rate|\sstep size(\s|\.|\,))"
demographic parity,"Afairness metricthat is satisfied if
the results of a model's classification are not dependent on a
givensensitive attribute. For example, if both Lilliputians and Brobdingnagians apply to
Glubbdubdrib University, demographic parity is achieved if the percentage
of Lilliputians admitted is the same as the percentage of Brobdingnagians
admitted, irrespective of whether one group is on average more qualified
than the other. Contrast withequalized oddsandequality of opportunity, which permit
classification results in aggregate to depend on sensitive attributes,
but don't permit classification results for certain specifiedground truthlabels to depend on sensitive attributes. See""Attacking
discrimination with smarter machine learning""for a visualization
exploring the tradeoffs when optimizing for demographic parity.",,"['attribute', 'class', 'equality of opportunity', 'equalized odds', 'fairness metric', 'graph', 'ground truth', 'label', 'machine learning', 'metric', 'model', 'sensitive attribute', 'retrieval-augmented generation']",,false,"(demographic(\s|-)?parity|\s(\s|\.|\,))"
denoising,"A common approach toself-supervised learningin which: Denoising enables learning fromunlabeled examples.
The originaldatasetserves as the target orlabeland
the noisy data as the input. Somemasked language modelsuse denoising
as follows:",,"['label', 'labeled example', 'language model', 'masked language model', 'model', 'self-supervised learning', 'target', 'unlabeled example']",,false,"(denois|\s(\s|\.|\,))"
metric,"A statistic that you care about. Anobjectiveis a metric that a machine learning system
tries to optimize. ",,"['machine learning', 'objective']",,false,"(metric|\s(\s|\.|\,))"
objective,A metric that your algorithm is trying to optimize. ,,"['metric']",,false,"(objective|\s(\s|\.|\,))"
generative adversarial network (GAN),"A system to create new data in which ageneratorcreates
data and adiscriminatordetermines whether that
created data is valid or invalid.",,"['discriminator', 'generator']",,false,"(generative(\s|-)?adversarial(\s|-)?network(\s|-)?|\s(\s|\.|\,))"
self-attention layer,"A neural network layer that transforms a sequence of
embeddings (for instance,tokenembeddings)
into another sequence of embeddings. Each embedding in the output sequence is
constructed by integrating information from the elements of the input sequence
through anattentionmechanism. Theselfpart ofself-attentionrefers to the sequence attending to
itself rather than to some other context. Self-attention is one of the main
building blocks forTransformersand uses dictionary lookup
terminology, such as ""query"", ""key"", and ""value"". A self-attention layer starts with a sequence of input representations, one
for each word. The input representation for a word can be a simple
embedding. For each word in an input sequence, the network
scores the relevance of the word to every element in the whole sequence of
words. The relevance scores determine how much the word's final representation
incorporates the representations of other words. For example, consider the following sentence: The animal didn't cross the street because it was too tired. The following illustration (fromTransformer: A Novel Neural Network Architecture for Language
Understanding)
shows a self-attention layer's attention pattern for the pronounit, with
the darkness of each line indicating how much each word contributes to the
representation:  The self-attention layer highlights words that are relevant to ""it"". In this
case, the attention layer has learned to highlight words thatitmight
refer to, assigning the highest weight toanimal. For a sequence ofntokens, self-attention transforms a sequence
of embeddingsnseparate times, once at each position in the sequence. Refer also toattentionandmulti-head self-attention. ",,"['attention', 'instance', 'layer', 'multi-head self-attention', 'neural network', 'representation', 'token', 'Transformer', 'weight', 'Tensor Processing Unit']",,false,"(self(\s|-)?attention(\s|-)?layer|\s(\s|\.|\,))"
semi-supervised learning,"Training a model on data where some of the training examples have labels but
others don't. One technique for semi-supervised learning is to infer labels for
the unlabeled examples, and then to train on the inferred labels to create a new
model. Semi-supervised learning can be useful if labels are expensive to obtain
but unlabeled examples are plentiful. Self-trainingis one technique for semi-supervised
learning. #fairnessA human attribute that may be given special consideration for legal,
ethical, social, or personal reasons.",,"['attribute', 'label', 'labeled example', 'model', 'self-training', 'training', 'unlabeled example']",,false,"(semi(\s|-)?supervised(\s|-)?learn|\s(\s|\.|\,))"
disparate impact,"Making decisions about people that impact different population
subgroups disproportionately. This usually refers to situations
where an algorithmic decision-making process harms or benefits
some subgroups more than others. For example, suppose an algorithm that determines a Lilliputian's
eligibility for a miniature-home loan is more likely to classify
them as ""ineligible"" if their mailing address contains a certain
postal code. If Big-Endian Lilliputians are more likely to have
mailing addresses with this postal code than Little-Endian Lilliputians,
then this algorithm may result in disparate impact. Contrast with disparate treatment,
which focuses on disparities that result when subgroup characteristics
are explicit inputs to an algorithmic decision-making process.",,"['class', 'disparate treatment']",,false,"(disparate(\s|-)?impact|\s(\s|\.|\,))"
cross-entropy,"A generalization of Log Loss to multi-class classification problems. Cross-entropy
quantifies the difference between two probability distributions. See also perplexity. ",,"['class', 'distribution', 'entropy', 'generalization', 'Log Loss', 'loss', 'multi-class classification', 'perplexity']",,false,"(cross(\s|-)?entropy|\s(\s|\.|\,))"
model training,The process of determining the bestmodel. ,,"['model']",,false,"(model(\s|-)?train|\s(\s|\.|\,))"
transfer learning,"Transferring information from one machine learning task to another.
For example, in multi-task learning, a single model solves multiple tasks,
such as a deep modelthat has different output nodes for
different tasks. Transfer learning might involve transferring knowledge
from the solution of a simpler task to a more complex one, or involve
transferring knowledge from a task where there is more data to one where
there is less data. Most machine learning systems solve asingletask. Transfer learning is a
baby step towards artificial intelligence in which a single program can solvemultipletasks.",,"['artificial intelligence', 'deep model', 'machine learning', 'model', 'step', 'task', 'Tensor Processing Unit']",,false,"(transfer(\s|-)?learn|\s(\s|\.|\,))"
Softmax Function,"A function that determines probabilities for each possible class in amulti-class classification model. The probabilities add up
to exactly 1.0. For example, the following table shows how softmax distributes
various probabilities: Softmax is also calledfull softmax. Contrast withcandidate sampling. The softmax equation is as follows: For example, suppose the input vector is: Therefore, softmax calculates the denominator as follows: The softmax probability of each element is therefore: So, the output vector is therefore: The sum of the three elements in $\sigma$ is 1.0. Phew!",,"['candidate sampling', 'class', 'classification model', 'full softmax', 'model', 'multi-class classification', 'vector', 'intersection over union', 'Tensor Processing Unit']",,false,"(Softmax(\s|-)?Funct|\sfull softmax(\s|\.|\,))"
Mixed Precision,"Automatic Mixed Precision (AMP) is another very simple way of reducing memory consumption and training time without losing final quality, which was introduced in ""Mixed Precision Training"" paper by NVIDIA and Baidu researchers in 2017. The key idea behind the approach is to use lower precision for keeping the model's gradients and parameters in the memory, i.e instead of using full precision (e.g float32) the proposed approach uses half-precision (e.g float16) for keeping tensors in memory. However, when computing gradients in lower precision, some values can be so small that they are treated as zeros, this phenomenon is called ""overflow"". In order to prevent ""overflow"", the authors of the original paper proposed a gradient scaling method.

PyTorch provides a package with necessary functionality (from lowering precision to gradient scaling) for using Automatic Mixed Precision, called torch.cuda.amp. Automatic Mixed Precision was implemented as a context manager, so it can easily be inserted in training and inferencing scripts.",,"['optimization']",,,(Mixed(\s|-)?Precis)
Mean Squared Error (MSE),"The average loss per example whenL2lossis
used. Calculate Mean Squared Error as follows: For example, consider the loss on the following batch of five examples: Therefore, the Mean Squared Error is: Mean Squared Error is a popular trainingoptimizer,
particularly forlinear regression. Contrast Mean Squared Error withMean Absolute ErrorandRoot Mean Squared Error. TensorFlow Playgrounduses Mean Squared Error
to calculate loss values. Outliersstrongly influence Mean Squared Error.
For example, a loss of 1 is a squared loss of 1, but a loss of 3 is a
squared loss of 9. In the preceding table, the example with a loss of 3
accounts for ~56% of the Mean Squared Error, while each of the examples
with a loss of 1 accounts for only 6% of the Mean Squared Error. Outliers don't influence Mean Absolute Error as strongly as
Mean Squared Error. For example, a loss of 3 accounts for only ~38% of the
Mean Absolute Error. Clippingis one way to prevent extreme
outliers from damaging your model's predictive ability.",,"['batch', 'clipping', 'L2loss', 'linear', 'linear regression', 'loss', 'model', 'optimizer', 'outliers', 'root', 'squared loss', 'Tensor', 'TensorFlow', 'TensorFlow Playground', 'training', 'retrieval-augmented generation']",,false,"(Mean(\s|-)?Squared(\s|-)?Error(\s|-)?|\s(\s|\.|\,))"
normalization,"Broadly speaking, the process of converting a variable's actual range
of values into a standard range of values, such as: For example, suppose the actual range of values of a certain feature is
800 to 2,400. As part offeature engineering,
you could normalize the actual values down to a standard range, such
as -1 to +1. Normalization is a common task infeature engineering. Models usually train faster
(and produce better predictions) when every numerical feature in thefeature vectorhas roughly the same range. ",,"['feature', 'feature engineering', 'feature vector', 'model', 'prediction', 'task', 'vector']",,false,"(normalizat|\s(\s|\.|\,))"
disparate treatment,"Factoring subjects' sensitive attributes into an algorithmic decision-making process such that different subgroups
of people are treated differently. For example, consider an algorithm that
determines Lilliputians' eligibility for a miniature-home loan based on the
data they provide in their loan application. If the algorithm uses a
Lilliputian's affiliation as Big-Endian or Little-Endian as an input, it
is enacting disparate treatment along that dimension. Contrast withdisparate impact, which focuses
on disparities in the societal impacts of algorithmic decisions on subgroups,
irrespective of whether those subgroups are inputs to the model.",,"['attribute', 'disparate impact', 'model', 'sensitive attribute']",,false,"(disparate(\s|-)?treatment|\s(\s|\.|\,))"
rotational invariance,"In an image classification problem, an algorithm's ability to successfully
classify images even when the orientation of the image changes. For example,
the algorithm can still identify a tennis racket whether it is pointing up,
sideways, or down. Note that rotational invariance is not always desirable;
for example, an upside-down 9 shouldn't be classified as a 9. See also translational invariance and size invariance. ",,"['class', 'size invariance', 'translational invariance']",,false,"(rotational(\s|-)?invariance|\s(\s|\.|\,))"
role prompting,"An optional part of a prompt that identifies a target audience
for a generative AImodel's response.Without a role
prompt, a large language model provides an answer that may or may not be useful
for the person asking the questions. With a role prompt, a large language
model can answer in a way that's more appropriate and more helpful for a
specific target audience.",,"['generative AI', 'language model', 'large language model', 'model', 'prompt', 'target']",,false,"(role(\s|-)?prompt|\s(\s|\.|\,))"
subsampling,See pooling layer,,"['pooling']",,false,"(subsampl|\s(\s|\.|\,))"
distribution,"The frequency and range of different values for a givenfeatureorlabel.
A distribution captures how likely a particular value is. The following image shows histograms of two different distributions:  Understanding each feature and label's distribution can help you determine how
tonormalizevalues and detectoutliers. The phraseout of distributionrefers to a value that doesn't appear in the
dataset or is very rare. For example, an image of the planet Saturn would be
considered out of distribution for a dataset consisting of cat images.",,"['feature', 'label', 'outliers']",,false,"(distribut|\s(\s|\.|\,))"
decision forest,"A model created from multiple decision trees.
A decision forest makes a prediction by aggregating the predictions of its decision trees. Popular types of decision forests include random forests and gradient boosted trees. ",,"['decision tree', 'gradient', 'model', 'prediction', 'random forest']",,false,"(decision(\s|-)?forest|\s(\s|\.|\,))"
TensorStore,"A library for efficiently reading and
writing large multi-dimensional arrays.",,[],,false,"(TensorStore|\s(\s|\.|\,))"
non-binary condition,"Aconditioncontaining more than two possible outcomes.
For example, the following non-binary condition contains three possible
outcomes:",,"['binary condition', 'condition']",,false,"(non(\s|-)?binary(\s|-)?condit|\s(\s|\.|\,))"
non-response bias,Seeselection bias.,,"['selection bias']",,false,"(non(\s|-)?response(\s|-)?bia|\sparticipation bias(\s|\.|\,))"
embedding layer,"A hidden layerthat trains on a
highdimensional categorical feature to
gradually learn a lower dimension embedding vector. An
embedding layer enables a neural network to train far more
efficiently than training just on the high-dimensional categorical feature. For example, Earth currently supports about 73,000 tree species. Suppose
tree species is afeaturein your model, so your model's
input layer includes aone-hot vector73,000
elements long.
For example, perhapsbaobabwould be represented something like this:  A 73,000-element array is very long. If you don't add an embedding layer
to the model, training is going to be very time consuming due to
multiplying 72,999 zeros. Perhaps you pick the embedding layer to consist
of 12 dimensions. Consequently, the embedding layer will gradually learn
a new embedding vector for each tree species. In certain situations,hashingis a reasonable alternative
to an embedding layer.",,"['dimensions', 'embedding vector', 'feature', 'hashing', 'hidden layer', 'input layer', 'layer', 'model', 'neural network', 'training', 'vector']",,false,"(embedding(\s|-)?layer|\s(\s|\.|\,))"
root,"The startingnode(the firstcondition) in adecision tree.
By convention, diagrams put the root at the top of the decision tree.
For example:",,"['condition', 'decision tree']",,false,"(root|\s(\s|\.|\,))"
scalar,"A single number or a single string that can be represented as atensorofrank0. For example, the following
lines of code each create one scalar in TensorFlow: ",,"['Tensor', 'TensorFlow']",,false,"(scalar|\s(\s|\.|\,))"
scikit-learn,A popular open-source machine learning platform. Seescikit-learn.org.,,"['machine learning']",,false,"(scikit(\s|-)?learn|\s(\s|\.|\,))"
embedding vector,"Broadly speaking, an array of floating-point numbers taken fromanyhidden layerthat describe the inputs to that hidden layer.
Often, an embedding vector is the array of floating-point numbers trained in
an embedding layer. For example, suppose an embedding layer must learn an
embedding vector for each of the 73,000 tree species on Earth. Perhaps the
following array is the embedding vector for a baobab tree:  An embedding vector is not a bunch of random numbers. An embedding layer
determines these values through training, similar to the way a
neural network learns other weights during training. Each element of the
array is a rating along some characteristic of a tree species. Which
element represents which tree species' characteristic? That's very hard
for humans to determine. The mathematically remarkable part of an embedding vector is that similar
items have similar sets of floating-point numbers. For example, similar
tree species have a more similar set of floating-point numbers than
dissimilar tree species. Redwoods and sequoias are related tree species,
so they'll have a more similar set of floating-pointing numbers than
redwoods and coconut palms. The numbers in the embedding vector will
change each time you retrain the model, even if you retrain the model
with identical input. ",,"['embedding layer', 'hidden layer', 'items', 'layer', 'model', 'neural network', 'training', 'vector', 'weight']",,false,"(embedding(\s|-)?vector|\s(\s|\.|\,))"
F1-Score,"A ""roll-up""binary classification metric that
relies on both precision and recall.",,"['binary classification', 'class', 'fairness constraint', 'metric', 'precision', 'recall']",,false,"(F1(\s|-)?Score|\s(\s|\.|\,))"
online inference,"Generating predictions on demand. For example,
suppose an app passes input to a model and issues a request for a
prediction.
A system using online inference responds to the request by running
the model (and returning the prediction to the app). Contrast withoffline inference.",,"['inference', 'model', 'offline', 'offline inference', 'online', 'prediction', 'return']",,false,"(online(\s|-)?inference|\s(\s|\.|\,))"
outlier detection,The process of identifyingoutliersin atraining set. Contrast withnovelty detection. ,,"['novelty detection', 'outliers', 'training', 'training set']",,false,"(outlier(\s|-)?detect|\s(\s|\.|\,))"
scoring,"The part of arecommendation systemthat
provides a value or ranking for each item produced by thecandidate generationphase.",,"['candidate generation', 'ranking', 'recommendation system']",,false,"(scoring|\s(\s|\.|\,))"
scaling,"Any mathematical transform or technique that shifts the range of a label
and/or feature value. Some forms of scaling are very useful for transformations
like normalization. Common forms of scaling useful in Machine Learning include: ",,"['feature', 'label', 'machine learning', 'normalization']",,false,"(scaling|\s(\s|\.|\,))"
accuracy,"The number of correct classificationpredictionsdivided
by the total number of predictions. That is: For example, a model that made 40 correct predictions and 10 incorrect
predictions would have an accuracy of: Binary classificationprovides specific names
for the different categories ofcorrect predictionsandincorrect predictions. So, the accuracy formula for binary classification
is as follows: where: Compare and contrast accuracy withprecisionandrecall. Although a valuable metric for some situations, accuracy is highly
misleading for others. Notably, accuracy is usually a poor metric
for evaluating classification models that processclass-imbalanced datasets. For example, suppose snow falls only 25 days per century in a certain
subtropical city. Since days without snow (the negative class) vastly
outnumber days with snow (the positive class), the snow dataset for
this city is class-imbalanced.
Imagine abinary classificationmodel that is supposed to predict either snow or no snow each day but
simply predicts ""no snow"" every day.
This model is highly accurate but has no predictive power.
The following table summarizes the results for a century of predictions: The accuracy of this model is therefore: Although 99.93% accuracy seems like very a impressive percentage, the model
actually has no predictive power. Precisionandrecallare usually more useful metrics
thanaccuracyfor evaluating models trained on class-imbalanced datasets.",,"['binary classification', 'class', 'classification model', 'class-imbalanced dataset', 'imbalanced dataset', 'metric', 'model', 'negative class', 'positive class', 'precision', 'prediction', 'recall']",,false,"(accuracy|\s(\s|\.|\,))"
variable importances,"A set of scores that indicates the relative importance of eachfeatureto the model. For example, consider adecision treethat
estimates house prices. Suppose this decision tree uses three
features: size, age, and style. If a set of variable importances
for the three features are calculated to be
{size=5.8, age=2.5, style=4.7}, then size is more important to the
decision tree than age or style. Different variable importance metrics exist, which can inform
ML experts about different aspects of models.",,"['decision tree', 'feature', 'metric', 'model']",,false,"(variable(\s|-)?importance|\sfeature importances(\s|\.|\,))"
candidate sampling,"A training-time optimization that calculates a probability for all the positivelabels, using, for example,softmax, but only for a random
sample of negative labels. For instance, given an example labeledbeagleanddog, candidate sampling computes the predicted probabilities
and corresponding loss terms for: The idea is that thenegative classescan learn from less frequent
negative reinforcement as long aspositive classesalways get proper positive
reinforcement, and this is indeed observed empirically. Candidate sampling is more computationally efficient than training algorithms
that compute predictions forallnegative classes, particularly when the
number of negative classes is very large.",,"['class', 'instance', 'label', 'loss', 'negative class', 'positive class', 'prediction', 'softmax', 'training']",,false,"(candidate(\s|-)?sampl|\snegative sampling(\s|\.|\,))"
"empirical cumulative distribution function (eCDF or
EDF)","Acumulative distribution functionbased onempirical measurementsfrom a real dataset. The value of the
function at any point along the x-axis is the fraction of observations in
the dataset that are less than or equal to the specified value. ",,"['action', 'distribution']",,false,"(empirical(\s|-)?cumulative(\s|-)?distribution(\s|-)?function(\s|-)?|\s(\s|\.|\,))"
early stopping,"A method for regularization that involves ending training before training loss finishes
decreasing. In early stopping, you intentionally stop training the model when the loss on a validation dataset starts to
increase i.e. when generalization performance worsens. ",,"['generalization', 'loss', 'model', 'overfitting', 'performance', 'prediction', 'regularization', 'training', 'training loss', 'validation']",,false,"(early(\s|-)?stopp|\s(\s|\.|\,))"
entropy,"Ininformation theory,
a description of how unpredictable a probability
distribution is. Alternatively, entropy is also defined as how much
information eachexamplecontains. A distribution has
the highest possible entropy when all values of a random variable are
equally likely. The entropy of a set with two possible values ""0"" and ""1"" (for example,
the labels in abinary classificationproblem)
has the following formula: H = -p log p - q log q = -p log p - (1-p) * log (1-p) where: For example, suppose the following: Therefore, the entropy value is: A set that is perfectly balanced (for example, 200 ""0""s and 200 ""1""s)
would have an entropy of 1.0 bit per example. As a set becomes moreimbalanced, its entropy moves towards 0.0. Indecision trees, entropy helps formulateinformation gainto help thesplitterselect theconditionsduring the growth of a classification decision tree. Compare entropy with: Entropy is often called Shannon's entropy.",,"['binary classification', 'class', 'condition', 'decision tree', 'distribution', 'information gain', 'label', 'split', 'splitter']",,false,"(entropy|\s(\s|\.|\,))"
recall,"A metric forclassification modelsthat answers
the following question: Whenground truthwas thepositive class, what percentage of predictions did
the model correctly identify as the positive class? Here is the formula: \[\text{Recall} =
\frac{\text{true positives}} {\text{true positives} + \text{false negatives}}
\] where: For instance, suppose your model made 200 predictions on examples for which
ground truth was the positive class. Of these 200 predictions: In this case: \[\text{Recall} =
\frac{\text{180}} {\text{180} + \text{20}} = 0.9
\] Recall is particularly useful for determining the predictive power of
classification models in which the positive class is rare. For example, consider
aclass-imbalanced datasetin which the positive class for a certain disease occurs in only 10 patients
out of a million. Suppose your model makes five million predictions that yield
the following outcomes: The recall of this model is therefore: That high value of accuracy looks impressive but is essentially meaningless.
Recall is a much more useful metric for class-imbalanced datasets than accuracy.",,"['accuracy', 'class', 'classification model', 'class-imbalanced dataset', 'ground truth', 'imbalanced dataset', 'instance', 'metric', 'model', 'positive class', 'prediction']",,false,"(recall|\strue positive rate (TPR)(\s|\.|\,))"
latent space,Synonym forembedding space.,,"['embedding space']",embedding space,true,"(latent(\s|-)?space|\sembedding space(\s|\.|\,))"
backpropagation,"The algorithm that implements gradient descent during training in neural networks - determining whether to increase or decrease the weights applied to particular neurons. 
‚Ä®The learning rate is a multiplier that controls the degree to which each backward pass increases or decreases each weight.
‚Ä®In calculus terms, backpropagation implements the 'chain rule'.
from calculus. ",,"['gradient', 'gradient descent', 'hidden layer', 'iteration', 'layer', 'learning rate', 'loss', 'neural network', 'neuron', 'parameter', 'partial derivative', 'Tensor', 'TensorFlow', 'training', 'weight']",,false,"(backpropagat|\s(\s|\.|\,))"
post-processing,"Adjusting the output of a modelafterthe model has been run.
Post-processing can be used to enforce fairness constraints without
modifying models themselves. For example, one might apply post-processing to a binary classifier
by setting a classification threshold such thatequality of opportunityis maintained
for some attribute by checking that thetrue positive rateis the same for all values of that attribute. ",,"['attribute', 'class', 'classification threshold', 'equality of opportunity', 'fairness constraint', 'model', 'Tensor Processing Unit']",,false,"(post(\s|-)?process|\s(\s|\.|\,))"
quantile,Each bucket in quantile bucketing. ,,"['bucketing', 'quantile bucketing']",,false,"(quantile|\s(\s|\.|\,))"
confusion matrix,"An NxN table that summarizes the number of correct and incorrect predictions
that aclassification modelmade.
For example, consider the following confusion matrix for abinary classificationmodel: The preceding confusion matrix shows the following: The confusion matrix for amulti-class classificationproblem can help you identify patterns of mistakes.
For example, consider the following confusion matrix for a 3-class
multi-class classification model that categorizes three different iris types
(Virginica, Versicolor, and Setosa). When the ground truth was Virginica, the
confusion matrix shows that the model was far more likely to mistakenly
predict Versicolor than Setosa: As yet another example, a confusion matrix could reveal that a model trained
to recognize handwritten digits tends to mistakenly predict 9 instead of 4,
or mistakenly predict 1 instead of 7. Confusion matrixes contain sufficient information to calculate a
variety of performance metrics, includingprecisionandrecall.",,"['binary classification', 'class', 'classification model', 'ground truth', 'metric', 'model', 'multi-class classification', 'performance', 'precision', 'prediction', 'recall']",,false,"(confusion(\s|-)?matrix|\s(\s|\.|\,))"
split,"In adecision tree, another name for acondition.",,"['condition', 'decision tree']",,false,"(split|\s(\s|\.|\,))"
exploding gradient problem,"The tendency for gradients in deep neural networks(especially recurrent neural networks) to become
surprisingly steep (high). Steep gradients often cause very large updates
to the weights of each nodein a
deep neural network. Models suffering from the exploding gradient problem become difficult
or impossible to train. Gradient clipping can mitigate this problem. Compare to vanishing gradient problem. ",,"['clipping', 'deep neural network', 'gradient', 'gradient clipping', 'model', 'neural network', 'recurrent neural network', 'vanishing gradient problem', 'weight']",,false,"(exploding(\s|-)?gradient(\s|-)?problem|\s(\s|\.|\,))"
pre-training,"The initial training of a model on a large dataset. Some pre-trained models
are clumsy giants and must typically be refined through additional training.
For example, ML experts might pre-train alarge language modelon a vast text dataset,
such as all the English pages in Wikipedia. Following pre-training, the
resulting model might be further refined through any of the following
techniques: ",,"['language model', 'large language model', 'model', 'pre-trained model', 'training']",,false,"(pre(\s|-)?train|\s(\s|\.|\,))"
Bayesian neural network,"A probabilistic neural network that accounts for
uncertainty in weights and outputs. A standard neural network
regression model typicallypredictsa scalar value;
for example, a standard model predicts a house price
of 853,000. In contrast, a Bayesian neural network predicts a distribution of
values; for example, a Bayesian model predicts a house price of 853,000 with
a standard deviation of 67,200. A Bayesian neural network relies onBayes' Theoremto calculate uncertainties in weights and predictions. A Bayesian neural
network can be useful when it is important to quantify uncertainty, such as in
models related to pharmaceuticals. Bayesian neural networks can also help
preventoverfitting. ",,"['distribution', 'model', 'neural network', 'overfitting', 'prediction', 'regression model', 'scalar', 'weight', 'Tensor Processing Unit']",,false,"(Bayesian(\s|-)?neural(\s|-)?network|\s(\s|\.|\,))"
recurrent neural network,"A neural network that is intentionally run multiple
times, where parts of each run feed into the next run. Specifically,
hidden layers from the previous run provide part of the
input to the same hidden layer in the next run. Recurrent neural networks
are particularly useful for evaluating sequences, so that the hidden layers
can learn from previous runs of the neural network on earlier parts of
the sequence. For example, the following figure shows a recurrent neural network that
runs four times. Notice that the values learned in the hidden layers from
the first run become part of the input to the same hidden layers in
the second run. Similarly, the values learned in the hidden layer on the
second run become part of the input to the same hidden layer in the
third run. In this way, the recurrent neural network gradually trains and
predicts the meaning of the entire sequence rather than just the meaning
of individual words.",RNN,"['hidden layer', 'layer', 'neural network', 'intersection over union']",,false,"(recurrent(\s|-)?neural(\s|-)?network|\sRNN(\s|\.|\,)|\s(\s|\.|\,))"
subword token,"Inlanguage models, atokenthat is a
substring of a word, which may be the entire word. For example, a word like ""itemize"" might be broken up into the pieces ""item""
(a root word) and ""ize"" (a suffix), each of which is represented by its own
token. Splitting uncommon words into such pieces, called subwords, allows
language models to operate on the word's more common constituent parts,
such as prefixes and suffixes. Conversely, common words like ""going"" might not be broken up and might be
represented by a single token.",,"['language model', 'model', 'root', 'split', 'token']",,false,"(subword(\s|-)?token|\s(\s|\.|\,))"
epsilon greedy policy,"In reinforcement learning, a policy that either follows a random policy with epsilon probability or agreedy policy otherwise. For example, if epsilon is
0.9, then the policy follows a random policy 90% of the time and a greedy
policy 10% of the time. Over successive episodes, the algorithm reduces epsilon's value in order to shift from following a random policy to following a greedy policy. By shifting the policy, the agent first randomly explores the environment and then greedily exploits the results of random exploration.",,"['agent', 'environment', 'episode', 'greedy policy', 'policy', 'random policy', 'Low-Rank Adaptability']",,false,"(epsilon(\s|-)?greedy(\s|-)?policy|\s(\s|\.|\,))"
proxy (sensitive attributes),,,[],,false,"(proxy(\s|-)?|\s(\s|\.|\,))"
supervised machine learning,"Training amodelfromfeaturesand their
correspondinglabels. Supervised machine learning is analogous
to learning a subject by studying a set of questions and their
corresponding answers. After mastering the mapping between questions and
answers, a student can then provide answers to new (never-before-seen)
questions on the same topic. Compare withunsupervised machine learning.",,"['feature', 'label', 'machine learning', 'model', 'training', 'unsupervised machine learning']",,false,"(supervised(\s|-)?machine(\s|-)?learn|\s(\s|\.|\,))"
validation loss,"A metric representing a model's loss on
the validation set during a particular iteration of training. See also generalization curve.",,"['generalization', 'generalization curve', 'iteration', 'loss', 'metric', 'model', 'training', 'validation', 'validation set']",,false,"(validation(\s|-)?los|\s(\s|\.|\,))"
JAX,"An array computing library, bringing together XLA (Accelerated Linear Algebra) and automatic differentiation
for high-performance numerical computing. JAX provides a simple and powerful
API for writing accelerated numerical code with composable transformations.
JAX provides features such as: JAX is a language for expressing and composing transformations of numerical
code, analogous‚Äîbut much larger in scope‚Äîto Python'sNumPylibrary. (In fact, the .numpy library under JAX is a functionally equivalent,
but entirely rewritten version of the Python NumPy library.) JAX is particularly well-suited for speeding up many machine learning tasks
by transforming the models and data into a form suitable for parallelism
across GPU andTPUaccelerator chips. Flax,Optax,Pax, and many other
libraries are built on the JAX infrastructure. ",,"['accelerator chip', 'feature', 'Flax', 'linear', 'machine learning', 'model', 'NumPy', 'Optax', 'Pax', 'performance', 'task', 'XLA (Accelerated Linear Algebra)', 'Tensor Processing Unit']",,false,"(JAX|\s(\s|\.|\,))"
convex function,"A function in which the region above the graph of the function is a convex set. The prototypical convex function is
shaped something like the letter U. For example, the following
are all convex functions:  In contrast, the following function is not convex. Notice how the
region above the graph is not a convex set:  Astrictly convex functionhas exactly one local minimum point, which
is also the global minimum point. The classic U-shaped functions are
strictly convex functions. However, some convex functions
(for example, straight lines) are not U-shaped. A lot of the commonloss functions, including the
following, are convex functions: Many variations ofgradient descentare guaranteed to find a point close to the minimum of a
strictly convex function. Similarly, many variations ofstochastic gradient descenthave a high probability
(though, not a guarantee) of finding a point close to the minimum of a
strictly convex function. The sum of two convex functions (for example,
L2loss + L1regularization) is a convex function. Deep modelsare never convex functions.
Remarkably, algorithms designed forconvex optimizationtend to find
reasonably good solutions on deep networks anyway, even though
those solutions are not guaranteed to be a global minimum. ",,"['class', 'convex optimization', 'convex set', 'deep model', 'gradient', 'gradient descent', 'graph', 'L1regularization', 'L2loss', 'loss', 'loss function', 'model', 'regularization']",,false,"(convex(\s|-)?funct|\s(\s|\.|\,))"
temperature,"A hyperparameterthat controls the degree of randomness
of a model's output. Higher temperatures result in more random output,
while lower temperatures result in less random output. Choosing the best temperature depends on the specific application and
the preferred properties of the model's output. For example, you would
probably raise the temperature when creating an application that
generates creative output. Conversely, you would probably lower the temperature
when building a model that classifies images or text in order to improve the
model's accuracy and consistency. Temperature is often used withsoftmax. ",,"['accuracy', 'class', 'hyperparameter', 'model', 'parameter', 'softmax', 'Tensor Processing Unit']",,false,"(temperature|\s(\s|\.|\,))"
rater,"A human who provideslabelsforexamples.
""Annotator"" is another name for rater. ",,"['label']",,false,"(rater|\s(\s|\.|\,))"
classification threshold,"In a binary classification, a
number between 0 and 1 that converts the raw output of a logistic regressionmodel
into a prediction of either thepositive classor thenegative class.
Note that the classification threshold is a value that a human chooses,
not a value chosen by model training. A logistic regression model outputs a raw value between 0 and 1. Then: For example, suppose the classification threshold is 0.8. If the raw value
is 0.9, then the model predicts the positive class. If the raw value is
0.7, then the model predicts the negative class. The choice of classification threshold strongly influences the number offalse positivesandfalse negatives. As models or datasets evolve, engineers sometimes also change the
classification threshold. When the classification threshold changes,
positive class predictions can suddenly become negative classes
and vice-versa. For example, consider a binary classification disease prediction model.
Suppose that when the system runs in the first year: Therefore, the system diagnoses the positive class. (The patient gasps,
""Oh no! I'm sick!"") A year later, perhaps the values now look as follows: Therefore, the system now reclassifies that patient as the negative class.
(""Happy day! I'm not sick."") Same patient. Different diagnosis.",,"['binary classification', 'class', 'logistic regression', 'model', 'model training', 'negative class', 'positive class', 'prediction', 'regression model', 'training', 'Tensor Processing Unit']",,false,"(classification(\s|-)?threshold|\sdecision threshold(\s|\.|\,))"
replay buffer,"In DQN-like algorithms, the memory used by the agent to store state transitions for use inexperience replay. ",,"['agent', 'experience replay', 'state', 'Deep Q-Network']",,false,"(replay(\s|-)?buffer|\s(\s|\.|\,))"
similarity measure,"In clustering algorithms, the metric used to determine how alike (how similar) any two examples are. ",,"['clustering', 'metric']",,false,"(similarity(\s|-)?measure|\s(\s|\.|\,))"
equality of opportunity,"Afairness metricto assess whether a model is
predicting the desirable outcome equally well for all values of asensitive attribute. In other words, if the
desirable outcome for a model is thepositive class,
the goal would be to have thetrue positive ratebe the
same for all groups. Equality of opportunity is related toequalized odds,
which requires thatboththe true positive rates andfalse positive ratesare the same for all groups. Suppose Glubbdubdrib University admits both Lilliputians and Brobdingnagians
to a rigorous mathematics program. Lilliputians' secondary schools offer a
robust curriculum of math classes, and the vast majority of students are
qualified for the university program. Brobdingnagians' secondary schools don't
offer math classes at all, and as a result, far fewer of their students are
qualified. Equality of opportunity is satisfied for the preferred label of
""admitted"" with respect to nationality (Lilliputian or Brobdingnagian) if
qualified students are equally likely to be admitted irrespective of whether
they're a Lilliputian or a Brobdingnagian. For example, suppose 100 Lilliputians and 100 Brobdingnagians apply to
Glubbdubdrib University, and admissions decisions are made as follows: Table 1.Lilliputian applicants (90% are qualified)  Table 2.Brobdingnagian applicants (10% are qualified): The preceding examples satisfy equality of opportunity for acceptance of
qualified students because qualified Lilliputians and Brobdingnagians both
have a 50% chance of being admitted. While equality of opportunity is satisfied, the following two fairness metrics
are not satisfied: See""Equality of
Opportunity in Supervised Learning""for a more detailed discussion
of equality of opportunity. Also see""Attacking
discrimination with smarter machine learning""for a visualization
exploring the tradeoffs when optimizing for equality of opportunity.",,"['attribute', 'class', 'equalized odds', 'fairness metric', 'label', 'machine learning', 'metric', 'model', 'positive class', 'sensitive attribute']",,false,"(equality(\s|-)?of(\s|-)?opportunity|\s(\s|\.|\,))"
recommendation system,"A system that selects for each user a relatively small set of desirableitemsfrom a large corpus.
For example, a video recommendation system might recommend two videos
from a corpus of 100,000 videos, selectingCasablancaandThe Philadelphia Storyfor one user, andWonder WomanandBlack Pantherfor another. A video recommendation system might
base its recommendations on factors such as:",,"['items']",,false,"(recommendation(\s|-)?system|\s(\s|\.|\,))"
representation,The process of mapping data to usefulfeatures.,,"['feature']",,false,"(representat|\s(\s|\.|\,))"
offline,Synonym for static.,,"['static']",static,true,"(offline|\sstatic(\s|\.|\,))"
self-supervised learning,"A family of techniques for converting anunsupervised machine learningproblem
into asupervised machine learningproblem
by creating surrogatelabelsfromunlabeled examples. SomeTransformer-based models such asBERTuse
self-supervised learning. Self-supervised training is asemi-supervised learningapproach. ",,"['label', 'labeled example', 'machine learning', 'model', 'semi-supervised learning', 'supervised machine learning', 'training', 'Transformer', 'unlabeled example', 'unsupervised machine learning']",,false,"(self(\s|-)?supervised(\s|-)?learn|\s(\s|\.|\,))"
Bayesian optimization,"A probabilistic regression model technique for optimizing computationally expensive objective functions by instead optimizing a surrogate
that quantifies the uncertainty using a Bayesian learning technique. Since
Bayesian optimization is itself very expensive, it is usually used to optimize
expensive-to-evaluate tasks that have a small number of parameters, such as
selecting hyperparameters.",,"['hyperparameter', 'model', 'objective', 'objective function', 'parameter', 'probabilistic regression model', 'regression model', 'task']",,false,"(Bayesian(\s|-)?optimizat|\s(\s|\.|\,))"
interpretability,"The ability to explain or to present an ML model's reasoning in understandable terms to a human. Most linear regression models, for example, are highly
interpretable. (You merely need to look at the trained weights for each
feature.) Decision forests are also highly interpretable. Some models, however,
require sophisticated visualization to become interpretable. You can use theLearning Interpretability Tool (LIT)to interpret ML models. ",,"['decision forest', 'feature', 'Learning Interpretability Tool (LIT)', 'linear', 'linear regression', 'model', 'weight']",,false,"(interpretability|\s(\s|\.|\,))"
N-gram,"An ordered sequence of N words. For example,truly madlyis a 2-gram. Because
order is relevant,madly trulyis a different 2-gram thantruly madly. Manynatural language understandingmodels rely on N-grams to predict the next word that the user will type
or say. For example, suppose a user typedthree blind.
An NLU model based on trigrams would likely predict that the
user will next typemice. Contrast N-grams withbag of words, which are
unordered sets of words.",,"['bag of words', 'model', 'natural language understanding', 'trigram']",,false,"(N(\s|-)?gram|\s(\s|\.|\,))"
Momentum,"A gradient descent algorithm in which a learning step depends
not only on the derivative in the current step, but also on the derivatives
of the step(s) that immediately preceded it. Momentum involves computing an
exponentially weighted moving average of the gradients over time, analogous
to momentum in physics. Momentum sometimes prevents learning from getting
stuck in local minima.",,"['gradient', 'gradient descent', 'step', 'weight', 'retrieval-augmented generation']",,false,"(Momentum|\s(\s|\.|\,))"
confabulation,"Synonym forhallucination. Confabulation is probably a more technically accurate term than hallucination.
However, hallucination became popular first. ",,"['hallucination']",hallucination,true,"(confabulat|\shallucination(\s|\.|\,))"
equalized odds,"A fairness metric to assess whether a model is predicting outcomes equally
well for all values of asensitive attributewith
respect to both thepositive classandnegative class‚Äînot just one class or the other
exclusively. In other words, both thetrue positive rateandfalse negative rateshould be the same for
all groups. Equalized odds is related toequality of opportunity, which only focuses
on error rates for a single class (positive or negative). For example, suppose Glubbdubdrib University admits both Lilliputians and
Brobdingnagians to a rigorous mathematics program. Lilliputians' secondary
schools offer a robust curriculum of math classes, and the vast majority of
students are qualified for the university program. Brobdingnagians' secondary
schools don't offer math classes at all, and as a result, far fewer of
their students are qualified. Equalized odds is satisfied provided that no
matter whether an applicant is a Lilliputian or a Brobdingnagian, if they
are qualified, they are equally as likely to get admitted to the program,
and if they are not qualified, they are equally as likely to get rejected. Suppose 100 Lilliputians and 100 Brobdingnagians apply to Glubbdubdrib
University, and admissions decisions are made as follows: Table 3.Lilliputian applicants (90% are qualified)  Table 4.Brobdingnagian applicants (10% are qualified): Equalized odds is satisfied because qualified Lilliputian and Brobdingnagian
students both have a 50% chance of being admitted, and unqualified Lilliputian
and Brobdingnagian have an 80% chance of being rejected. Equalized odds is formally defined in""Equality of
Opportunity in Supervised Learning""as follows:
""predictor ≈∂ satisfies equalized odds with respect
to protected attribute A and outcome Y if ≈∂ and A are independent,
conditional on Y.""",,"['attribute', 'class', 'condition', 'equality of opportunity', 'fairness metric', 'false negative rate', 'metric', 'model', 'negative class', 'positive class', 'sensitive attribute']",,false,"(equalized(\s|-)?odd|\s(\s|\.|\,))"
experience replay,"In reinforcement learning, a DQN technique used to
reduce temporal correlations in training data. The agent stores state transitions in areplay buffer, and then
samples transitions from the replay buffer to create training data.",,"['agent', 'replay buffer', 'state', 'training', 'Deep Q-Network']",,false,"(experience(\s|-)?replay|\s(\s|\.|\,))"
false negative (FN),"An example in which the model mistakenly predicts thenegative class. For example, the model
predicts that a particular email message isnot spam(the negative class), but that email messageactually is spam. ",,"['class', 'model', 'negative class']",,false,"(false(\s|-)?negative(\s|-)?|\s(\s|\.|\,))"
configuration,"The process of assigning the initial property values used to train a model,
including: In machine learning projects, configuration can be done through a special
configuration file or using configuration libraries ",,"['machine learning', 'model']",,false,"(configurat|\s(\s|\.|\,))"
false positive (FP),"An example in which the model mistakenly predicts thepositive class. For example, the model predicts
that a particular email message isspam(the positive class), but that
email message isactually not spam.",,"['class', 'model', 'positive class']",,false,"(false(\s|-)?positive(\s|-)?|\s(\s|\.|\,))"
false positive rate (FPR),"The proportion of actual negative examples for which the model mistakenly
predicted the positive class. The following formula calculates the false
positive rate: The false positive rate is the x-axis in anROC curve.",,"['class', 'model', 'positive class']",,false,"(false(\s|-)?positive(\s|-)?rate(\s|-)?|\s(\s|\.|\,))"
parameter update,"The operation of adjusting a model's parameters during
training, typically within a single iteration of gradient descent. ",,"['gradient', 'gradient descent', 'iteration', 'model', 'parameter', 'training']",,false,"(parameter(\s|-)?update|\s(\s|\.|\,))"
natural language understanding,"Determining a user's intentions based on what the user typed or said.
For example, a search engine uses natural language understanding to
determine what the user is searching for based on what the user typed or said.",,[],,false,"(natural(\s|-)?language(\s|-)?understand|\s(\s|\.|\,))"
loss function,"A mathematical function, used in training or testing, that calculates the
loss on a batch of examples. A loss function returns a lower loss
for models that makes good predictions than for models that make bad predictions. The goal of training is typically to minimize the loss that a loss function
returns. Many different kinds of loss functions exist depending on the model you're building.",,"['batch', 'loss', 'model', 'prediction', 'return', 'test', 'training']",,false,"(loss(\s|-)?funct|\s(\s|\.|\,))"
target,Synonym forlabel.,,"['label']",label,true,"(target|\slabel(\s|\.|\,))"
participation bias,Synonym for non-response bias. Seeselection bias. ,,"['non-response bias', 'selection bias']",non-response bias,true,"(participation(\s|-)?bia|\snon-response bias(\s|\.|\,))"
Q-function,"In Q-learning, the function that predicts the expected return (the 'reward') from taking an action in a state and then following a given policy. 
The core equation in the Q-function is the Bellman equation.",,"['action', 'policy', 'return', 'state', 'state-action value function']",,false,"(Q(\s|-)?funct|\sstate-action value function(\s|\.|\,))"
sentiment analysis,"Using statistical or machine learning algorithms to determine a group's
overall attitude‚Äîpositive or negative‚Äîtoward a service, product,
organization, or topic. For example, using natural language understanding,
an algorithm could perform sentiment analysis on the textual feedback
from a university course to determine the degree to which students
generally liked or disliked the course.",,"['machine learning', 'natural language understanding']",,false,"(sentiment(\s|-)?analysi|\s(\s|\.|\,))"
feature,"An input variable to a machine learning model. Anexampleconsists of one or more features. For instance, suppose you are training a
model to determine the influence of weather conditions on student test scores.
The following table shows three examples, each of which contains
three features and one label: Contrast withlabel.",,"['condition', 'instance', 'label', 'machine learning', 'model', 'test', 'training']",,false,"(feature|\sattribute(\s|\.|\,))"
generative AI,"An emerging transformative field with no formal definition.
That said, most experts agree that generative AI models can
create (""generate"") content that is all of the following: For example, a generative AI model can create sophisticated
essays or images. Some earlier technologies, includingLSTMsandRNNs, can also generate original and
coherent content. Some experts view these earlier technologies as
generative AI, while others feel that true generative AI requires more complex
output than those earlier technologies can produce. Contrast withpredictive ML. ",,"['model', 'predictive ML', 'Long Short-Term Memory', 'Tensor Processing Unit']",,false,"(generative(\s|-)?AI|\s(\s|\.|\,))"
sensitive attribute,,,[],,false,"(sensitive(\s|-)?attribute|\s(\s|\.|\,))"
sequence model,"A model whose inputs have a sequential dependence. For example, predicting
the next video watched from a sequence of previously watched videos.",,"['model', 'intersection over union']",,false,"(sequence(\s|-)?model|\s(\s|\.|\,))"
uplift modeling,"A modeling technique, commonly used in marketing, that models the
""causal effect"" (also known as the ""incremental impact"") of a
""treatment"" on an ""individual."" Here are two examples: Uplift modeling differs fromclassificationorregressionin that some labels (for example, half
of the labels in binary treatments) are always missing in uplift modeling.
For example, a patient can either receive or not receive a treatment;
therefore, we can only observe whether the patient is going to heal or
not heal in only one of these two situations (but never both).
The main advantage of an uplift model is that it can generate predictions
for the unobserved situation (the counterfactual) and use it to compute
the causal effect. ",,"['class', 'label', 'model', 'prediction']",,false,"(uplift(\s|-)?model|\s(\s|\.|\,))"
greedy policy,"In reinforcement learning, a policy that always chooses the
action with the highest expected return.",,"['action', 'policy', 'return']",,false,"(greedy(\s|-)?policy|\s(\s|\.|\,))"
neuron,"In machine learning, a distinct unit within ahidden layerof aneural network. Each neuron performs the following
two-step action: A neuron in the first hidden layer accepts inputs from the feature values
in theinput layer. A neuron in any hidden layer beyond
the first accepts inputs from the neurons in the preceding hidden layer.
For example, a neuron in the second hidden layer accepts inputs from the
neurons in the first hidden layer. The following illustration highlights two neurons and their
inputs.  A neuron in a neural network mimics the behavior of neurons in brains and
other parts of nervous systems.",,"['action', 'feature', 'hidden layer', 'input layer', 'layer', 'machine learning', 'neural network', 'step']",,false,"(neuron|\s(\s|\.|\,))"
Fiddle,"A Python-first configuration library that sets the
values of functions and classes without invasive code or infrastructure.
In the case of Pax‚Äîand other ML codebases‚Äîthese functions and
classes represent models and training hyperparameters. ",,"['class', 'configuration', 'hyperparameter', 'machine learning', 'model', 'parameter', 'Pax', 'training']",,false,"(Fiddle|\s(\s|\.|\,))"
TPU type,"A configuration of one or moreTPU deviceswith a specific
TPU hardware version. You select a TPU type when you create
aTPU nodeon Google Cloud. For example, av2-8TPU type is a single TPU v2 device with 8 cores. Av3-2048TPU type has 256
networked TPU v3 devices and a total of 2048 cores. TPU types are a resource
defined in theCloud TPU API.",,"['Cloud TPU', 'configuration', 'device', 'TPU device', 'TPU node', 'Tensor Processing Unit']",,false,"(TPU(\s|-)?type|\s(\s|\.|\,))"
clustering,"Grouping related examples, particularly during unsupervised learning. Once all the
examples are grouped, a human can optionally supply meaning to each cluster. Many clustering algorithms exist. For example, the k-meansalgorithm clusters examples based on their proximity to acentroid, as in the following diagram:  A human researcher could then review the clusters and, for example,
label cluster 1 as ""dwarf trees"" and cluster 2 as ""full-size trees."" As another example, consider a clustering algorithm based on an
example's distance from a center point, illustrated as follows:  ",,"['centroid', 'k-means', 'label']",,false,"(cluster|\s(\s|\.|\,))"
sparse feature,"Afeaturewhose values are predominately zero or empty.
For example, a feature containing a single 1 value and a million 0 values is
sparse. In contrast, adense featurehas values that
are predominantly not zero or empty. In machine learning, a surprising number of features are sparse features.
Categorical features are usually sparse features.
For example, of the 300 possible tree species in a forest, a single example
might identify just amaple tree. Or, of the millions
of possible videos in a video library, a single example might identify
just ""Casablanca."" In a model, you typically represent sparse features withone-hot encoding. If the one-hot encoding is big,
you might put anembedding layeron top of the
one-hot encoding for greater efficiency.",,"['dense feature', 'embedding layer', 'feature', 'layer', 'machine learning', 'model', 'one-hot encoding']",,false,"(sparse(\s|-)?feature|\s(\s|\.|\,))"
convolutional neural network,"A neural networkin which at least one layer is a convolutional layer. A typical convolutional
neural network consists of some combination of the following layers: Convolutional neural networks have had great success in certain kinds
of problems, such as image recognition.",CNN,"['convolution', 'convolutional layer', 'image recognition', 'layer', 'neural network']",,false,"(convolutional(\s|-)?neural(\s|-)?network|\sCNN(\s|\.|\,)|\s(\s|\.|\,))"
autoencoder,"A system that learns to extract the most important information from the
input. Autoencoders are a combination of anencoderanddecoder. Autoencoders rely on the following two-step process: Autoencoders are trained end-to-end by having the decoder attempt to
reconstruct the original input from the encoder's intermediate format
as closely as possible. Because the intermediate format is smaller
(lower-dimensional) than the original format, the autoencoder is forced
to learn what information in the input is essential, and the output won't
be perfectly identical to the input. For example: See alsovariational autoencoders.",,"['decoder', 'encoder', 'step', 'Tensor Processing Unit']",,false,"(autoencoder|\s(\s|\.|\,))"
model cascading,"A system that picks the ideal model for a specific inference
query. Imagine a group of models, ranging from very large (lots ofparameters) to much smaller (far fewer parameters).
Very large models consume more computational resources atinferencetime than smaller models. However, very large
models can typically infer more complex requests than smaller models.
Model cascading determines the complexity of the inference query and then
picks the appropriate model to perform the inference.
The main motivation for model cascading is to reduce inference costs by generally selecting smaller models, and only selecting a larger model for more
complex queries. Imagine that a small model runs on a phone and a larger version of that model
runs on a remote server. Good model cascading reduces cost and latency by
enabling the smaller model to handle simple requests and only calling the
remote model to handle complex requests. See alsomodel router.",,"['cost', 'inference', 'model', 'model router', 'parameter']",,false,"(model(\s|-)?cascad|\s(\s|\.|\,))"
generative model,"Practically speaking, a model that does either of the following: A generative model can theoretically discern the distribution of examples
or particular features in a dataset. That is: Unsupervised learning models are generative. Contrast withdiscriminative models. ",,"['discriminative model', 'distribution', 'feature', 'model']",,false,"(generative(\s|-)?model|\s(\s|\.|\,))"
vector,"Very overloaded term whose meaning varies across different mathematical
and scientific fields. Within machine learning, a vector has two properties: For example, consider afeature vectorthat holds eight
floating-point numbers. This feature vector has a length or dimension of eight.
Note that machine learning vectors often have a huge number of dimensions. You can represent many different kinds of information as a vector. For example: Vectors can be concatenated; therefore, a variety of different media can be
represented as a single vector. Some models operate directly on the
concatenation of manyone-hot encodings. Specialized processors such asTPUsare optimized to perform
mathematical operations on vectors. A vector is atensorofrank1. ",,"['dimensions', 'feature', 'feature vector', 'machine learning', 'model', 'one-hot encoding', 'Tensor', 'Tensor Processing Unit']",,false,"(vector|\s(\s|\.|\,))"
wide model,"A linear model that typically has manysparse input features. We refer to it as ""wide"" since
such a model is a special type ofneural networkwith a
large number of inputs that connect directly to the output node. Wide models
are often easier to debug and inspect thandeep models.
Although wide models
cannot express nonlinearities throughhidden layers,
wide models can use transformations such asfeature crossingandbucketizationto model nonlinearities in different ways. Contrast withdeep model. ",,"['deep model', 'feature', 'feature cross', 'hidden layer', 'layer', 'linear', 'linear model', 'model', 'neural network', 'nonlinear', 'online', 'Tensor Processing Unit']",,false,"(wide(\s|-)?model|\s(\s|\.|\,))"
weight,"A value that a model multiplies by another value. Training is the process of determining a model's ideal weights;inferenceis the process of using those learned weights to
make predictions. Imagine alinear modelwith two features.
Suppose that training determines the following weights (andbias): Now imagine anexamplewith the following feature
values: This linear model uses the following formula to generate a prediction,
y': Therefore, the prediction is: If a weight is 0, then the corresponding feature doesn't contribute to
the model. For example, if w1is 0, then the value of x1is irrelevant.",,"['feature', 'inference', 'linear', 'linear model', 'model', 'prediction', 'training']",,false,"(weight|\s(\s|\.|\,))"
feature cross,"Asynthetic featureformed by ""crossing""categoricalorbucketedfeatures. For example, consider a ""mood forecasting"" model that represents
temperature in one of the following four buckets: And represents wind speed in one of the following three buckets: Without feature crosses, the linear model trains independently on each of the
preceding seven various buckets. So, the model trains on, for instance,freezingindependently of the training on, for instance,windy. Alternatively, you could create a feature cross of temperature and
wind speed. This synthetic feature would have the following 12 possible
values: Thanks to feature crosses, the model can learn mood differences
between afreezing-windyday and afreezing-stillday. If you create a synthetic feature from two features that each have a lot of
different buckets, the resulting feature cross will have a huge number
of possible combinations. For example, if one feature has 1,000 buckets and
the other feature has 2,000 buckets, the resulting feature cross has 2,000,000
buckets. Formally, a cross is aCartesian product. Feature crosses are mostly used with linear models and are rarely used
with neural networks.",,"['feature', 'instance', 'linear', 'linear model', 'model', 'neural network', 'synthetic feature', 'temperature', 'training', 'intersection over union']",,false,"(feature(\s|-)?cros|\s(\s|\.|\,))"
feature engineering,"A process that involves the following steps: For example, you might determine thattemperaturemight be a useful
feature. Then, you might experiment withbucketingto optimize what the model can learn from differenttemperatureranges. Feature engineering is sometimes calledfeature extractionorfeaturization. In TensorFlow, feature engineering often means converting raw log file
entries totf.Exampleprotocol buffers.
See alsotf.Transform. ",,"['action', 'bucketing', 'feature', 'feature extraction', 'featurization', 'model', 'step', 'temperature', 'Tensor', 'TensorFlow']",,false,"(feature(\s|-)?engineer|\s(\s|\.|\,))"
decision threshold,Synonym forclassification threshold.,,"['class', 'classification threshold']",classification threshold,true,"(decision(\s|-)?threshold|\sclassification threshold(\s|\.|\,))"
summary,"In TensorFlow, a value or set of values calculated at a particularstep, usually used for tracking model metrics during training.",,"['metric', 'model', 'step', 'Tensor', 'TensorFlow', 'training']",,false,"(summary|\s(\s|\.|\,))"
task,"A problem that can be solved using machine learning techniques, such as:",,"['machine learning']",,false,"(task|\s(\s|\.|\,))"
AUC (Area under the ROC curve),"A number between 0.0 and 1.0 representing abinary classificationmodel's
ability to separatepositive classesfromnegative classes.
The closer the AUC is to 1.0, the better the model's ability to separate
classes from each other. For example, the following illustration shows a classifier model
that separates positive classes (green ovals) from negative classes
(purple rectangles) perfectly. This unrealistically perfect model has
an AUC of 1.0:  Conversely, the following illustration shows the results for a classifier
model that generated random results. This model has an AUC of 0.5:  Yes, the preceding model has an AUC of 0.5, not 0.0. Most models are somewhere between the two extremes. For instance, the
following model separates positives from negatives somewhat, and therefore
has an AUC somewhere between 0.5 and 1.0:  AUC ignores any value you set forclassification threshold. Instead, AUC
considersallpossible classification thresholds. AUC represents theareaunder anROC curve.
For example,
the ROC curve for a model that perfectly separates positives from
negatives looks as follows:  AUC is the area of the gray region in the preceding illustration.
In this unusual case, the area is simply the length of the gray region
(1.0) multiplied by the width of the gray region (1.0). So, the product
of 1.0 and 1.0 yields an AUC of exactly 1.0, which is the highest possible
AUC score. Conversely, the ROC curve for a classifier that can't separate classes
at all is as follows. The area of this gray region is 0.5.  A more typical ROC curve looks approximately like the following:  It would be painstaking to calculate the area under this curve manually,
which is why a program typically calculates most AUC values. AUC is the probability that a classifier will be more confident that a
randomly chosen positive example is actually positive than that a
randomly chosen negative example is positive.",AUC,"['binary classification', 'class', 'classification threshold', 'instance', 'model', 'negative class', 'positive class', 'width']",,false,"((\s|-)?|\sAUC(\s|\.|\,)|\s(\s|\.|\,))"
DataFrame,"A popularpandasdata type for representingdatasetsin memory. A DataFrame is analogous to a table or a spreadsheet. Each column of
a DataFrame has a name (a header), and each row is identified by a
unique number. Each column in a DataFrame is structured like a 2D array, except that
each column can be assigned its own data type. See also the officialpandas.DataFrame reference
page. ",,"['pandas']",,false,"(DataFrame|\s(\s|\.|\,))"
differential privacy,"In machine learning, an anonymization approach to protect any sensitive data
(for example, an individual's personal information) included in a model'straining setfrom being exposed. This approach ensures
that themodeldoesn't learn or remember much about a specific
individual. This is accomplished by sampling and adding noise during model
training to obscure individual data points, mitigating the risk of exposing
sensitive training data. Differential privacy is also used outside of machine learning. For example,
data scientists sometimes use differential privacy to protect individual
privacy when computing product usage statistics for different demographics. ",,"['graph', 'machine learning', 'model', 'noise', 'training', 'training set']",,false,"(differential(\s|-)?privacy|\s(\s|\.|\,))"
hyperplane,"A boundary that separates a space into two subspaces. For example, a line is a
hyperplane in two dimensions and a plane is a hyperplane in three dimensions.
More typically in machine learning, a hyperplane is the boundary separating a
high-dimensional space.Kernel Support Vector Machinesuse
hyperplanes to separate positive classes from negative classes, often in a very
high-dimensional space. ",,"['class', 'dimensions', 'machine learning', 'negative class', 'positive class', 'vector']",,false,"(hyperplane|\s(\s|\.|\,))"
cost,Synonym forloss. ,,"['loss']",loss,true,"(cost|\sloss(\s|\.|\,))"
Dataset API (tf.data),"A high-level TensorFlow API for reading data and transforming it into a form that a machine learning algorithm requires.
Atf.data.Datasetobject represents a sequence of elements, in which each element contains one or moreTensors. 
Atf.data.Iteratorobject provides access to the elements of a Dataset. ",,"['machine learning', 'pipeline', 'Tensor', 'TensorFlow']",,false,"(Dataset(\s|-)?API(\s|-)?|\s(\s|\.|\,))"
image recognition,"A process that classifies object(s), pattern(s), or concept(s) in an image.
Image recognition is also known as image classification.",,"['class']",,false,"(image(\s|-)?recognit|\s(\s|\.|\,))"
trigram,AnN-gramin which N=3.,,"['N-gram']",,false,"(trigram|\s(\s|\.|\,))"
TensorBoard,"The dashboard that displays the summaries saved during the execution of one or
more TensorFlow programs.",,"['Tensor', 'TensorFlow']",,false,"(TensorBoard|\s(\s|\.|\,))"
discriminative model,"A model that predictslabelsfrom a set of one or
morefeatures. More formally, discriminative models define the
conditional probability of an output given the features andweights; that is: For example, a model that predicts whether an email is spam from features
and weights is a discriminative model. The vast majority of supervised learning models, including classification
and regression models, are discriminative models. Contrast withgenerative model. ",,"['class', 'condition', 'feature', 'generative model', 'label', 'model', 'regression model', 'weight', 'Tensor Processing Unit']",,false,"(discriminative(\s|-)?model|\s(\s|\.|\,))"
dimensions,"Overloaded term having any of the following definitions: The number of levels of coordinates in aTensor. For
example: You can uniquely specify a particular cell in a one-dimensional vector
with one coordinate; you need two coordinates to uniquely specify a
particular cell in a two-dimensional matrix. The number of entries in afeature vector. The number of elements in anembedding layer.",,"['embedding layer', 'feature', 'feature vector', 'layer', 'Tensor', 'vector']",,false,"(dimens|\s(\s|\.|\,))"
discriminator,"A system that determines whetherexamplesare real or fake. Alternatively, the subsystem within agenerative adversarial
networkthat determines whether
the examples created by thegeneratorare real or fake.",,"['generator']",,false,"(discriminator|\s(\s|\.|\,))"
Tensor,"The primary data structure in TensorFlow programs. Tensors are N-dimensional
(where N could be very large) data structures, most commonly scalars, vectors,
or matrixes. The elements of a Tensor can hold integer, floating-point,
or string values.",,"['scalar', 'TensorFlow', 'vector']",,false,"(Tensor|\s(\s|\.|\,))"
Tensor size,"The total number of scalars aTensorcontains. For example, a[5, 10]Tensor has a size of 50. ",,"['scalar', 'Tensor']",,false,"(Tensor(\s|-)?size|\s(\s|\.|\,))"
anomaly detection,"The process of identifyingoutliers. For example, if the mean
for a certainfeatureis 100 with a standard deviation of 10,
then anomaly detection should flag a value of 200 as suspicious. ",,"['feature', 'outliers', 'intersection over union']",,false,"(anomaly(\s|-)?detect|\s(\s|\.|\,))"
activation function,"A function that enablesneural networksto learnnonlinear(complex) relationships between features
and the label. Popular activation functions include: The plots of activation functions are never single straight lines.
For example, the plot of the ReLU activation function consists of
two straight lines:  A plot of the sigmoid activation function looks as follows:  In a neural network, activation functions manipulate theweighted sumof all the inputs to aneuron. To calculate a weighted sum, the neuron adds up
the products of the relevant values and weights. For example, suppose the
relevant input to a neuron consists of the following:  ",,"['feature', 'label', 'linear', 'neural network', 'neuron', 'nonlinear', 'online', 'weight', 'weighted sum', 'Rectified Linear Unit']",,false,"(activation(\s|-)?funct|\s(\s|\.|\,))"
staged training,"A tactic of training a model in a sequence of discrete stages. The goal can be
either to speed up the training process, or to achieve better model quality. An illustration of the progressive stacking approach is shown below:  See alsopipelining.",,"['model', 'pipelining', 'training']",,false,"(staged(\s|-)?train|\s(\s|\.|\,))"
Neural Architecture Search (NAS),"A technique for automatically designing the architecture of a neural network. NAS algorithms can reduce the amount of time and resources required to train a neural network. 
NAS algorithms often start with a small set of possible architectures and
gradually expand the search space as the algorithm learns more about what
architectures are effective. 
The fitness (or 'fit') function is typically based on the performance of the architecture on a training set, and the algorithm is
typically trained using a reinforcement learning technique.",,"['class', 'neural network', 'performance', 'task', 'training', 'training set']",,false,"(Neural(\s|-)?Architecture(\s|-)?Search(\s|-)?|\s(\s|\.|\,))"
feature vector,"The array offeaturevalues comprising anexample. The feature vector is input duringtrainingand duringinference.
For example, the feature vector for a model with two discrete features
might be:  Each example supplies different values for the feature vector, so the
feature vector for the next example could be something like: Feature engineeringdetermines how to represent
features in the feature vector. For example, a binary categorical feature with
five possible values might be represented withone-hot encoding. In this case, the portion of the
feature vector for a particular example would consist of four zeroes and
a single 1.0 in the third position, as follows: As another example, suppose your model consists of three features: In this case, the feature vector for each example would be represented
byninevalues. Given the example values in the preceding list, the
feature vector would be: ",,"['discrete feature', 'feature', 'feature engineering', 'inference', 'model', 'one-hot encoding', 'training', 'vector']",,false,"(feature(\s|-)?vector|\s(\s|\.|\,))"
evaluation,"The process of measuring the quality of a machine learning model'spredictions. While developing a model, you typically
apply evaluation metrics not only on thetraining setbut also on avalidation setand atest set. You can also use evaluation metrics to compare
different models to each other.",,"['machine learning', 'metric', 'model', 'prediction', 'test', 'test set', 'training', 'training set', 'validation', 'validation set']",,false,"(evaluat|\s(\s|\.|\,))"
class-imbalanced dataset,"A dataset for a classification problem in which the total number
oflabelsof each class differs significantly.
For example, consider a binary classification dataset whose two labels
are divided as follows: The ratio of negative to positive labels is 100,000 to 1, so this
is a class-imbalanced dataset. In contrast, the following dataset isnotclass-imbalanced because the
ratio of negative labels to positive labels is relatively close to 1: Multi-class datasets can also be class-imbalanced. For example, the following
multi-class classification dataset is also class-imbalanced because one label
has far more examples than the other two: See also entropy,majority class,
andminority class.",,"['binary classification', 'class', 'entropy', 'imbalanced dataset', 'label', 'majority class', 'minority class', 'multi-class classification']",,false,"(class(\s|-)?imbalanced(\s|-)?dataset|\simbalanced dataset(\s|\.|\,))"
masked language model,"Alanguage modelthat predicts the probability of
candidate tokens to fill in blanks in a sequence. For instance, a
masked language model can calculate probabilities for candidate word(s)
to replace the underline in the following sentence: The ____ in the hat came back. The literature typically uses the string ""MASK"" instead of an underline.
For example: The ""MASK"" in the hat came back. Most modern masked language models arebidirectional. ",,"['bidirectional', 'instance', 'language model', 'model', 'token']",,false,"(masked(\s|-)?language(\s|-)?model|\s(\s|\.|\,))"
output layer,"The ""final"" layer of a neural network. The output layer contains the prediction. The following illustration shows a small deep neural network with an input
layer, two hidden layers, and an output layer:",,"['deep neural network', 'hidden layer', 'layer', 'neural network', 'prediction', 'Tensor Processing Unit']",,false,"(output(\s|-)?layer|\s(\s|\.|\,))"
Metrics API (tf.metrics),"A TensorFlow API for evaluating models. For example,tf.metrics.accuracydetermines how often a model's predictions match labels.",,"['accuracy', 'label', 'metric', 'model', 'prediction', 'Tensor', 'TensorFlow']",,false,"(Metrics(\s|-)?API(\s|-)?|\s(\s|\.|\,))"
Learning Interpretability Tool (LIT),"A visual and interactive model to visualize text, image, and
tabular data.",,"['model']",,false,"(Learning(\s|-)?Interpretability(\s|-)?Tool(\s|-)?|\s(\s|\.|\,))"
reward,"In reinforcement learning, the numerical result of taking anactionin astate, as defined by
theenvironment. ",,"['action', 'environment', 'state']",,false,"(reward|\s(\s|\.|\,))"
dropout regularization,"A form of regularization useful in training neural networks. Dropout regularization
removes a random selection of a fixed number of the units in a network
layer for a single gradient step. The more units dropped out, the stronger
the regularization. This is analogous to training the network to emulate
an exponentially largeensembleof smaller networks.
For full details, seeDropout: A Simple Way to Prevent Neural Networks from
Overfitting.",,"['ensemble', 'gradient', 'layer', 'neural network', 'overfitting', 'regularization', 'step', 'training']",,false,"(dropout(\s|-)?regularizat|\s(\s|\.|\,))"
Einsum notation,"An efficient notation for describing how twotensorsare to be
combined. The tensors are combined by multiplying the elements of one tensor
by the elements of the other tensor and then summing the products.
Einsum notation uses symbols to identify the axes of each tensor, and those
same symbols are rearranged to specify the shape of the new resulting tensor. NumPyprovides a common Einsum implementation.",,"['NumPy', 'Tensor']",,false,"(Einsum(\s|-)?notat|\s(\s|\.|\,))"
context window,"The number of tokens a model can process in a given prompt. The larger the context window, the more information
the model can use to provide coherent and consistent responses to the prompt.",,"['model', 'prompt', 'token']",,false,"(context(\s|-)?window|\s(\s|\.|\,))"
contextualized language embedding,"Anembeddingthat comes close to ""understanding"" words
and phrases in ways that native human speakers can. Contextualized language
embeddings can understand complex syntax, semantics, and context. For example, consider embeddings of the English wordcow. Older embeddings
such asword2veccan represent English
words such that the distance in theembedding spacefromcowtobullis similar to the distance fromewe(female sheep) toram(male sheep) or fromfemaletomale. Contextualized language
embeddings can go a step further by recognizing that English speakers sometimes
casually use the wordcowto mean either cow or bull.",,"['embedding space', 'step']",,false,"(contextualized(\s|-)?language(\s|-)?embedd|\s(\s|\.|\,))"
continuous feature,"A floating-pointfeaturewith an infinite range of possible
values, such as temperature or weight. Contrast withdiscrete feature. ",,"['discrete feature', 'feature', 'temperature', 'weight']",,false,"(continuous(\s|-)?feature|\s(\s|\.|\,))"
convenience sampling,"Using a dataset not gathered scientifically in order to run quick
experiments. Later on, it's essential to switch to a scientifically gathered
dataset.",,[],,false,"(convenience(\s|-)?sampl|\s(\s|\.|\,))"
convex optimization,"The process of using mathematical techniques such as gradient descent to find
the minimum of a convex function.",,"['convex function', 'gradient', 'gradient descent', 'machine learning', 'intersection over union']",,false,"(convex(\s|-)?optimizat|\s(\s|\.|\,))"
feature importances,Synonym forvariable importances.,,"['variable importances']",variable importances,true,"(feature(\s|-)?importance|\svariable importances(\s|\.|\,))"
"earth mover's distance (EMD)","A measure of the relative similarity of twodis tributions.
The lower the earth mover's distance, the more similar the distributions.",,"['distribution']",,false,"(earth(\s|-)?mover's(\s|-)?distance(\s|-)?|\s(\s|\.|\,))"
featurization,"The process of extractingfeaturesfrom an input source,
such as a document or video, and mapping those features into afeature vector. Some ML experts use featurization as a synonym forfeature engineeringorfeature extraction. ",,"['action', 'feature', 'feature engineering', 'feature extraction', 'feature vector', 'vector']",,false,"(featurizat|\s(\s|\.|\,))"
federated learning,"A distributed machine learning approach thattrainsmachine learningmodelsusing decentralizedexamplesresiding on devices such as smartphones.
In federated learning, a subset of devices downloads the current model
from a central coordinating server. The devices use the examples stored
on the devices to make improvements to the model. The devices then upload
the model improvements (but not the training examples) to the coordinating
server, where they are aggregated with other updates to yield an improved
global model. After the aggregation, the model updates computed by devices
are no longer needed, and can be discarded. Since the training examples are never uploaded, federated learning follows the
privacy principles of focused data collection and data minimization. For more information about federated learning,
seethis tutorial.",,"['device', 'machine learning', 'model', 'training']",,false,"(federated(\s|-)?learn|\s(\s|\.|\,))"
fully connected layer,"Ahidden layerin which eachnodeis
connected toeverynode in the subsequent hidden layer. A fully connected layer is also known as adense layer. ",,"['dense layer', 'hidden layer', 'layer']",,false,"(fully(\s|-)?connected(\s|-)?layer|\sdense layer(\s|\.|\,))"
width,The number ofneuronsin a particularlayerof aneural network.,,"['layer', 'neural network', 'neuron']",,false,"(width|\s(\s|\.|\,))"
few-shot learning,"A machine learning approach, often used for object classification,
designed to train effective classifiers from only a small number of
training examples. See also one-shot learning and zero-shot learning.",,"['class', 'machine learning', 'one-shot learning', 'training', 'zero-shot learning']",,false,"(few(\s|-)?shot(\s|-)?learn|\s(\s|\.|\,))"
direct prompting,Synonym for zero-shot prompting.,,"['prompt', 'zero-shot prompting']",zero-shot prompting,true,"(direct(\s|-)?prompt|\szero-shot prompting(\s|\.|\,))"
function transformation,"A function that takes a function as input and returns a transformed function
as output.JAXuses function transformations. ",,"['JAX', 'return', 'Tensor Processing Unit']",,false,"(function(\s|-)?transformat|\s(\s|\.|\,))"
generalized linear model,"A generalization ofleast squares regressionmodels, which are based onGaussian
noise, to other
types of models based on other types of noise, such asPoisson noiseor
categorical noise. Examples of generalized linear models include: The parameters of a generalized linear model can be found throughconvex optimization. Generalized linear models exhibit the following properties: The power of a generalized linear model is limited by its features. Unlike
a deep model, a generalized linear model cannot ""learn new features."" ",,"['convex optimization', 'deep model', 'feature', 'generalization', 'least squares regression', 'linear', 'linear model', 'model', 'noise', 'parameter']",,false,"(generalized(\s|-)?linear(\s|-)?model|\s(\s|\.|\,))"
crash blossom,"A sentence or phrase with an ambiguous meaning.
Crash blossoms present a significant problem innatural
language understanding.
For example, the headlineRed Tape Holds Up Skyscraperis a
crash blossom because an NLU model could interpret the headline literally or
figuratively.",,"['loss', 'model']",,false,"(crash(\s|-)?blossom|\s(\s|\.|\,))"
episode,"In reinforcement learning, each of the repeated attempts by theagentto learn anenvironment.",,"['agent', 'environment']",,false,"(episode|\s(\s|\.|\,))"
fine tuning,"A second, task-specific training pass performed on apre-trained modelto refine its parameters for a
specific use case. For example, the full training sequence for somelarge language modelsis as follows: As another example, the full training sequence for a large image model is as
follows: Fine-tuning can entail any combination of the following strategies: Fine-tuning is a form oftransfer learning.
As such, fine-tuning might use a different loss function or a different model
type than those used to train the pre-trained model. For example, you could
fine-tune a pre-trained large image model to produce a regression model that
returns the number of birds in an input image. Compare and contrast fine-tuning with the following terms:",,"['language model', 'large language model', 'loss', 'loss function', 'model', 'parameter', 'pre-trained model', 'regression model', 'return', 'task', 'training', 'transfer learning']",,false,"(fine(\s|-)?tun|\s(\s|\.|\,))"
generalization,"A model'sability to make correct predictions on new,
previously unseen data. A model that can generalize is the opposite
of a model that is overfitting. You train a model on the examples in the training set. Consequently, the
model learns the peculiarities of the data in the training set. Generalization
essentially asks whether your model can make good predictions on examples
that arenotin the training set. To encourage generalization,regularizationhelps a model train
less exactly to the peculiarities of the data in the training set.",,"['model', 'overfitting', 'prediction', 'regularization', 'training', 'training set', 'intersection over union', 'retrieval-augmented generation']",,false,"(generalizat|\s(\s|\.|\,))"
deep neural network,Synonym fordeep model.,,"['deep model', 'model']",deep model,true,"(deep(\s|-)?neural(\s|-)?network|\sdeep model(\s|\.|\,))"
Bellman equation,"The core equation in the Q-function: which is used to help identify the optimal Q-function. 
Beyond reinforcement learning, the Bellman equation has applications to
dynamic programming.",,"['dynamic', 'Q-function', 'Q-learning', 'large language model']",,false,"(Bellman(\s|-)?equat|\s(\s|\.|\,))"
few-shot prompting,"A prompt that contains more than one (a ""few"") example demonstrating how the large language modelshould respond. For example, the following lengthy prompt contains two
examples showing a large language model how to answer a query. Few-shot prompting generally produces more desirable results thanzero-shot promptingandone-shot prompting. However, few-shot prompting
requires a lengthier prompt. Few-shot prompting is a form offew-shot learningapplied toprompt-based learning.",,"['few-shot learning', 'language model', 'large language model', 'model', 'one-shot prompting', 'prompt', 'prompt-based learning', 'zero-shot prompting']",,false,"(few(\s|-)?shot(\s|-)?prompt|\sin-context learning(\s|\.|\,))"
generalization curve,"A plot of both training loss and validation loss as a function of the number ofiterations. A generalization curve can help you detect possible overfitting. For example, the following
generalization curve suggests overfitting because validation loss
ultimately becomes significantly higher than training loss.  ",,"['generalization', 'iteration', 'loss', 'overfitting', 'training', 'training loss', 'validation', 'validation loss']",,false,"(generalization(\s|-)?curve|\s(\s|\.|\,))"
implicit bias,"Automatically making an association or assumption based on one's mind
models and memories. Implicit bias can affect the following: For example, when building a classifier to identify wedding photos,
an engineer may use the presence of a white dress in a photo as a feature.
However, white dresses have been customary only during certain eras and
in certain cultures. See alsoconfirmation bias. ",,"['class', 'confirmation bias', 'feature', 'model']",,false,"(implicit(\s|-)?bia|\s(\s|\.|\,))"
L2 loss,"A loss function that calculates the square
of the difference between actuallabelvalues and
the values that amodelpredicts. For example, here's the
calculation of L2loss for abatchof fiveexamples: Due to squaring, L2loss amplifies the influence ofoutliers.
That is, L2loss reacts more strongly to bad predictions thanL1loss. For example, the L1loss
for the preceding batch would be 8 rather than 16. Notice that a single
outlier accounts for 9 of the 16. Regression modelstypically use L2loss
as the loss function. The Mean Squared Erro ris the average
L2loss per example.Squared lossis another name for L2loss. $$ L_2 loss = \sum_{i=0}^n {(y_i - \hat{y}_i)}^2$$",,"['batch', 'L1loss', 'label', 'loss', 'loss function', 'model', 'outliers', 'prediction', 'regression model', 'squared loss', 'retrieval-augmented generation']",,false,"(L2loss|\ssquared loss(\s|\.|\,))"
nonstationarity,"A feature whose values change across one or more dimensions, usually time.
For example, consider the following examples of nonstationarity: Contrast withstationarity.",,"['dimensions', 'feature', 'stationarity']",,false,"(nonstationarity|\s(\s|\.|\,))"
TPU Pod,"A specific configuration ofTPU devicesin a Google
data center. All of the devices in a TPU Pod are connected to one another
over a dedicated high-speed network. A TPU Pod is the largest configuration ofTPU devicesavailable for a specific TPU version.",,"['configuration', 'device', 'TPU device', 'Tensor Processing Unit']",,false,"(TPU(\s|-)?Pod|\s(\s|\.|\,))"
Wasserstein loss,"One of the loss functions commonly used in generative adversarial networks,
based on theearth mover's distancebetween
the distribution of generated data and real data.",,"['distribution', 'loss', 'loss function']",,false,"(Wasserstein(\s|-)?los|\s(\s|\.|\,))"
TPU chip,"A programmable linear algebra accelerator with on-chip high bandwidth memory
that is optimized for machine learning workloads.
Multiple TPU chips are deployed on aTPU device.",,"['device', 'linear', 'machine learning', 'TPU device', 'width', 'Tensor Processing Unit']",,false,"(TPU(\s|-)?chip|\s(\s|\.|\,))"
TPU master,"The central coordination process running on a host machine that sends and
receives data, results, programs, performance, and system health information
to theTPU workers. The TPU master also manages the setup
and shutdown ofTPU devices.",,"['device', 'host', 'performance', 'TPU device', 'TPU worker', 'Tensor Processing Unit']",,false,"(TPU(\s|-)?master|\s(\s|\.|\,))"
TPU node,"A TPU resource on Google Cloud with a specificTPU type. The TPU node connects to yourVPC Networkfrom apeer VPC network.
TPU nodes are a resource defined in theCloud TPU API.",,"['Cloud TPU', 'TPU resource', 'TPU type', 'Tensor Processing Unit']",,false,"(TPU(\s|-)?node|\s(\s|\.|\,))"
Pax,"A programming framework designed for training large-scale neural networkmodels so large
that they span multiple TPU accelerator chips lices or pods. Pax is built onFlax, which is built on JAX.  ",,"['accelerator chip', 'Flax', 'JAX', 'model', 'neural network', 'training', 'Tensor Processing Unit']",,false,"(Pax|\s(\s|\.|\,))"
Mean Absolute Error (MAE),"The average loss per example when L1l oss is
used. Calculate Mean Absolute Error as follows: $$\text{Mean Absolute Error} = \frac{1}{n}\sum_{i=0}^n | y_i - \hat{y}_i |$$ where: For example, consider the calculation of L1loss on the
following batch of five examples: So, L1loss is 8 and the number of examples is 5.
Therefore, the Mean Absolute Error is: Contrast Mean Absolute Error withMean Squared ErrorandRoot Mean Squared Error. ",,"['batch', 'L1loss', 'loss', 'root', 'retrieval-augmented generation']",,false,"(Mean(\s|-)?Absolute(\s|-)?Error(\s|-)?|\s(\s|\.|\,))"
ROC (receiver operating characteristic) Curve,"A graph oftrue positive rateversusfalse positive ratefor differentclassification thresholdsin binary
classification. The shape of an ROC curve suggests a binary classification model's ability
to separate positive classes from negative classes. Suppose, for example,
that a binary classification model perfectly separates all the negative
classes from all the positive classes:  The ROC curve for the preceding model looks as follows:  In contrast, the following illustration graphs the raw logistic regression
values for a terrible model that can't separate negative classes from
positive classes at all:  The ROC curve for this model looks as follows:  Meanwhile, back in the real world, most binary classification models separate
positive and negative classes to some degree, but usually not perfectly. So,
a typical ROC curve falls somewhere between the two extremes:  The point on an ROC curve closest to (0.0,1.0) theoretically identifies the
ideal classification threshold. However, several other real-world issues
influence the selection of the ideal classification threshold. For example,
perhaps false negatives cause far more pain than false positives. A numerical metric calledAUCsummarizes the ROC curve into
a single floating-point value.",,"['binary classification', 'class', 'classification model', 'classification threshold', 'graph', 'logistic regression', 'metric', 'model', 'negative class', 'positive class']",,false,"(ROC(\s|-)?(\s|-)?Curve|\s(\s|\.|\,))"
Rectified Linear Unit,"Anactivation functionwith the following behavior: For example: Here is a plot of ReLU:  ReLU is a very popular activation function. Despite its simple behavior,
ReLU still enables a neural network to learnnonlinearrelationships betweenfeaturesand thelabel.",ReLU,"['activation function', 'feature', 'label', 'linear', 'neural network', 'nonlinear', 'online']",,false,"(Rectified(\s|-)?Linear(\s|-)?Unit|\sReLU(\s|\.|\,)|\s(\s|\.|\,))"
Praxis,"A core, high-performance ML library of Pax. Praxis is often
called the ""Layer library"". Praxis contains not just the definitions for the Layer class, but most of
its supporting components as well, including: Praxis provides the definitions for the Model class. ",,"['class', 'layer', 'model', 'Pax', 'performance']",,false,"(Praxis|\s(\s|\.|\,))"
R-squared,"A regression metric indicating how much variation in a label is due to an individual feature or to a feature set.
R-squared is a value between 0 and 1, which you can interpret as follows: R-squared is the square of the Pearson correlation
coefficientbetween the values that a model predicted andground truth. ",,"['feature', 'feature set', 'ground truth', 'label', 'metric', 'model']",,false,"(R(\s|-)?squared|\s(\s|\.|\,))"
Gradient Scaling,TBC,,,,,(Gradient(\s|-)?Scal)
queue,"A TensorFlowOperationthat implements a queue data
structure. Typically used in I/O. ",,"['Tensor', 'TensorFlow']",,false,"(queue|\s(\s|\.|\,))"
upweighting,"Applying a weight to thedownsampledclass equal
to the factor by which you downsampled.",,"['class', 'weight']",,false,"(upweight|\s(\s|\.|\,))"
sparse vector,"A vector whose values are mostly zeroes. See alsosparse
featureandsparsity. ",,"['feature', 'sparsity', 'vector']",,false,"(sparse(\s|-)?vector|\s(\s|\.|\,))"
Transformer,"Aneural networkarchitecture developed at Google that
relies onself-attentionmechanisms to transform a
sequence of input embeddings into a sequence of output
embeddings without relying onconvolutionsorrecurrent neural networks. A Transformer can be
viewed as a stack of self-attention layers. A Transformer can include any of the following: Anencodertransforms a sequence of embeddings into a new sequence of the
same length. An encoder includes N identical layers, each of which contains two
sub-layers. These two sub-layers are applied at each position of the input
embedding sequence, transforming each element of the sequence into a new
embedding. The first encoder sub-layer aggregates information from across the
input sequence. The second encoder sub-layer transforms the aggregated
information into an output embedding. Adecodertransforms a sequence of input embeddings into a sequence of
output embeddings, possibly with a different length. A decoder also includes
N identical layers with three sub-layers, two of which are similar to the
encoder sub-layers. The third decoder sub-layer takes the output of the
encoder and applies theself-attentionmechanism to
gather information from it. The blog postTransformer: A Novel Neural Network Architecture for Language
Understandingprovides a good introduction to Transformers.",,"['attention', 'convolution', 'decoder', 'encoder', 'layer', 'neural network', 'recurrent neural network', 'Tensor Processing Unit']",,false,"(Transformer|\s(\s|\.|\,))"
Weighted Alternating Least Squares (WALS),"An algorithm for minimizing the objective function during matrix factorization in recommendation systems, which allows a
downweighting of the missing examples. WALS minimizes the weighted
squared error between the original matrix and the reconstruction by
alternating between fixing the row factorization and column factorization.
Each of these optimizations can be solved by least squaresconvex optimization.",,"['convex optimization', 'matrix factorization', 'objective', 'objective function', 'recommendation system', 'weight']",,false,"(Weighted(\s|-)?Alternating(\s|-)?Least(\s|-)?Squares(\s|-)?|\s(\s|\.|\,))"
in-context learning,Synonym for few-shot prompting.,,"['few-shot prompting', 'prompt']",few-shot prompting,true,"(in(\s|-)?context(\s|-)?learn|\sfew-shot prompting(\s|\.|\,))"
gini impurity,"A metric similar toentropy.Splittersuse values derived from either gini impurity or entropy to composeconditionsfor classificationdecision trees.Information gainis derived from entropy.
There is no universally accepted equivalent term for the metric derived
from gini impurity; however, this unnamed metric is just as important as
information gain. Gini impurity is also calledgini index, or simplygini. Gini impurity is the probability of misclassifying a new piece of data
taken from the same distribution. The gini impurity of a set with two
possible values ""0"" and ""1"" (for example, the labels in abinary classificationproblem)
is calculated from the following formula: I = 1 - (p2+ q2) = 1 - (p2+ (1-p)2) where: For example, consider the following dataset: Therefore, the gini impurity is: Consequently, a random label from the same dataset would have a 37.5% chance
of being misclassified, and a 62.5% chance of being properly classified. A perfectly balanced label (for example, 200 ""0""s and 200 ""1""s) would have a
gini impurity of 0.5. A highlyimbalancedlabel would have a
gini impurity close to 0.0. ",,"['binary classification', 'class', 'condition', 'decision tree', 'distribution', 'entropy', 'information gain', 'label', 'metric', 'split', 'splitter']",,false,"(gini(\s|-)?impurity|\s(\s|\.|\,))"
hashing,"In machine learning, a mechanism for bucketingcategorical data, particularly when the number
of categories is large, but the number of categories actually appearing
in the dataset is comparatively small. For example, Earth is home to about 73,000 tree species. You could
represent each of the 73,000 tree species in 73,000 separate categorical
buckets. Alternatively, if only 200 of those tree species actually appear
in a dataset, you could use hashing to divide tree species into
perhaps 500 buckets. A single bucket could contain multiple tree species. For example, hashing
could placebaobabandred maple‚Äîtwo genetically dissimilar
species‚Äîinto the same bucket. Regardless, hashing is still a good way to
map large categorical sets into the selected number of buckets. Hashing turns a
categorical feature having a large number of possible values into a much
smaller number of values by grouping values in a
deterministic way. ",,"['bucketing', 'categorical data', 'feature', 'machine learning']",,false,"(hashing|\s(\s|\.|\,))"
gradient clipping,"A commonly used mechanism to mitigate the exploding gradient problem by artificially
limiting (clipping) the maximum value of gradients when using gradient descent to train a model.",,"['clipping', 'exploding gradient problem', 'gradient', 'gradient descent', 'model']",,false,"(gradient(\s|-)?clipp|\s(\s|\.|\,))"
divisive clustering,Seehierarchical clustering.,,"['clustering', 'hierarchical clustering']",,false,"(divisive(\s|-)?cluster|\s(\s|\.|\,))"
action,"In reinforcement learning,
the mechanism by which the agent transitions between states of the environment. The agent chooses the action by using a policy.",,"['agent', 'environment', 'policy', 'state']",,false,"(action|\s(\s|\.|\,))"
gradient boosted (decision) trees (GBT),A type of decision forest in which...,,"['decision forest']",,false,"(gradient(\s|-)?boosted(\s|-)?(\s|-)?trees(\s|-)?|\s(\s|\.|\,))"
leaf,"Any endpoint in adecision tree. Unlike acondition, a leaf doesn't perform a test.
Rather, a leaf is a possible prediction. A leaf is also the terminalnodeof aninference path. For example, the following decision tree contains three leaves:  ",,"['condition', 'decision tree', 'inference', 'inference path', 'prediction', 'test']",,false,"(leaf|\s(\s|\.|\,))"
loss surface,"A graph of weight(s) versus loss. Gradient descent aims
to find the weight(s) for which the loss surface is at a local minimum.",,"['gradient', 'gradient descent', 'graph', 'loss', 'weight']",,false,"(loss(\s|-)?surface|\s(\s|\.|\,))"
ground truth,"Reality. The thing that actually happened. For example, consider a binary classification model that predicts whether a student in their first year of university
will graduate within six years. Ground truth for this model is whether or
not that student actually graduated within six years. We assess model quality against ground truth. However, ground truth
is not always completely, well, truthful. For example, consider the
following examples of potential imperfections in ground truth:",,"['binary classification', 'class', 'model']",,false,"(ground(\s|-)?truth|\s(\s|\.|\,))"
gradient descent,A mathematical technique that iteratively adjusts weights and biases to gradually find the best combination that minimizes loss.,,"['gradient', 'loss', 'machine learning', 'weight']",,false,"(gradient(\s|-)?descent|\s(\s|\.|\,))"
bias (math) or bias term,"An intercept or offset from an origin. Bias is a parameter in
machine learning models, which is symbolized by either of the
following: For example, bias is thebin the following formula: In a simple two-dimensional line, bias just means ""y-intercept.""
For example, the bias of the line in the following illustration is 2.  Bias exists because not all models start from the origin (0,0). For example,
suppose an amusement park costs 2 Euros to enter and an additional
0.5 Euro for every hour a customer stays. Therefore, a model mapping the
total cost has a bias of 2 because the lowest cost is 2 Euros. Bias is not to be confused withbias in ethics and fairnessorprediction bias.",,"['cost', 'machine learning', 'model', 'parameter', 'prediction', 'prediction bias']",,false,"(bias(\s|-)?(\s|-)?or(\s|-)?bias(\s|-)?term|\s(\s|\.|\,))"
oblique condition,"In adecision tree, aconditionthat involves more than onefeature. For example, if height and width are both features,
then the following is an oblique condition: Contrast withaxis-aligned condition.",,"['axis-aligned condition', 'condition', 'decision tree', 'feature', 'width']",,false,"(oblique(\s|-)?condit|\s(\s|\.|\,))"
serving,The process of making a trained model available to provide predictions throughonline inferenceoroffline inference. ,,"['inference', 'model', 'offline', 'offline inference', 'online', 'online inference', 'prediction']",,false,"(serving|\s(\s|\.|\,))"
text span,"The array index span associated with a specific subsection of a text string.
For example, the wordgoodin the Python strings=""Be good now""occupies
the text span from 3 to 6.",,[],,false,"(text(\s|-)?span|\s(\s|\.|\,))"
dimension reduction,"Decreasing the number of dimensions used to represent a particular feature
in a feature vector, typically by
converting to an embedding vector. ",,"['dimensions', 'embedding vector', 'feature', 'feature vector', 'vector']",,false,"(dimension(\s|-)?reduct|\s(\s|\.|\,))"
quantization,"A technique to reduce the number of bits required to store model parameters (e.g. weights and biases).
Quantization converts the model parameters from 32 bits down to 4, 8, or 16 bits. 
Quantization may result in a decrease in the model's performance. ",,"['model', 'parameter', 'prediction']",,false,"(quantizat|\s(\s|\.|\,))"
classification model,"Amodelwhose prediction is aclass.
For example, the following are all classification models: In contrast,regression modelspredict numbers
rather than classes. Two common types of classification models are:",,"['class', 'model', 'prediction', 'regression model']",,false,"(classification(\s|-)?model|\s(\s|\.|\,))"
co-adaptation,"When neurons predict patterns in training data by relying
almost exclusively on outputs of specific other neurons instead of relying on
the network's behavior as a whole. When the patterns that cause co-adaptation
are not present in validation data, then co-adaptation causes overfitting. Dropout regularization reduces co-adaptation
because dropout ensures neurons cannot rely solely on specific other neurons.",,"['dropout regularization', 'neuron', 'overfitting', 'regularization', 'training', 'validation', 'Tensor Processing Unit']",,false,"(co(\s|-)?adaptat|\s(\s|\.|\,))"
clipping,"A technique for handling outliers by doing
either or both of the following: For example, suppose that <0.5% of values for a particular feature fall
outside the range 40‚Äì60. In this case, you could do the following: Outliers can damage models, sometimes causingweightsto overflow during training. Some outliers can also dramatically spoil
metrics likeaccuracy. Clipping is a common technique to limit
the damage. Gradient clippingforcesgradientvalues within a designated range during training.",,"['accuracy', 'feature', 'gradient', 'gradient clipping', 'metric', 'model', 'outliers', 'training', 'weight']",,false,"(clipping|\s(\s|\.|\,))"
convex set,"A subset of Euclidean space such that a line drawn between any two points in the
subset remains completely within the subset. For instance, the following two
shapes are convex sets:  In contrast, the following two shapes are not convex sets:",,"['instance']",,false,"(convex(\s|-)?set|\s(\s|\.|\,))"
data parallelism,"A way of scalingtrainingorinferencethat replicates an entiremodelonto
multiple devices and then passes a subset of the input data to each device.
Data parallelism can enable training and inference on very largebatch sizes; however, data parallelism requires that the
model be small enough to fit on all devices. Data parallelism typically speeds training and inference. See alsomodel parallelism.",,"['batch', 'batch size', 'device', 'inference', 'model', 'model parallelism', 'replica', 'scaling', 'training']",,false,"(data(\s|-)?parallelism|\s(\s|\.|\,))"
splitter,"While training a decision tree, the routine
(and algorithm) responsible for finding the best condition at each node. ",,"['condition', 'decision tree', 'training']",,false,"(splitter|\s(\s|\.|\,))"
state,"In reinforcement learning, the parameter values that describe the current configuration of the environment, which the agent uses to choose an action.",,"['action', 'agent', 'configuration', 'environment', 'parameter']",,false,"(state|\s(\s|\.|\,))"
one-shot prompting,"A prompt that contains one example demonstrating how the large language modelshould respond. For example,
the following prompt contains one example showing a large language model how
it should answer a query.",,"['language model', 'large language model', 'model', 'prompt']",,false,"(one(\s|-)?shot(\s|-)?prompt|\s(\s|\.|\,))"
ridge regularization,"Synonym for L2 regularization. The termridge regularizationis more frequently used in pure statistics
contexts, whereasL2regularizationis used more often
in machine learning.",,"['L2regularization', 'machine learning', 'regularization']",l2regularization,true,"(ridge(\s|-)?regularizat|\sL2regularization(\s|\.|\,))"
intersection over union,"The intersection of two sets divided by their union. In machine-learning
image-detection tasks, IoU is used to measure the accuracy of the model's
predicted bounding box with respect to the ground-truth bounding box. In this case, the IoU for the two boxes is the ratio between the overlapping area and the total area, and
its value ranges from 0 (no overlap of predicted bounding box and ground-truth
bounding box) to 1 (predicted bounding box and ground-truth bounding box have
the exact same coordinates). For example, in the image below:  Here, the intersection of the bounding boxes for prediction and ground truth
(below left) is 1, and the union of the bounding boxes for prediction and
ground truth (below right) is 7, so the IoU is \(\frac{1}{7}\). ",IoU,"['accuracy', 'bounding box', 'ground truth', 'model', 'prediction', 'task']",,false,"(intersection(\s|-)?over(\s|-)?un|\sIoU(\s|\.|\,)|\s(\s|\.|\,))"
inference path,"In adecision tree, duringinference,
the route a particularexampletakes from therootto otherconditions, terminating with
aleaf. For instance, in the following decision tree, the
thicker arrows show the inference path for an example with the following
feature values: The inference path in the following illustration travels through three
conditions before reaching the leaf (Zeta).  The three thick arrows show the inference path.",,"['condition', 'decision tree', 'feature', 'inference', 'instance', 'leaf', 'root']",,false,"(inference(\s|-)?path|\s(\s|\.|\,))"
information gain,"Indecision forests, the difference between
a node'sentropyand the weighted (by number of examples)
sum of the entropy of its children nodes. A node's entropy is the entropy
of the examples in that node. For example, consider the following entropy values: So 40% of the examples are in one child node and 60% are in the
other child node. Therefore: So, the information gain is: Mostsplittersseek to createconditionsthat maximize information gain.",,"['condition', 'decision forest', 'entropy', 'split', 'splitter', 'weight']",,false,"(information(\s|-)?gain|\s(\s|\.|\,))"
input generator,"A mechanism by which data is loaded into
aneural network. An input generator can be thought of as a component responsible for processing
raw data into tensors which are iterated over to generate batches for
training, evaluation, and inference.",,"['batch', 'evaluation', 'generator', 'inference', 'neural network', 'Tensor', 'training']",,false,"(input(\s|-)?generator|\s(\s|\.|\,))"
inter-rater agreement,"A measurement of how often human raters agree when doing a task.
If raters disagree, the task instructions may need to be improved.
Also sometimes calledinter-annotator agreementorinter-rater reliability. See alsoCohen's
kappa,
which is one of the most popular inter-rater agreement measurements.",,"['rater', 'task']",,false,"(inter(\s|-)?rater(\s|-)?agreement|\s(\s|\.|\,))"
feature set,"The group offeaturesyour machine learningmodeltrains on.
For example, postal code, property size, and property condition might
comprise a simple feature set for a model that predicts housing prices.",,"['condition', 'feature', 'machine learning', 'model']",,false,"(feature(\s|-)?set|\s(\s|\.|\,))"
distillation,"The process of reducing the size of one model (known as the teacher) into a smaller model (known as the student) that emulates
the original model's predictions as faithfully as possible. Distillation
is useful because the smaller model has two key benefits over the larger
model (the teacher): However, the student's predictions are typically not as good as
the teacher's predictions. Distillation trains the student model to minimiz e aloss function based on the difference between the outputs of the predictions of the student and teacher models.",,"['loss', 'loss function', 'model', 'prediction', 'Tensor Processing Unit']",,false,"(distillat|\s(\s|\.|\,))"
eager execution,"A TensorFlow programming environment in whichoperationsrun immediately. In contrast, operations called ingraph executiondon't run until they are explicitly
evaluated. Eager execution is animperative interface, much
like the code in most programming languages. Eager execution programs are
generally far easier to debug than graph execution programs.",,"['environment', 'graph', 'graph execution', 'Tensor', 'TensorFlow']",,false,"(eager(\s|-)?execut|\s(\s|\.|\,))"
instruction tuning,"A form of fine-tuning that improves a generative AI model's ability to follow
instructions. Instruction tuning involves training a model on a series
of instruction prompts, typically covering a wide
variety of tasks. The resulting instruction-tuned model then tends to
generate useful responses tozero-shot promptsacross a variety of tasks. Compare and contrast with:",,"['generative AI', 'model', 'prompt', 'task', 'training']",,false,"(instruction(\s|-)?tun|\s(\s|\.|\,))"
item matrix,"Inrecommendation systems, a
matrix ofembedding vectorsgenerated bymatrix factorizationthat holds latent signals about eachitem.
Each row of the item matrix holds the value of a single latent
feature for all items.
For example, consider a movie recommendation system. Each column
in the item matrix represents a single movie. The latent signals
might represent genres, or might be harder-to-interpret
signals that involve complex interactions among genre, stars,
movie age, or other factors. The item matrix has the same number of columns as the target
matrix that is being factorized. For example, given a movie
recommendation system that evaluates 10,000 movie titles, the
item matrix will have 10,000 columns.",,"['action', 'embedding vector', 'feature', 'items', 'matrix factorization', 'recommendation system', 'target', 'vector']",,false,"(item(\s|-)?matrix|\s(\s|\.|\,))"
label,"Insupervised machine learning, the
""answer"" or ""result"" portion of anexample. Eachlabeled exampleconsists of one or morefeaturesand a label. For instance, in a spam
detection dataset, the label would probably be either ""spam"" or
""not spam."" In a rainfall dataset, the label might be the amount of
rain that fell during a certain period.",,"['feature', 'instance', 'labeled example', 'machine learning', 'supervised machine learning']",,false,"(label|\starget(\s|\.|\,))"
label leakage,"A model design flaw in which afeatureis a proxy for thelabel. For example, consider abinary classificationmodel that predicts
whether or not a prospective customer will purchase a particular product.
Suppose that one of the features for the model is a Boolean namedSpokeToCustomerAgent. Further suppose that a customer agent is only
assignedafterthe prospective customer has actually purchased the
product. During training, the model will quickly learn the association
betweenSpokeToCustomerAgentand the label.",,"['agent', 'binary classification', 'class', 'feature', 'label', 'model', 'training', 'retrieval-augmented generation']",,false,"(label(\s|-)?leakage|\s(\s|\.|\,))"
false negative rate,"The proportion of actual positive examples for which the model mistakenly
predicted the negative class. The following formula calculates the false
negative rate:",,"['class', 'model', 'negative class']",,false,"(false(\s|-)?negative(\s|-)?rate|\s(\s|\.|\,))"
edit distance,"A measurement of how similar two text strings are to each other.
In machine learning, edit distance is useful because it is simple to
compute, and an effective way to compare two strings that are known to be
similar or to find strings that are similar to a given string. There are several definitions of edit distance, each using different string
operations. For example, theLevenshtein distanceconsiders the fewest delete, insert, and substitute operations. For example, the Levenshtein distance between the words ""heart"" and ""darts""
is 3 because the following 3 edits are the fewest changes to turn one word
into the other: ",,"['machine learning']",,false,"(edit(\s|-)?distance|\s(\s|\.|\,))"
embedding space,"The d-dimensional vector space that features from a higher-dimensional
vector space are mapped to. Ideally, the embedding space contains a
structure that yields meaningful mathematical results; for example,
in an ideal embedding space, addition and subtraction of embeddings
can solve word analogy tasks. Thedot productof two embeddings is a measure of their similarity.",,"['action', 'feature', 'task', 'vector']",,false,"(embedding(\s|-)?space|\slatent space(\s|\.|\,))"
environment,"In reinforcement learning, the world that contains theagentand allows the agent to observe that world'sstate. For example,
the represented world can be a game like chess, or a physical world like a
maze. When the agent applies anactionto the environment,
then the environment transitions between states.",,"['action', 'agent', 'state']",,false,"(environment|\s(\s|\.|\,))"
empirical risk minimization (ERM),"Choosing the function that minimizes loss on the training set. Contrast
withstructural risk minimization.",,"['loss', 'training', 'training set']",,false,"(empirical(\s|-)?risk(\s|-)?minimization(\s|-)?|\s(\s|\.|\,))"
linear regression,"A type of machine learning model in which both of the following are true: Contrast linear regression withlogistic regression.
Also, contrast regression withclassification. ",,"['class', 'linear', 'logistic regression', 'machine learning', 'model']",,false,"(linear(\s|-)?regress|\s(\s|\.|\,))"
multi-head self-attention,"An extension ofself-attentionthat applies the
self-attention mechanism multiple times for each position in the input sequence. Transformersintroduced multi-head self-attention.",,"['attention', 'Transformer']",,false,"(multi(\s|-)?head(\s|-)?self(\s|-)?attent|\s(\s|\.|\,))"
predictive ML,"Any standard (""classic"")machine learningsystem. The termpredictive MLdoesn't have a formal definition.
Rather, the term distinguishes a category of ML systemsnotbased ongenerative AI.",,"['class', 'generative AI', 'machine learning']",,false,"(predictive(\s|-)?ML|\s(\s|\.|\,))"
predictive parity,"Afairness metricthat checks whether,
for a given classifier, theprecisionrates
are equivalent for subgroups under consideration. For example, a model that predicts college acceptance would satisfy
predictive parity for nationality if its precision rate is the same
for Lilliputians and Brobdingnagians. Predictive parity is sometime also calledpredictive rate parity. See""Fairness Definitions
Explained""(section 3.2.1)
for a more detailed discussion of predictive parity.",,"['class', 'fairness metric', 'metric', 'model', 'precision', 'predictive rate parity']",,false,"(predictive(\s|-)?parity|\s(\s|\.|\,))"
temporal data,"Data recorded at different points in time. For example, winter coat sales
recorded for each day of the year would be temporal data.",,[],,false,"(temporal(\s|-)?data|\s(\s|\.|\,))"
tf.Example,A standardprotocol bufferfor describing input data for machine learning model training or inference.,,"['inference', 'machine learning', 'model', 'model training', 'training']",,false,"(tf.Example|\s(\s|\.|\,))"
unidirectional,"A system that only evaluates the text thatprecedesa target section of text.
In contrast, a bidirectional system evaluates both the
text thatprecedesandfollowsa target section of text.
Seebidirectionalfor more details.",,"['bidirectional', 'target']",,false,"(unidirectional|\s(\s|\.|\,))"
Gradient checkpointing,"Sometimes even using small batch size and other optimization techniques, e.g. Gradient Accumulation, Freezing, or Automatic Precision Training, we still can run out of memory, especially in cases when the models are large enough. One of the proposed powerful solutions for solving this issue is Gradient Checkpointing, which was firstly introduced in the ""Training Deep Nets With Sublinear Memory Cost"" paper in 2016. The authors demonstrated that Gradient Checkpointing can significantly reduce memory utilization from  
O
(
n
)
  to  
O
(
‚àö
n
)
 , where  
n
  is the number of layers in the model. This approach allows training large models on a single GPU or provides more memory for increasing the batch size for better and faster convergence.",,"['gradient', 'checkpoint', 'optimization']",,false,(Gradient(\s|-)?checkpoint)
dense layer,Synonym forfully connected layer.,,"['fully connected layer', 'layer']",fully connected layer,true,"(dense(\s|-)?layer|\sfully connected layer(\s|\.|\,))"
tabular Q-learning,"In Q-learning, an implementation using a table to store the Q-functions for every combination of state and action. ",,"['action', 'Q-function', 'Q-learning', 'state']",,false,"(tabular(\s|-)?Q(\s|-)?learn|\s(\s|\.|\,))"
mini-batch stochastic gradient descent,"An Optimizer (gradient descent algorithm) that uses mini-batches. In other words, mini-batch stochastic gradient descent estimates the gradient based on a small subset of the training data. ",,"['batch', 'gradient', 'gradient descent', 'mini-batch', 'training']",,false,"(mini(\s|-)?batch(\s|-)?stochastic(\s|-)?gradient(\s|-)?descent|\s(\s|\.|\,))"
gradient accumulation,"A backpropagation technique that updates the parameters only once per epoch rather than once per iteration. The idea is to simulate a larger batch size. Sometimes using a large batch size is necessary for better convergence or improving the performance, however, it often requires a lot of memory. ",,"['backpropagation', 'batch', 'batch size', 'epoch', 'gradient', 'iteration', 'mini-batch', 'model', 'parameter', 'parameter update', 'training']",,false,"(gradient(\s|-)?accumulat|\s(\s|\.|\,))"
one-shot learning,"A machine learning approach, often used for object classification,
designed to learn effective classifiers from a single training example. See alsofew-shot learningandzero-shot learning.",,"['class', 'few-shot learning', 'machine learning', 'training', 'zero-shot learning']",,false,"(one(\s|-)?shot(\s|-)?learn|\s(\s|\.|\,))"
prompt design,Synonym for prompt engineering.,,"['prompt', 'prompt engineering']",prompt engineering,true,"(prompt(\s|-)?design|\sprompt engineering(\s|\.|\,))"
instance,Synonym forexample.,,[],example,false,"(instance|\sexample(\s|\.|\,))"
landmarks,Synonym forkeypoints.,,"['keypoints']",keypoints,true,"(landmark|\skeypoints(\s|\.|\,))"
k-median,A clustering algorithm closely related to k-means.,,"['clustering', 'k-means']",,false,"(k(\s|-)?median|\s(\s|\.|\,))"
feature extraction,Overloaded term having either of the following definitions:,,[],,false,"(feature(\s|-)?extract|\s(\s|\.|\,))"
GPT,"A family ofTransformer-basedlarge language modelsdeveloped byOpenAI. GPT variants can apply to multiplemodalities, including: ",GPT,"['language model', 'large language model', 'model', 'Transformer']",,false,"(|\sGPT(\s|\.|\,)|\s(\s|\.|\,))"
generator,"The subsystem within agenerative adversarial
networkthat creates newexamples. Contrast withdiscriminative model.",,"['discriminative model', 'model']",,false,"(generator|\s(\s|\.|\,))"
Parameter-efficient fine-tuning (PEFT),"A set of techniques to fine-tune a large pre-trained language model (PLM) more efficiently than full fine-tuning. Parameter-efficient
tuning typically fine-tunes far fewerparametersthan full
fine-tuning, yet generally produces alarge language modelthat performs
as well (or almost as well) as a large language model built from full fine-tuning. 
Parameter-efficient tuning is also known as parameter-efficient fine-tuning.",,"['language model', 'large language model', 'model', 'parameter']",,false,"(parameter(\s|-)?efficient(\s|-)?tun|\s(\s|\.|\,))"
overfitting,"Creating a modelthat matches the training data so closely that the model fails to
make correct predictions on new data. Regularizationcan reduce overfitting.
Training on a large and diverse training set can also reduce overfitting. Overfitting is like strictly following advice from only your favorite
teacher. You'll probably be successful in that teacher's class, but you
might ""overfit"" to that teacher's ideas and be unsuccessful in other
classes. Following advice from a mixture of teachers will enable you to
adapt better to new situations. ",,"['class', 'model', 'prediction', 'regularization', 'training', 'training set']",,false,"(overfitt|\s(\s|\.|\,))"
sampling bias,See selection bias.,,"['selection bias']",,false,"(sampling(\s|-)?bia|\s(\s|\.|\,))"
L1 loss,"A loss function that calculates the absolute value
of the difference between actuallabelvalues and
the values that amodelpredicts. For example, here's the
calculation of L1loss for abatchof fiveexamples: L1loss is less sensitive tooutliersthanL2loss. TheMean Absolute Erroris the average
L1loss per example. $$ L_1 loss = \sum_{i=0}^n | y_i - \hat{y}_i |$$",,"['batch', 'L2loss', 'label', 'loss', 'loss function', 'model', 'outliers', 'retrieval-augmented generation']",,false,"(L1loss|\s(\s|\.|\,))"
SepCNN,"Also known as depthwise separable convolutional neural network - SepCNN is a convolutional neural network architecture based on Inception,
but where Inception modules are replaced with depthwise separable
convolutions. Also known as Xception. A depthwise separable convolution (also abbreviated as separable convolution)
factors a standard 3D convolution into two separate convolution operations
that are more computationally efficient: first, a depthwise convolution,
with a depth of 1 (n ‚úï n ‚úï 1), and then second, a pointwise convolution,
with length and width of 1 (1 ‚úï 1 ‚úï n). To learn more, seeXception: Deep Learning with Depthwise Separable
Convolutions. ",,"['convolution', 'convolutional neural network', 'depth', 'neural network', 'width']",,false,"(SepCNN|\s(\s|\.|\,))"
tower,"A component of adeep neural networkthat is
itself a deep neural network. In some cases, each tower reads from an
independent data source, and those towers stay independent until their
output is combined in a final layer. In other cases, (for example, in
theencoderanddecoderstack/tower of
manyTransformers), towers have cross-connections
to each other.",,"['decoder', 'deep neural network', 'encoder', 'layer', 'neural network', 'Transformer', 'Tensor Processing Unit']",,false,"(tower|\s(\s|\.|\,))"
token,"In a language model, the atomic unit that the model is
training on and making predictions on. A token is typically one of the
following: In domains outside of language models, tokens can represent other kinds of
atomic units. For example, in computer vision, a token might be a subset
of an image. ",,"['language model', 'model', 'prediction', 'training']",,false,"(token|\s(\s|\.|\,))"
weighted sum,"The sum of all the relevant input values multiplied by their corresponding
weights. For example, suppose the relevant inputs consist of the following: The weighted sum is therefore: A weighted sum is the input argument to anactivation function. ",,"['activation function', 'weight']",,false,"(weighted(\s|-)?sum|\s(\s|\.|\,))"
Q-learning,"In reinforcement learning, an algorithm that allows an agent to learn the optimal Q-function of a Markov decision process by applying the Bellman equation. The Markov decision process models
an environment. 
""Q"" refers to the Q-function: a function that calculates the quality of a state‚Äìaction combination.",,"['agent', 'Bellman equation', 'environment', 'model', 'Q-function', 'large language model']",,false,"(Q(\s|-)?learn|\s(\s|\.|\,))"
model parameter,"The model variables that are learned from the data during training e.g. weights, biases.",,"['hyperparameter', 'learning rate', 'linear', 'linear regression', 'model', 'training', 'weight']",,false,"(parameter|\s(\s|\.|\,))"
node (decision tree),"In adecision tree, anyconditionorleaf.",,"['condition', 'decision tree', 'leaf']",,false,"(node(\s|-)?|\s(\s|\.|\,))"
hyperparameter,"A hyperparameter is a training parameter or variable whose value is set before the training process begins. ‚Ä®Hyperparameters are configurations that are set before the learning process begins and control the learning process itself. These include settings like the learning rate, the number of layers, the number of neurons per layer, and regularization parameters like the strength of Lasso regularization.‚Ä®Examples of hyperparameters include learning rate, the number of hidden layers and batch size. ",,"['learning rate', 'model', 'parameter', 'training', 'weight', 'intersection over union']",,false,"(hyperparameter|\s(\s|\.|\,))"
T5X,"An open-source,machine learningframework designed
to build andtrainlarge-scale natural language processing
(NLP) models.T5is implemented on the T5X codebase (which is
built onJAXandFlax).",,"['Flax', 'JAX', 'machine learning', 'model', 'T5']",,false,"(T5X|\s(\s|\.|\,))"
SavedModel,"The recommended format for saving and recovering TensorFlow models. SavedModel
is a language-neutral, recoverable serialization format, which enables
higher-level systems and tools to produce, consume, and transform TensorFlow
models. See theSaving and Restoring chapterin the TensorFlow Programmer's Guide for complete details.",,"['model', 'Tensor', 'TensorFlow']",,false,"(SavedModel|\s(\s|\.|\,))"
T5,"A text-to-texttransfer learningmodelintroduced byGoogle AI in 2020.
T5 is anencoder-decodermodel, based on theTransformerarchitecture, trained on an extremely large
dataset. It is effective at a variety of natural language processing tasks,
such as generating text, translating languages, and answering questions in
a conversational manner. T5 gets its name from the five T's in ""Text-to-Text Transfer Transformer.""",,"['decoder', 'encoder', 'model', 'task', 'transfer learning', 'Transformer']",,false,"(T5|\s(\s|\.|\,))"
Root Mean Squared Error (RMSE),The square root of theMean Squared Error.,RMSE,"['root']",,false,"(Root(\s|-)?Mean(\s|-)?Squared(\s|-)?Error(\s|-)?()|\sRMSE(\s|\.|\,)|\s(\s|\.|\,))"
host,"When training an ML model onaccelerator chips(GPUs orTPUs), the part of the system
that controls both of the following: The host typically runs on a CPU, not on an accelerator chip; thedevicemanipulatestensorson the
accelerator chips.",,"['accelerator chip', 'device', 'model', 'Tensor', 'test', 'training', 'Tensor Processing Unit']",,false,"(host|\s(\s|\.|\,))"
language model,"Amodelthat estimates the probability of atokenor sequence of tokens occurring in a longer sequence of tokens. Though counterintuitive, many models that evaluate text are notlanguage models. For example, text classification models and sentiment
analysis models are notlanguage models.",,"['class', 'classification model', 'model', 'token']",,false,"(language(\s|-)?model|\s(\s|\.|\,))"
TensorFlow Playground,"A program that visualizes how differenthyperparametersinfluence model
(primarily neural network) training.
Go tohttp://playground.tensorflow.orgto experiment with TensorFlow Playground.",,"['hyperparameter', 'model', 'neural network', 'parameter', 'Tensor', 'TensorFlow', 'training']",,false,"(TensorFlow(\s|-)?Playground|\s(\s|\.|\,))"
minority class,"The less common label in aclass-imbalanced dataset. For example,
given a dataset containing 99% negative labels and 1% positive labels, the
positive labels are the minority class. Contrast withmajority class. A training set with a millionexamplessounds
impressive. However, if the minority class is poorly represented,
then even a very large training set might be insufficient. Focus less
on the total number of examples in the dataset and more on the number of
examples in the minority class. If your dataset doesn't contain enough minority class examples, consider
usingdownsampling(the definition
in the second bullet) to supplement the minority class. ",,"['class', 'class-imbalanced dataset', 'downsampling', 'imbalanced dataset', 'label', 'majority class', 'training', 'training set']",,false,"(minority(\s|-)?clas|\s(\s|\.|\,))"
hierarchical clustering,"A category of clustering algorithms that create a tree
of clusters. Hierarchical clustering is well-suited to hierarchical data,
such as botanical taxonomies. There are two types of hierarchical
clustering algorithms",,"['centroid', 'centroid-based clustering', 'clustering']",,false,"(hierarchical(\s|-)?cluster|\s(\s|\.|\,))"
out-of-bag evaluation (OOB evaluation),"A mechanism for evaluating the quality of adecision forestby testing eachdecision treeagainst theexamplesnotused duringtrainingof that decision tree. For example, in the
following diagram, notice that the system trains each decision tree
on about two-thirds of the examples and then evaluates against the
remaining one-third of the examples.  Out-of-bag evaluation is a computationally efficient and conservative
approximation of thecross-validationmechanism.
In cross-validation, one model is trained for each cross-validation round
(for example, 10 models are trained in a 10-fold cross-validation).
With OOB evaluation, a single model is trained. Becausebaggingwithholds some data from each tree during training, OOB evaluation can use
that data to approximate cross-validation.",,"['bagging', 'cross-validation', 'decision forest', 'decision tree', 'evaluation', 'model', 'test', 'training', 'validation']",,false,"(out(\s|-)?of(\s|-)?bag(\s|-)?evaluation(\s|-)?|\s(\s|\.|\,))"
prior belief,"What you believe about the data before you begin training on it.
For example,L2regularizationrelies on
a prior belief thatweightsshould be small and normally
distributed around zero. ",,"['L2regularization', 'regularization', 'training', 'weight']",,false,"(prior(\s|-)?belief|\s(\s|\.|\,))"
perplexity,"One measure of how well amodelis accomplishing its task.
For example, suppose your task is to read the first few letters of a word
a user is typing on a phone keyboard, and to offer a list of possible
completion words. Perplexity, P, for this task is approximately the number
of guesses you need to offer in order for your list to contain the actual
word the user is trying to type. Perplexity is related tocross-entropyas follows: ",,"['cross-entropy', 'entropy', 'model', 'task']",,false,"(perplexity|\s(\s|\.|\,))"
prompt,"Any text entered as input to a large language model to condition the model to behave in a certain way. A generative AI model can respond to a prompt with text, code, images,embeddings, videos‚Ä¶almost anything.",,"['condition', 'generative AI', 'language model', 'large language model', 'model']",,false,"(prompt|\s(\s|\.|\,))"
prompt engineering,"The art of creating prompts that elicit the desired responses from a large language model. Humans perform prompt
engineering. Writing well-structured prompts is an essential part of ensuring
useful responses from a large language model. ",,"['language model', 'large language model', 'model', 'prompt', 'prompt design']",,false,"(prompt(\s|-)?engineer|\s(\s|\.|\,))"
replica,"A copy of thetraining setormodel,
typically on another machine. For example, a system could use the following
strategy for implementingdata parallelism:",,"['data parallelism', 'model', 'training', 'training set']",,false,"(replica|\s(\s|\.|\,))"
reporting bias,"The fact that the frequency with which people write about actions,
outcomes, or properties is not a reflection of their real-world
frequencies or the degree to which a property is characteristic
of a class of individuals. Reporting bias can influence the composition
of data that machine learning systems learn from. For example, in books, the wordlaughedis more prevalent thanbreathed. A machine learning model that estimates the relative frequency of
laughing and breathing from a book corpus would probably determine
that laughing is more common than breathing. ",,"['action', 'class', 'machine learning', 'model']",,false,"(reporting(\s|-)?bia|\s(\s|\.|\,))"
log-odds,"The logarithm of the odds of some event. If the event is a binary probability, thenoddsrefers to
the ratio of the probability of success (p) to the probability of
failure (1-p). For example, suppose that a given event has a 90%
probability of success and a 10% probability of failure. In this case,
odds is calculated as follows: The log-odds is simply the logarithm of the odds. By convention,
""logarithm"" refers tonatural logarithm,
but logarithm could actually be any base greater than 1.
Sticking to convention, the log-odds of our example is therefore: The log-odds function is the inverse of thesigmoid function.",,"['sigmoid function']",,false,"(log(\s|-)?odds|\s(\s|\.|\,))"
reinforcement learning (RL),"A family of algorithms that learn an 'optimal policy', whose goal
is to 'maximize return' when interacting with
an 'environment'.
For example, the ultimate reward (maximize return) of most games is victory.
Reinforcement learning systems can become expert at playing complex games by evaluating sequences of previous game moves that ultimately led to wins and sequences that ultimately led to losses.",,"['environment', 'loss', 'policy', 'return', 'reward', 'intersection over union']",,false,"(reinforcement(\s|-)?learning(\s|-)?|\s(\s|\.|\,))"
least squares regression,A linear regression model trained by minimizingL2Loss.,,"['L2loss', 'linear', 'linear regression', 'loss', 'model', 'regression model']",,false,"(least(\s|-)?squares(\s|-)?regress|\s(\s|\.|\,))"
critic,Synonym for Deep Q-Network. ,,"['Deep Q-Network']",deep q-network,true,"(critic|\sDeep Q-Network(\s|\.|\,))"
minimax loss,"A loss function forgenerative adversarial networks,
based on thecross-entropybetween the distribution
of generated data and real data. Minimax loss is used in thefirst paperto describe
generative adversarial networks.",,"['cross-entropy', 'distribution', 'entropy', 'loss', 'loss function']",,false,"(minimax(\s|-)?los|\s(\s|\.|\,))"
quantile bucketing,"Distributing a feature's values intobucketsso that each
bucket contains the same (or almost the same) number of examples. For example,
the following figure divides 44 points into 4 buckets, each of which
contains 11 points. In order for each bucket in the figure to contain the
same number of points, some buckets span a different width of x-values.  ",,"['feature', 'width']",,false,"(quantile(\s|-)?bucket|\s(\s|\.|\,))"
single program / multiple data,"A parallelism technique where the same computation is run on different input
data in parallel on different devices. The goal of SPMD is to obtain results
more quickly. It is the most common style of parallel programming.",SPMD,"['device']",,false,"(single(\s|-)?program(\s|-)?/(\s|-)?multiple(\s|-)?data|\sSPMD(\s|\.|\,)|\s(\s|\.|\,))"
model parallelism,"A way of scaling training or inference that puts different parts of onemodelon differentdevices. Model parallelism
enables models that are too big to fit on a single device. To implement model parallelism, a system typically does the following: Model parallelism slows training. See alsodata parallelism.",,"['data parallelism', 'device', 'inference', 'model', 'scaling', 'training']",,false,"(model(\s|-)?parallelism|\s(\s|\.|\,))"
static,"Something done once rather than continuously.
The termsstaticandofflineare synonyms.
The following are common uses ofstaticandofflinein machine
learning: Contrast withdynamic.",,"['dynamic', 'linear', 'offline']",,false,"(static|\soffline(\s|\.|\,))"
prediction,"A model's output.",,"['model', 'Tensor Processing Unit']",,false,"(predict|\s(\s|\.|\,))"
permutation variable importances,"A type ofvariable importancethat evaluates
the increase in the prediction error of a modelafterpermuting the
feature's values. Permutation variable importance is a model-independent
metric. ",,"['feature', 'metric', 'model', 'prediction']",,false,"(permutation(\s|-)?variable(\s|-)?importance|\s(\s|\.|\,))"
value imputation,"The process of replacing a missing value with an acceptable substitute.
When a value is missing, you can either discard the entire example or you
can use value imputation to salvage the example. A synonym for Feature Imputation.",,"['feature', 'imputation', 'temperature']",,false,"(value(\s|-)?imputat|\s(\s|\.|\,))"
word embedding,"Representin geach word in a word set within anembedding vector; that is, representing each word as
a vector of floating-point values between 0.0 and 1.0. Words with similar
meanings have more-similar representations than words with different meanings.
For example,carrots,celery, andcucumberswould all have relatively
similar representations, which would be very different from the representations
ofairplane,sunglasses, andtoothpaste. ",,"['embedding vector', 'representation', 'vector']",,false,"(word(\s|-)?embedd|\s(\s|\.|\,))"
root directory,"The directory you specify for hosting subdirectories of the TensorFlow
checkpoint and events files of multiple models.",,"['checkpoint', 'host', 'model', 'Tensor', 'TensorFlow']",,false,"(root(\s|-)?directory|\s(\s|\.|\,))"
Gradient Freezing,"Freezing is an effective way to speed up training and decrease memory utilization almost without losing final quality by toggling computing gradients in certain layers of the model.

A well-known fact in Deep Learning is that low layers learn input data patterns and at the same time top layers learn high-level features, which are specific to target tasks. When performing the optimization step with some kind of optimization algorithms (e.g. SGD, AdamW, or RMSprop), the low layers receive small gradients, and hence the parameters almost stay not changed, this is called Gradient Vanishing, so instead of computing ""useless"" gradients and perform optimization of such low-gradients parameters, which sometimes require a lot of time and computational power, we can just freeze them.

PyTorch provides a comfortable API for toggling computing gradients. Such behavior can be set by the property requires_grad of torch.Tensor.",,"['gradient', 'gradient descent', 'optimization']",,false,(Gradient(\s|-)?Freez)
Dynamic Padding,"Generally, the models are trained with a batch of inputs, and each input in the batch must have a fixed size, I.e the batch must be a representation of the matrix. The fixed size is often selected relatively on the length distribution in the dataset, the number of features, or other factors. In NLP tasks, the input size is referred to as the length of the text and called max length. Unfortunately, different texts have different lengths, so to handle such cases, the researchers proposed padding tokens and truncation. Truncation is applied, when the max length is smaller than the input text's length, so some tokens (often lasts) are removed. Padding tokens are special tokens, which is added to the end of input text when the input text's length is smaller than the max length, also worthing to note that padding tokens should not be included in calculating loss in some tasks (e.g Masked Language Modeling or Named Entity Recognition).",,,,,(Dynamic(\s|-)?Padd)
8-bit Optimizers,"The idea of 8-bit Optimizers is similar to Automatic Mixed Precision, where the model's parameters and gradients are kept in lower precision, but 8-bit Optimizers additionally keep the optimizer's state in lower precision too. The authors (Meta Research) detail described the 8-bit Optimizers in the original paper ""8-bit Optimizers via Block-wise Quantization"", and showed that 8-bit Optimizers lead to significant decreasing memory utilization and slightly speeding up the training. Additionally, the authors studied the impact of different hyperparameter settings and show that 8-bit Optimizers are stable to different choices of learning rate, betas and weight decay parameters without losing performance or hurting the convergence. Therefore, the authors provided a comfortable high-level library for 8-bit Optimizers, called bitsandbytes.",,"['quantization', 'weights', 'biases', 'parameters']",,false,(8(\s|-)?bit(\s|-)?Optimizer)
synthetic feature,"Afeaturenot present among the input features, but
assembled from one or more of them. Methods for creating synthetic features
include the following: Features created bynormalizingorscalingalone are not considered synthetic features. ",,"['feature', 'scaling']",,false,"(synthetic(\s|-)?feature|\s(\s|\.|\,))"
training set,"The subset of the dataset used to train a model. Traditionally, examples in the dataset are divided into the following three distinct subsets: Ideally, each example in the dataset should belong to only one of the preceding subsets. For example, a single example shouldn't belong to both the training set and the validation set.",,"['model', 'training', 'validation', 'validation set']",,false,"(training(\s|-)?set|\s(\s|\.|\,))"
Keras,"A popular Python machine learning API. Keras runs on
several deep learning frameworks, including TensorFlow, where it is made
available astf.keras. ",,"['machine learning', 'Tensor', 'TensorFlow', 'tf.keras']",,false,"(Keras|\s(\s|\.|\,))"
preprocessing,,,[],,false,"(preprocess|\s(\s|\.|\,))"
mini-batch,"A small, randomly selected subset of abatchprocessed in oneiteration.
Thebatch sizeof a mini-batch is usually
between 10 and 1,000 examples. For example, suppose the entire training set (the full batch)
consists of 1,000 examples. Further suppose that you set thebatch sizeof each mini-batch to 20. Therefore, each
iteration determines the loss on a random 20 of the 1,000 examples and then
adjusts theweightsandbiasesaccordingly. It is much more efficient to calculate the loss on a mini-batch than the
loss on all the examples in the full batch. ",,"['batch', 'batch size', 'iteration', 'loss', 'training', 'training set', 'weight']",,false,"(mini(\s|-)?batch|\s(\s|\.|\,))"
AdaGrad,"A gradient descent algorithm that rescales the gradients of each parameter, effectively giving each parameter
an independent learning rate. ",,"['gradient', 'gradient descent', 'learning rate', 'parameter']",,false,"(AdaGrad|\s(\s|\.|\,))"
"BERT (Bidirectional Encoder
Representations from Transformers)","A model architecture for text representation. A trained
BERT model can act as part of a larger model for text classification or
other ML tasks. BERT has the following characteristics: BERT's variants include: SeeOpen Sourcing BERT: State-of-the-Art Pre-training for Natural Language
Processingfor an overview of BERT.",BERT,"['class', 'model', 'pre-training', 'representation', 'state', 'task', 'training']",,false,"((\s|-)?|\sBERT(\s|\.|\,)|\s(\s|\.|\,))"
Markov property,"A property of certainenvironments, where state
transitions are entirely determined by information implicit in the
currentstateand the agent'saction.",,"['action', 'agent', 'environment', 'state']",,false,"(Markov(\s|-)?property|\s(\s|\.|\,))"
multinomial regression,Synonym for multi-class logistic regression. ,,"['class', 'logistic regression', 'multi-class logistic regression']",multi-class logistic regression,true,"(multinomial(\s|-)?regress|\smulti-class logistic regression(\s|\.|\,))"
TPU device,"A printed circuit board (PCB) with multipleTPU chips,
high bandwidth network interfaces, and system cooling hardware.",,"['TPU chip', 'width', 'Tensor Processing Unit']",,false,"(TPU(\s|-)?device|\s(\s|\.|\,))"
test,"In adecision tree, another name for acondition.",,"['condition', 'decision tree']",,false,"(test|\s(\s|\.|\,))"
categorical data,"Featureshaving a specific set of possible values. For example,
consider a categorical feature namedtraffic-light-state, which can only
have one of the following three possible values: By representingtraffic-light-stateas a categorical feature,
a model can learn the
differing impacts ofred,green, andyellowon driver behavior. Categorical features are sometimes calleddiscrete features. Contrast withnumerical data.",,"['discrete feature', 'feature', 'model', 'numerical data', 'state']",,false,"(categorical(\s|-)?data|\s(\s|\.|\,))"
NumPy,An open-source math library that provides efficient array operations in Python.,,"['pandas']",,false,"(NumPy|\s(\s|\.|\,))"
machine learning,"A program or system that trains a model from input data. The trained model can
make useful predictions from new (never-before-seen) data drawn from
the same distribution as the one used to train the model. Machine learning also refers to the field of study concerned
with these programs or systems.",ML,"['distribution', 'model', 'prediction']",,false,"(machine(\s|-)?learn|\sML(\s|\.|\,)|\s(\s|\.|\,))"
spatial pooling,See pooling layer,,"['pooling']",,false,"(spatial(\s|-)?pool|\s(\s|\.|\,))"
in-group bias,"Showing partiality to one's own group or own characteristics.
If testers or raters consist of the machine learning developer's friends,
family, or colleagues, then in-group bias may invalidate product testing
or the dataset. In-group bias is a form ofgroup attribution bias.
See alsoout-group homogeneity bias. ",,"['group attribution bias', 'machine learning', 'out-group homogeneity bias', 'rater', 'test']",,false,"(in(\s|-)?group(\s|-)?bia|\s(\s|\.|\,))"
Z-score normalization,"Ascalingtechnique that replaces a rawfeaturevalue with a floating-point value representing
the number of standard deviations from that feature's mean.
For example, consider a feature whose mean is 800 and whose standard
deviation is 100. The following table shows how Z-score normalization
would map the raw value to its Z-score: The machine learning model then trains on the Z-scores
for that feature instead of on the raw values. Except as otherwise noted, the content of this page is licensed under theCreative Commons Attribution 4.0 License, and code samples are licensed under theApache 2.0 License. For details, see theGoogle Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates. Last updated 2024-06-13 UTC.",,"['feature', 'machine learning', 'model', 'normalization', 'scaling']",,false,"(Z(\s|-)?score(\s|-)?normalizat|\s(\s|\.|\,))"
active learning,"A type of machine learning focused on methods that interactively query a user or another information source to label new data points with the desired outputs. A training approach in which the algorithm chooses some of the data it learns from. Active learning
is particularly valuable when labeled examples are scarce or expensive to obtain. Instead of blindly seeking a diverse
range of labeled examples, an active learning algorithm selectively seeks
the particular range of examples it needs for learning. ",,"['label', 'labeled example', 'training']",,false,"(active(\s|-)?learn|\s(\s|\.|\,))"
agent,"In reinforcement learning,
the entity that uses a policyto maximize the expected returngained from
transitioning between statesof the environment. More generally, an agent is software that autonomously plans and executes a
series of actions in pursuit of a goal, with the ability to adapt to changes
in its environment. e.g. LLM-based agents might use the
LLM to generate a plan, rather than applying a reinforcement learning policy.",,"['action', 'environment', 'policy', 'return', 'state', 'large language model']",,false,"(agent|\s(\s|\.|\,))"
node (neural network),A neuron in a hidden layer.,,"['hidden layer', 'layer', 'neuron']",,false,"(node(\s|-)?|\s(\s|\.|\,))"
zero-shot learning,"A type of machine learningtrainingwhere themodelinfers apredictionfor a task
that it was not specifically already trained on. In other words, the model
is given zero task-specific trainingexamplesbut asked
to doinferencefor that task.",,"['inference', 'machine learning', 'model', 'prediction', 'task', 'training']",,false,"(zero(\s|-)?shot(\s|-)?learn|\s(\s|\.|\,))"
dense feature,"Afeaturein which most or all values are nonzero, typically
aTensorof floating-point values. For example, the following
10-element Tensor is dense because 9 of its values are nonzero: Contrast withsparse feature. ",,"['feature', 'sparse feature', 'Tensor']",,false,"(dense(\s|-)?feature|\s(\s|\.|\,))"
depth,"The sum of the following in aneural network: For example, a neural network with five hidden layers and one output layer
has a depth of 6. Notice that theinput layerdoesn't
influence depth.",,"['hidden layer', 'input layer', 'layer', 'neural network', 'output layer', 'Tensor Processing Unit']",,false,"(depth|\s(\s|\.|\,))"
PR AUC (area under the PR curve),"Area under the interpolatedprecision-recall curve, obtained by plotting
(recall, precision) points for different values of theclassification threshold. Depending on how
it's calculated, PR AUC may be equivalent to theaverage precisionof the model. ",,"['average precision', 'class', 'classification threshold', 'model', 'precision', 'precision-recall curve', 'recall', 'retrieval-augmented generation']",,false,"(PR(\s|-)?AUC(\s|-)?|\s(\s|\.|\,))"
multi-class logistic regression,Using logistic regression in multi-class classification problems.,,"['class', 'logistic regression', 'multi-class classification']",,false,"(multi(\s|-)?class(\s|-)?logistic(\s|-)?regress|\smultinomial regression(\s|\.|\,))"
negative sampling,Synonym forcandidate sampling. ,,"['candidate sampling']",candidate sampling,true,"(negative(\s|-)?sampl|\scandidate sampling(\s|\.|\,))"
novelty detection,"The process of determining whether a new (novel) example comes from the same
distribution as thetraining set. In other words, after
training on the training set, novelty detection determines whether anewexample (during inference or during additional training) is anoutlier. Contrast withoutlier detection.",,"['distribution', 'inference', 'outlier detection', 'training', 'training set']",,false,"(novelty(\s|-)?detect|\s(\s|\.|\,))"
packed data,"An approach for storing data more efficiently. Packed data stores data either by using a compressed format or in
some other way that allows it to be accessed more efficiently.
Packed data minimizes the amount of memory and computation required to
access it, leading to faster training and more efficient model inference. Packed data is often used with other techniques, such asdata augmentationandregularization, further improving the performance ofmodels.",,"['data augmentation', 'inference', 'model', 'performance', 'regularization', 'training']",,false,"(packed(\s|-)?data|\s(\s|\.|\,))"
Optax,"A gradient processing and optimization library for JAX.
Optax facilitates research by providing building blocks that can be
recombined in custom ways to optimize parametric models such as
deep neural networks. Other goals include: ",,"['deep neural network', 'gradient', 'JAX', 'metric', 'model', 'neural network']",,false,"(Optax|\s(\s|\.|\,))"
noise,"Broadly speaking, anything that obscures the signal in a dataset. Noise
can be introduced into data in a variety of ways. For example:",,[],,false,"(noise|\s(\s|\.|\,))"
Flax,"A high-performance open-source library for
deep learning built on top of JAX. Flax provides functions
for trainingneural networks, as well
as methods for evaluating their performance.",,"['JAX', 'neural network', 'performance', 'training']",,false,"(Flax|\s(\s|\.|\,))"
L0regularization,"A type of regularization that
penalizes the total numberof nonzero weights in a model. For example, a model having 11 nonzero weights
would be penalized more than a similar model having 10 nonzero weights. L0regularization is sometimes calledL0-norm regularization. L0regularization is generally impractical in large models because
L0regularization turns training into a convex optimization problem.",,"['model', 'regularization', 'training', 'weight']",,false,"(L0regularizat|\s(\s|\.|\,))"
Kernel Support Vector Machines (KSVMs),"A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors
to a higher dimensional space. For example, consider a classification
problem in which the input dataset
has a hundred features. To maximize the margin between
positive and negative classes, a KSVM could internally map those features into
a million-dimension space. KSVMs uses a loss function calledhinge loss.",,"['class', 'feature', 'hinge loss', 'loss', 'loss function', 'negative class', 'vector']",,false,"(Kernel(\s|-)?Support(\s|-)?Vector(\s|-)?Machines(\s|-)?|\s(\s|\.|\,))"
Long Short-Term Memory,"A type of cell in a recurrent neural network used to process
sequences of data in applications such as handwriting recognition, machine
translation, and image captioning. LSTMs address thevanishing gradient problemthat occurs when
training RNNs due to long data sequences by maintaining history in an
internal memory state based on new input and context from previous cells
in the RNN.",LSTM,"['gradient', 'neural network', 'recurrent neural network', 'state', 'training', 'vanishing gradient problem', 'intersection over union']",,false,"(Long(\s|-)?Short(\s|-)?Term(\s|-)?Memory|\sLSTM(\s|\.|\,)|\s(\s|\.|\,))"
random policy,"In reinforcement learning, a policy that chooses an action at random. ",,"['action', 'policy']",,false,"(random(\s|-)?policy|\s(\s|\.|\,))"
neural network,"A model containing at least one hidden layer.
A deep neural network is a type of neural network
containing more than one hidden layer.",,"['convolution', 'convolutional neural network', 'deep neural network', 'feature', 'hidden layer', 'label', 'layer', 'linear', 'model', 'neuron', 'nonlinear', 'online', 'recurrent neural network']",,false,"(neural(\s|-)?network|\s(\s|\.|\,))"
pooling layer,"Reducing a matrix (or matrixes) created by an earlier convolutional layer to a smaller matrix.
Pooling usually involves taking either the maximum or average value
across the pooled area. For example, suppose we have the
following 3x3 matrix:  A pooling operation, just like a convolutional operation, divides that
matrix into slices and then slides that convolutional operation bystrides. For example, suppose the pooling operation
divides the convolutional matrix into 2x2 slices with a 1x1 stride.
As the following diagram illustrates, four pooling operations take place.
Imagine that each pooling operation picks the maximum value of the
four in that slice:  Pooling helps enforcetranslational invariancein the input matrix. Pooling for vision applications is known more formally asspatial pooling.
Time-series applications usually refer to pooling astemporal pooling.
Less formally, pooling is often calledsubsamplingordownsampling.",,"['convolution', 'convolutional layer', 'convolutional operation', 'downsampling', 'layer', 'spatial pooling', 'stride', 'subsampling', 'translational invariance', 'retrieval-augmented generation']",,false,"(pooling|\s(\s|\.|\,))"
binning,Synonym forbucketing.,,"['bucketing']",bucketing,true,"(binning|\sbucketing(\s|\.|\,))"