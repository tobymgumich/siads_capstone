{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7958ae24-4793-4ac1-8b84-59b187ada2ed",
   "metadata": {},
   "source": [
    "# Bitap Algorithm (Levenshtein Distance)\n",
    "\n",
    "The following notebook is used for evaluating approximate matching at the sentence level, where the text has "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6d70b4-b678-4efb-b771-d398f6f6669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622265f5-ba13-46b3-908e-1f1418dc3aab",
   "metadata": {},
   "source": [
    "## Homoglyph substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d91e88-ff54-4e9a-8fc9-15bb16425dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_dict = {\n",
    "    'a': ['а', 'ạ', 'ą', 'ä', 'à', 'á', 'ą'],\n",
    "    'c': ['с', 'ƈ', 'ċ'],\n",
    "    'd': ['ԁ', 'ɗ'],\n",
    "    'e': ['е', 'ẹ', 'ė', 'é', 'è'],\n",
    "    'g': ['ġ'],\n",
    "    'h': ['һ'],\n",
    "    'i': ['і', 'í', 'ï'],\n",
    "    'j': ['ј', 'ʝ'],\n",
    "    'k': ['κ'],\n",
    "    'l': ['ӏ', 'ḷ'],\n",
    "    'n': ['ո'],\n",
    "    'o': ['о', 'ο', 'օ', 'ȯ', 'ọ', 'ỏ', 'ơ', 'ó', 'ò', 'ö'],\n",
    "    'p': ['р'],\n",
    "    'q': ['զ'],\n",
    "    's': ['ʂ'],\n",
    "    'u': ['υ', 'ս', 'ü', 'ú', 'ù'],\n",
    "    'v': ['ν', 'ѵ'],\n",
    "    'x': ['х', 'ҳ'],\n",
    "    'y': ['у', 'ý'],\n",
    "    'z': ['ʐ', 'ż']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50cc49fc-f2de-4620-89ea-eb8de8623c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_text_converter(text, unicode_dict, max_changes=20):\n",
    "    \"\"\"\n",
    "    Convert characters in the input text to Unicode look-alikes.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The input text to be modified.\n",
    "    unicode_dict (dict): A dictionary mapping characters to lists of Unicode look-alikes.\n",
    "    max_changes (int): The maximum number of character changes to make. Defaults to 20.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the modified text (str) and the number of changes made (int).\n",
    "    \"\"\"\n",
    "    char_list = list(text)\n",
    "    changes_made = 0\n",
    "    \n",
    "    for i, char in enumerate(char_list):\n",
    "        if changes_made >= max_changes:\n",
    "            break\n",
    "        \n",
    "        if char.lower() in unicode_dict and unicode_dict[char.lower()]:\n",
    "            if random.random() < 0.5:\n",
    "                unicode_char = random.choice(unicode_dict[char.lower()])\n",
    "                \n",
    "                if char.isupper():\n",
    "                    char_list[i] = unicode_char.upper()\n",
    "                else:\n",
    "                    char_list[i] = unicode_char\n",
    "                \n",
    "                changes_made += 1\n",
    "    \n",
    "    modified_text = ''.join(char_list)\n",
    "    \n",
    "    return modified_text, changes_made\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74825a-c14d-42b3-8ae5-444a0c27fe0e",
   "metadata": {},
   "source": [
    "## Invisible character insertion\n",
    "The following method intentionally modifies the text by replacing some spaces with special characters, joining words together. By choosing a list of hardly used special characters to use as replacements, this would make it easier for the plagiariser to identify and modify the font color to white - giving the appearance of separate words while tricking NLP methods that are attempting to match text for detection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f2e337e-28e7-4446-825c-4ce57f5bcd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "special_chars = ['æ', 'œ', 'ß', 'ø', 'þ', 'ð', 'ŋ', 'ħ', 'ĸ', 'ł', 'đ', 'ſ', 'ŧ', 'ŋ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fe45399-3ec8-4975-95a3-363f38446e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specchar_space_converter(text, max_changes=20):\n",
    "    \"\"\"\n",
    "    Replace spaces between words with special characters in the input text.\n",
    "\n",
    "    Args:\n",
    "    text (str): The input text to be modified.\n",
    "    max_changes (int): The maximum number of space replacements to make. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the modified text (str) and the number of changes made (int).\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    changes_made = 0\n",
    "    modified_words = []\n",
    "    \n",
    "    for i in range(len(words) - 1):\n",
    "        modified_words.append(words[i])\n",
    "        \n",
    "        if changes_made < max_changes and random.random() < 0.5:\n",
    "            special_char = random.choice(special_chars)\n",
    "            modified_words.append(special_char)\n",
    "            changes_made += 1\n",
    "        else:\n",
    "            modified_words.append(' ')\n",
    "    \n",
    "    modified_words.append(words[-1])\n",
    "    modified_text = ''.join(modified_words)\n",
    "    \n",
    "    return modified_text, changes_made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7709f78-923f-42eb-acb3-46b2cdfab8c5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f1eb6-a6a3-442f-8f03-3c4fe97bef1a",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b3baec-1026-421c-b12c-6f64e20f7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = \"\"\"Spatial inference, or estimation, of a quantity Z : : R n → → R {{\\\\displaystyle Z\\\\colon \\\\mathbb {{R}} ^{{n}}\\\\to \\\\mathbb {{R}} }} , at an unobserved location x 0 {{\\\\displaystyle x_{{0}}}} , is calculated from a linear combination of the observed values z i = Z ( x i ) {{\\\\displaystyle z_{{i}}=Z(x_{{i}})}} and weights w i ( x 0 ) , i = 1 , … … , N {{\\\\displaystyle w_{{i}}(x_{{0}}),\\\\;i=1,\\\\ldots ,N}} : The weights w i {{\\\\displaystyle w_{{i}}}} are intended to summarize two extremely important procedures in a spatial inference process: reflect the structural \"proximity\" of samples to the estimation location x 0 {{\\\\displaystyle x_{{0}}}} ; at the same time, they should have a desegregation effect, in order to avoid bias caused by eventual sample clusters. When calculating the weights w i {{\\\\displaystyle w_{{i}}}} , there are two objectives in the geostatistical formalism: unbias and minimal variance of estimation. If the cloud of real values Z ( x 0 ) {{\\\\displaystyle Z(x_{{0}})}} is plotted against the estimated values Z ^ ^ ( x 0 ) {{\\\\displaystyle {{\\\\hat {{Z}}}}(x_{{0}})}} , the criterion for global unbias, intrinsic stationarity or [wide sense stationarity](https://en.wikipedia.org/wiki/Stationary_process) of the field, implies that the mean of the estimations must be equal to mean of the real values. The second criterion says that the mean of the squared deviations ( Z ^ ^ ( x ) − − Z ( x ) ) {{\\\\displaystyle {{\\\\big (}}{{\\\\hat {{Z}}}}(x)-Z(x){{\\\\big }}}} must be minimal, which means that when the cloud of estimated values versus the cloud real values is more disperse, the estimator is more imprecise.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99678d22-38bf-4dca-909d-6cd02cf2d66c",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cf53861-085e-40be-9fde-6a9f89f789cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matching_score(original_text, modified_text):\n",
    "    \"\"\"\n",
    "    Calculate the similarity score between original and modified texts.\n",
    "\n",
    "    Args:\n",
    "    original_text (str): The original unmodified text.\n",
    "    modified_text (str): The modified version of the text.\n",
    "\n",
    "    Returns:\n",
    "    float: The average similarity score between corresponding words,\n",
    "           normalized to a 0-1 scale.\n",
    "    \"\"\"\n",
    "    original_words = original_text.split()\n",
    "    modified_words = modified_text.split()\n",
    "    \n",
    "    total_score = 0\n",
    "    for orig_word, mod_word in zip(original_words, modified_words):\n",
    "        total_score += fuzz.ratio(orig_word.lower(), mod_word.lower())\n",
    "    \n",
    "    average_score = total_score / len(original_words)\n",
    "    return average_score / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1de2d923-6460-47eb-b62e-7dad556594a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_score(score):\n",
    "    if score >= 0.95:\n",
    "        return \"Nearly Identical\", \"The texts are practically the same with minimal changes.\"\n",
    "    elif score >= 0.90:\n",
    "        return \"Very Similar\", \"The texts are very similar with only minor differences.\"\n",
    "    elif score >= 0.80:\n",
    "        return \"Similar\", \"The texts are similar but have noticeable differences.\"\n",
    "    elif score >= 0.70:\n",
    "        return \"Moderately Different\", \"The texts have significant differences but maintain overall structure.\"\n",
    "    elif score >= 0.50:\n",
    "        return \"Substantially Different\", \"The texts have major differences but some similarities remain.\"\n",
    "    else:\n",
    "        return \"Very Different\", \"The texts are drastically different or unrelated.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2acc39-92eb-4a16-b59c-98200827accf",
   "metadata": {},
   "source": [
    "#### Unicode Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2a813-1abc-4134-8176-101867ee376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_text_converter_with_score(text, unicode_dict, max_changes=50):\n",
    "    \"\"\"\n",
    "    Convert text using Unicode look-alikes and calculate similarity score.\n",
    "\n",
    "    Args:\n",
    "    text (str): The input text to be modified.\n",
    "    unicode_dict (dict): A dictionary mapping characters to Unicode look-alikes.\n",
    "    max_changes (int): Maximum number of character changes. Defaults to 50.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Contains modified text (str), number of changes (int),\n",
    "           matching score (float), classification (str), and description (str).\n",
    "    \"\"\"\n",
    "    modified_text, num_changes = unicode_text_converter(text, unicode_dict, max_changes)\n",
    "    matching_score = calculate_matching_score(text, modified_text)\n",
    "    classification, description = classify_score(matching_score)\n",
    "    return modified_text, num_changes, matching_score, classification, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b24a32df-48f4-46ab-b538-0c707546b0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified text: Ʂрatiаl іոfėrẹnce, ȯr estímàtion, оf ạ qùạntïty Z : : R ո → → R {{\\diʂрlạystyle ʐ\\coӏòn \\mąthbb {{R}} ^{{ո}}\\to \\mạtһbb {{R}} }} , ąt an unοbserѵeɗ locatiơn x 0 {{\\dіʂрḷaýʂtyḷе x_{{0}}}} , is ƈaḷculаtẹԁ frօm a lineаr combinatïօn of thė ơbserved values z i = Z ( x i ) {{\\displaystyle z_{{i}}=Z(x_{{i}})}} and weights w i ( x 0 ) , i = 1 , … … , N {{\\displaystyle w_{{i}}(x_{{0}}),\\;i=1,\\ldots ,N}} : The weights w i {{\\displaystyle w_{{i}}}} are intended to summarize two extremely important procedures in a spatial inference process: reflect the structural \"proximity\" of samples to the estimation location x 0 {{\\displaystyle x_{{0}}}} ; at the same time, they should have a desegregation effect, in order to avoid bias caused by eventual sample clusters. When calculating the weights w i {{\\displaystyle w_{{i}}}} , there are two objectives in the geostatistical formalism: unbias and minimal variance of estimation. If the cloud of real values Z ( x 0 ) {{\\displaystyle Z(x_{{0}})}} is plotted against the estimated values Z ^ ^ ( x 0 ) {{\\displaystyle {{\\hat {{Z}}}}(x_{{0}})}} , the criterion for global unbias, intrinsic stationarity or [wide sense stationarity](https://en.wikipedia.org/wiki/Stationary_process) of the field, implies that the mean of the estimations must be equal to mean of the real values. The second criterion says that the mean of the squared deviations ( Z ^ ^ ( x ) − − Z ( x ) ) {{\\displaystyle {{\\big (}}{{\\hat {{Z}}}}(x)-Z(x){{\\big }}}} must be minimal, which means that when the cloud of estimated values versus the cloud real values is more disperse, the estimator is more imprecise.\n",
      "Number of changes made: 50\n",
      "Matching score: 0.97\n",
      "Classification: Nearly Identical\n",
      "Description: The texts are practically the same with minimal changes.\n"
     ]
    }
   ],
   "source": [
    "text = text_test\n",
    "modified_text, num_changes, matching_score, classification, description = unicode_text_converter_with_score(text, unicode_dict)\n",
    "#print(f\"Original text: {text}\")\n",
    "print(f\"Modified text: {modified_text}\")\n",
    "print(f\"Number of changes made: {num_changes}\")\n",
    "print(f\"Matching score: {matching_score:.2f}\")\n",
    "print(f\"Classification: {classification}\")\n",
    "print(f\"Description: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ca11c-9927-4b9d-b9ca-7896d8c99487",
   "metadata": {},
   "source": [
    "#### Hidden special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44206ab9-dc7c-484f-ba49-96bdc5460aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specchar_space_converter_with_score(text, max_changes=20):\n",
    "    \"\"\"\n",
    "    Replace spaces with special characters and calculate similarity score.\n",
    "\n",
    "    Args:\n",
    "    text (str): The input text to be modified.\n",
    "    max_changes (int): Maximum number of space replacements. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Contains modified text (str), number of changes (int),\n",
    "           matching score (float), classification (str), and description (str).\n",
    "    \"\"\"\n",
    "    modified_text, num_changes = specchar_space_converter(text, max_changes)\n",
    "    matching_score = calculate_matching_score(text, modified_text)\n",
    "    classification, description = classify_score(matching_score)\n",
    "    return modified_text, num_changes, matching_score, classification, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a0199b0-f884-4c86-9752-e92a62e4b450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified text: Spatial inference, orŧestimation,ŋof aſquantity Z : :ſR nĸ→æ→ R {{\\displaystyle Z\\colon \\mathbb {{R}} ^{{n}}\\to \\mathbb {{R}}ŋ}}đ, at anøunobservedælocationðxĸ0ħ{{\\displaystyleŋx_{{0}}}} ,æis calculatedĸfrom ađlinear combination of the observed values z i = Z (ŧxſi ) {{\\displaystyleøz_{{i}}=Z(x_{{i}})}} and weights w i ( x 0 ) , i = 1 , … … , N {{\\displaystyle w_{{i}}(x_{{0}}),\\;i=1,\\ldots ,N}} : The weights w i {{\\displaystyle w_{{i}}}} are intended to summarize two extremely important procedures in a spatial inference process: reflect the structural \"proximity\" of samples to the estimation location x 0 {{\\displaystyle x_{{0}}}} ; at the same time, they should have a desegregation effect, in order to avoid bias caused by eventual sample clusters. When calculating the weights w i {{\\displaystyle w_{{i}}}} , there are two objectives in the geostatistical formalism: unbias and minimal variance of estimation. If the cloud of real values Z ( x 0 ) {{\\displaystyle Z(x_{{0}})}} is plotted against the estimated values Z ^ ^ ( x 0 ) {{\\displaystyle {{\\hat {{Z}}}}(x_{{0}})}} , the criterion for global unbias, intrinsic stationarity or [wide sense stationarity](https://en.wikipedia.org/wiki/Stationary_process) of the field, implies that the mean of the estimations must be equal to mean of the real values. The second criterion says that the mean of the squared deviations ( Z ^ ^ ( x ) − − Z ( x ) ) {{\\displaystyle {{\\big (}}{{\\hat {{Z}}}}(x)-Z(x){{\\big }}}} must be minimal, which means that when the cloud of estimated values versus the cloud real values is more disperse, the estimator is more imprecise.\n",
      "Number of changes made: 20\n",
      "Matching score: 0.09\n",
      "Classification: Very Different\n",
      "Description: The texts are drastically different or unrelated.\n"
     ]
    }
   ],
   "source": [
    "text = text_test\n",
    "modified_text, num_changes, matching_score, classification, description = specchar_space_converter_with_score(text)\n",
    "#print(f\"Original text: {text}\")\n",
    "print(f\"Modified text: {modified_text}\")\n",
    "print(f\"Number of changes made: {num_changes}\")\n",
    "print(f\"Matching score: {matching_score:.2f}\")\n",
    "print(f\"Classification: {classification}\")\n",
    "print(f\"Description: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08f02c-30b6-46b7-8a0e-4384ef488a99",
   "metadata": {},
   "source": [
    "#### Summarisation, paraphrasing, and rewriting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7b35105-8754-4e63-ab06-bb2558f90630",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase_text = \"'Spatial inference involves estimating a quantity Z at an unobserved location x0 by using a linear combination of observed values Z(xi) and weights wi(x0). These weights play a crucial role in summarizing two key aspects in spatial inference: reflecting sample proximity to the estimation location x0 and preventing bias due to sample clustering. In geostatistical formalism, the objectives for calculating weights are to ensure unbiased estimates and minimize estimation variance. Meeting the criteria of global unbias and field stationarity involves ensuring the mean of estimations matches the mean of real values, and minimizing the mean of squared deviations between estimated and real values indicates precision.'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27307b-8614-465b-889c-7cd53a35758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_with_score(text):\n",
    "    \"\"\"\n",
    "    Paraphrase the input text and calculate its similarity score.\n",
    "\n",
    "    Args:\n",
    "    text (str): The input text to be paraphrased.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Contains paraphrased text (str), matching score (float),\n",
    "           classification (str), and description (str).\n",
    "    \"\"\"\n",
    "    modified_text = paraphrase_text(text)\n",
    "    matching_score = calculate_matching_score(text, modified_text)\n",
    "    classification, description = classify_score(matching_score)\n",
    "    return modified_text, matching_score, classification, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8f6c002-eb89-43f3-8ac2-699304ea8d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified text: 'Spatial inference involves estimating a quantity Z at an unobserved location x0 by using a linear combination of observed values Z(xi) and weights wi(x0). These weights play a crucial role in summarizing two key aspects in spatial inference: reflecting sample proximity to the estimation location x0 and preventing bias due to sample clustering. In geostatistical formalism, the objectives for calculating weights are to ensure unbiased estimates and minimize estimation variance. Meeting the criteria of global unbias and field stationarity involves ensuring the mean of estimations matches the mean of real values, and minimizing the mean of squared deviations between estimated and real values indicates precision.'\n",
      "Matching score: 0.05\n",
      "Classification: Very Different\n",
      "Description: The texts are drastically different or unrelated.\n"
     ]
    }
   ],
   "source": [
    "text = text_test\n",
    "modified_text, matching_score, classification, description = paraphrase_with_score(text)\n",
    "#print(f\"Original text: {text}\")\n",
    "print(f\"Modified text: {modified_text}\")\n",
    "print(f\"Matching score: {matching_score:.2f}\")\n",
    "print(f\"Classification: {classification}\")\n",
    "print(f\"Description: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b6e74b-8534-4bf4-8333-e885f684b036",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Bitap and/or Approximate Matching scored as follows:\n",
    "\n",
    "1. Unicode Insertion: Matching scores >0.95 \n",
    "2. Hidden special characters: Matching scores 0.05-0.10\n",
    "3. Summarisation, paraphrasing, and rewriting: Matching scores <0.05\n",
    "\n",
    "\n",
    "Testing revealed that Bitap is very strong for minor changes such as unicode due to the limited edit distance required in the characters. It was classified as \"Nearly Identical\" i.e. the texts are practically the same with minimal changes.\n",
    "In contrast, Approximate Matching was poor when hidden special characters were added as it caused the word lengths and overall structure to change significantly. The results were even worse when any summarisation, rewriting, or paraphrasing was done.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
