{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c9cc925-f1e5-41d6-a990-7a3c31242958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125cf6dc-c97a-4250-baeb-17493d4e4592",
   "metadata": {},
   "source": [
    "# Taxonomy\n",
    "Build a controlled vocab reflecting hierarchical structure and key concepts of the subject-matter e.g. AI/Machine Learning\n",
    "\n",
    "a) label/tag taxonomy entities according to wikipage titles\n",
    "\n",
    "Populate as many pages as possible to begin with for wiki_results table to get started. Why? Wikipedia doesn't do fuzzy matching. These are:\n",
    "\n",
    "\"Neural_network_(machine_learning)\" \"Machine_learning\" Outline_of_machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6936f82d-b317-47ed-ad90-3458f1b44d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxonomy Folder\n",
    "path = '../../siads_capstone/db/taxonomy_data/'  \n",
    "\n",
    "# Get all CSV files in the Folder\n",
    "csv_files = [file for file in os.listdir(path) if file.endswith('.csv')]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(path, file))\n",
    "    df = df.drop('id', axis=1, errors='ignore')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "taxonomy_df = pd.concat(dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b4af2-4508-4196-bb74-786c22194928",
   "metadata": {},
   "source": [
    "## Unique terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4bb3f51-06b3-4aa9-a6fa-9040628e990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_term(term):\n",
    "    \"\"\"\n",
    "    Clean and standardize a given term.\n",
    "\n",
    "    This function performs the following operations:\n",
    "    1. Handles NaN values\n",
    "    2. Removes acronyms in parentheses if the result is not too short\n",
    "    3. Preserves terms with 3 or more consecutive capital letters\n",
    "    4. Strips whitespace and title-cases the term\n",
    "\n",
    "    Args:\n",
    "    term (str or float): The term to be cleaned. Can be a string or NaN.\n",
    "\n",
    "    Returns:\n",
    "    str or float: The cleaned term, or NaN if the input was NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(term):\n",
    "        return term\n",
    "    \n",
    "    if re.search(r'\\s*\\([A-Z]{2,4}\\)\\s*', term):\n",
    "        drop_acronym = re.sub(r'\\s*\\([A-Z]{2,4}\\)\\s*', '', term)\n",
    "        \n",
    "        if len(drop_acronym.strip()) > 3:\n",
    "            return drop_acronym.strip().title()\n",
    "        else:\n",
    "            return term.strip().title()\n",
    "    \n",
    "    if re.search(r'[A-Z]{3,}', term):\n",
    "        return term.strip()\n",
    "    \n",
    "    return term.strip().title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d31dd319-d736-4f6f-bb84-7f62fba8be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['level_1', 'level_2', 'level_3', 'level_4', 'level_5']:\n",
    "    taxonomy_df[column] = taxonomy_df[column].apply(clean_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "719f4860-262a-4b20-8db7-a8a58a9d31a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>level_3</th>\n",
       "      <th>level_4</th>\n",
       "      <th>level_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>Computational Efficiency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>Computational Efficiency</td>\n",
       "      <td>Gradient Accumulation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>Computational Efficiency</td>\n",
       "      <td>Automatic Mixed Precision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>Computational Efficiency</td>\n",
       "      <td>Quantization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Data Preparation And Feature Engineering</td>\n",
       "      <td>Feature Engineering</td>\n",
       "      <td>Class-Imbalanced Datasets</td>\n",
       "      <td>Ensemble Methods</td>\n",
       "      <td>Easyensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Data Preparation And Feature Engineering</td>\n",
       "      <td>Feature Engineering</td>\n",
       "      <td>Class-Imbalanced Datasets</td>\n",
       "      <td>Ensemble Methods</td>\n",
       "      <td>RUSBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>Data Preparation And Feature Engineering</td>\n",
       "      <td>Feature Engineering</td>\n",
       "      <td>Feature Extraction</td>\n",
       "      <td>Text Features</td>\n",
       "      <td>Regular Expressions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>Data Preparation And Feature Engineering</td>\n",
       "      <td>Feature Engineering</td>\n",
       "      <td>Data Cleaning</td>\n",
       "      <td>Error Correction</td>\n",
       "      <td>Regular Expressions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>Data Preparation And Feature Engineering</td>\n",
       "      <td>Feature Engineering</td>\n",
       "      <td>Class-Imbalanced Datasets</td>\n",
       "      <td>Synthetic Data</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      level_1                   level_2  \\\n",
       "0                            Model Deployment                       NaN   \n",
       "1                            Model Deployment  Computational Efficiency   \n",
       "2                            Model Deployment  Computational Efficiency   \n",
       "3                            Model Deployment  Computational Efficiency   \n",
       "4                            Model Deployment  Computational Efficiency   \n",
       "..                                        ...                       ...   \n",
       "577  Data Preparation And Feature Engineering       Feature Engineering   \n",
       "578  Data Preparation And Feature Engineering       Feature Engineering   \n",
       "579  Data Preparation And Feature Engineering       Feature Engineering   \n",
       "580  Data Preparation And Feature Engineering       Feature Engineering   \n",
       "581  Data Preparation And Feature Engineering       Feature Engineering   \n",
       "\n",
       "                       level_3           level_4              level_5  \n",
       "0                          NaN               NaN                  NaN  \n",
       "1                          NaN               NaN                  NaN  \n",
       "2        Gradient Accumulation               NaN                  NaN  \n",
       "3    Automatic Mixed Precision               NaN                  NaN  \n",
       "4                 Quantization               NaN                  NaN  \n",
       "..                         ...               ...                  ...  \n",
       "577  Class-Imbalanced Datasets  Ensemble Methods         Easyensemble  \n",
       "578  Class-Imbalanced Datasets  Ensemble Methods             RUSBoost  \n",
       "579         Feature Extraction     Text Features  Regular Expressions  \n",
       "580              Data Cleaning  Error Correction  Regular Expressions  \n",
       "581  Class-Imbalanced Datasets    Synthetic Data                  NaN  \n",
       "\n",
       "[582 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc65b6d-a076-42e5-afa5-2b68dd686ad0",
   "metadata": {},
   "source": [
    "## Unique Taxonomy Terms\n",
    "\n",
    "In order to address both known and unknown spellings of our Ontology terms and increase our matching coverage we'll look to strip as much 'noise' from our Ontology term strings as possible while allowing for scenarios such as hyphenation, capitalisation, and singular/plurals etc. through the strategic design of our regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b410eb4f-2572-48c4-8e99-f2e0a5a4d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_term_regex():\n",
    "    \"\"\"\n",
    "    Generate a DataFrame of unique taxonomy terms with their corresponding regex patterns.\n",
    "\n",
    "    This function processes the taxonomy terms from all levels in the global taxonomy_df:\n",
    "    1. Removes duplicates and null values\n",
    "    2. Cleans and standardizes terms\n",
    "    3. Removes trailing 's' for plurals\n",
    "    4. Creates regex patterns allowing for flexible spacing and hyphenation\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with columns 'taxonomy_term' (original term) and \n",
    "                  'term_regex' (corresponding regex pattern).\n",
    "    \"\"\"\n",
    "    unique_terms = []\n",
    "    taxonomy_terms = set()\n",
    "    for level in ['level_1', 'level_2', 'level_3', 'level_4', 'level_5']:\n",
    "        taxonomy_terms.update(taxonomy_df[level].dropna().unique())\n",
    "    \n",
    "    for term in taxonomy_terms:\n",
    "        term_proc = term.strip().lower()\n",
    "        term_proc = re.sub(r's$', '', term_proc)\n",
    "        \n",
    "        words = re.split(r'(\\s|\\-)', term_proc)\n",
    "        processed_words = []\n",
    "        for word in words:\n",
    "            if word in [' ', '-']:\n",
    "                processed_words.append(r'(\\s*|\\-)?')\n",
    "            else:\n",
    "                processed_words.append(re.escape(word))\n",
    "        \n",
    "        term_regex = ''.join(processed_words)\n",
    "        \n",
    "        unique_terms.append({\n",
    "            'taxonomy_term': term,\n",
    "            'term_regex': term_regex\n",
    "        })\n",
    "    \n",
    "    unique_term_df = pd.DataFrame(unique_terms)\n",
    "    \n",
    "    return unique_term_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25abd46f-e840-4478-8e93-aea4c42d9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_term_df = unique_term_regex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d117a6a-c09d-4b0c-bf8b-9e113a757710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      taxonomy_term               term_regex\n",
      "0  Trainable Layers  trainable(\\s*|\\-)?layer\n",
      "1  Cluster Analysis  cluster(\\s*|\\-)?analysi\n",
      "2       Temperature              temperature\n",
      "3        One-Sample       one(\\s*|\\-)?sample\n",
      "4            Resnet                   resnet\n",
      "\n",
      "Total unique terms: 537\n",
      "Sample of term_regex:\n",
      "341    area(\\s*|\\-)?under(\\s*|\\-)?pr(\\s*|\\-)?curve\n",
      "16                          false(\\s*|\\-)?positive\n",
      "261                            triplet(\\s*|\\-)?los\n",
      "99             mean(\\s*|\\-)?absolute(\\s*|\\-)?error\n",
      "114                   power(\\s*|\\-)?transformation\n",
      "Name: term_regex, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(unique_term_df.head())\n",
    "print(f\"\\nTotal unique terms: {len(unique_term_df)}\")\n",
    "print(f\"Sample of term_regex:\")\n",
    "print(unique_term_df['term_regex'].sample(5))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c1351-cc77-41b6-8749-bee2a40d6f21",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dad3c668-e2cc-4621-bcd4-be563ad14c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique terms has been saved as 'taxonomy.csv' in the following directory:\n",
      "/home/sagemaker-user/siads_capstone\n",
      "unique terms has been saved as 'unique_terms.csv' in the following directory:\n",
      "/home/sagemaker-user/siads_capstone\n"
     ]
    }
   ],
   "source": [
    "\n",
    "relative_path = '../../siads_capstone/'\n",
    "    \n",
    "absolute_path = os.path.abspath(relative_path)\n",
    "    \n",
    "taxonomy_file_name = \"taxonomy.csv\"\n",
    "uniqueterms_file_name = \"unique_terms.csv\"\n",
    "    \n",
    "taxonomy_file_path = os.path.join(absolute_path, taxonomy_file_name)\n",
    "uniqueterms_file_path = os.path.join(absolute_path, uniqueterms_file_name)\n",
    "\n",
    "taxonomy_df.to_csv(taxonomy_file_path, index=False)\n",
    "unique_term_df.to_csv(uniqueterms_file_path, index=False)\n",
    "\n",
    "print(f\"unique terms has been saved as '{taxonomy_file_name}' in the following directory:\")\n",
    "print(absolute_path)\n",
    "print(f\"unique terms has been saved as '{uniqueterms_file_name}' in the following directory:\")\n",
    "print(absolute_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a57be77c-f5d8-4af5-ad7e-638153e4f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_path = '../taxonomy.csv'\n",
    "taxonomy_df = pd.read_csv(taxonomy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6de698a-47e7-47b1-a83a-e2d4b3d66b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>level_3</th>\n",
       "      <th>level_4</th>\n",
       "      <th>level_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>Computational Efficiency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>Computational Efficiency</td>\n",
       "      <td>Gradient Accumulation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>Computational Efficiency</td>\n",
       "      <td>Automatic Mixed Precision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model Deployment</td>\n",
       "      <td>Computational Efficiency</td>\n",
       "      <td>Quantization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            level_1                   level_2                    level_3  \\\n",
       "0  Model Deployment                       NaN                        NaN   \n",
       "1  Model Deployment  Computational Efficiency                        NaN   \n",
       "2  Model Deployment  Computational Efficiency      Gradient Accumulation   \n",
       "3  Model Deployment  Computational Efficiency  Automatic Mixed Precision   \n",
       "4  Model Deployment  Computational Efficiency               Quantization   \n",
       "\n",
       "  level_4 level_5  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a724a77-a247-422a-8678-7e214d67f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueterms_path = '../unique_terms.csv'\n",
    "uniqueterms_df = pd.read_csv(uniqueterms_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0232f0c6-3a9c-44f9-8218-cc91b5c667c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxonomy_term</th>\n",
       "      <th>term_regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trainable Layers</td>\n",
       "      <td>trainable(\\s*|\\-)?layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cluster Analysis</td>\n",
       "      <td>cluster(\\s*|\\-)?analysi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One-Sample</td>\n",
       "      <td>one(\\s*|\\-)?sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resnet</td>\n",
       "      <td>resnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      taxonomy_term               term_regex\n",
       "0  Trainable Layers  trainable(\\s*|\\-)?layer\n",
       "1  Cluster Analysis  cluster(\\s*|\\-)?analysi\n",
       "2       Temperature              temperature\n",
       "3        One-Sample       one(\\s*|\\-)?sample\n",
       "4            Resnet                   resnet"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueterms_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
